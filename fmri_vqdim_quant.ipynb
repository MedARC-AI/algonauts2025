{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from vector_quantize_pytorch import VectorQuantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "   def __init__(self, in_dim, out_dim):\n",
    "       super().__init__()\n",
    "       self.downsample = in_dim != out_dim\n",
    "       self.net = nn.Sequential(\n",
    "           nn.Linear(in_dim, out_dim),\n",
    "           nn.LayerNorm(out_dim),\n",
    "           nn.GELU(),\n",
    "           nn.Linear(out_dim, out_dim),\n",
    "           nn.LayerNorm(out_dim),\n",
    "           nn.GELU()\n",
    "       )\n",
    "       if self.downsample:\n",
    "           self.proj = nn.Linear(in_dim, out_dim)\n",
    "   \n",
    "   def forward(self, x):\n",
    "       if self.downsample:\n",
    "           return self.proj(x) + self.net(x)\n",
    "       return x + self.net(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "   def __init__(self, input_dim=1000, hidden_dims=[512, 384, 256], num_tokens=32, codebook_dim=64):\n",
    "       super().__init__()\n",
    "       \n",
    "       # Initial projection with one residual block\n",
    "       self.input_proj = ResidualBlock(input_dim, hidden_dims[0])\n",
    "       \n",
    "       # Main network with one residual block per layer\n",
    "       layers = []\n",
    "       for i in range(len(hidden_dims)-1):\n",
    "           layers.append(ResidualBlock(hidden_dims[i], hidden_dims[i+1]))\n",
    "       self.layers = nn.Sequential(*layers)\n",
    "       \n",
    "       # Project to token space with one residual block\n",
    "       self.token_proj = ResidualBlock(hidden_dims[-1], num_tokens * codebook_dim)\n",
    "       \n",
    "       self.num_tokens = num_tokens\n",
    "       self.codebook_dim = codebook_dim\n",
    "       \n",
    "   def forward(self, x):\n",
    "       x = self.input_proj(x)\n",
    "       x = self.layers(x)\n",
    "       x = self.token_proj(x)\n",
    "       return x.view(x.shape[0], self.num_tokens, self.codebook_dim)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "   def __init__(self, output_dim=1000, hidden_dims=[256, 384, 512], num_tokens=32, codebook_dim=64):\n",
    "       super().__init__()\n",
    "       \n",
    "       # Process tokens with one residual block\n",
    "       self.token_proj = ResidualBlock(num_tokens * codebook_dim, hidden_dims[0])\n",
    "       \n",
    "       # Main network with one residual block per layer\n",
    "       layers = []\n",
    "       for i in range(len(hidden_dims)-1):\n",
    "           layers.append(ResidualBlock(hidden_dims[i], hidden_dims[i+1]))\n",
    "       self.layers = nn.Sequential(*layers)\n",
    "       \n",
    "       # Final projection with one residual block\n",
    "       self.output_proj = ResidualBlock(hidden_dims[-1], output_dim)\n",
    "       \n",
    "   def forward(self, x):\n",
    "       # x shape: [batch_size, num_tokens, codebook_dim] \n",
    "       x = x.reshape(x.shape[0], -1)  # Flatten tokens\n",
    "       x = self.token_proj(x)\n",
    "       x = self.layers(x)\n",
    "       return self.output_proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert dim % num_heads == 0, f\"dim {dim} must be divisible by num_heads {num_heads}\"\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dim // num_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        \n",
    "        # Separate projections for Q, K, V\n",
    "        self.q_proj = nn.Linear(dim, dim)\n",
    "        self.k_proj = nn.Linear(dim, dim)\n",
    "        self.v_proj = nn.Linear(dim, dim)\n",
    "        \n",
    "        self.out_proj = nn.Linear(dim, dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape  # batch, num_tokens, channels\n",
    "        H = self.num_heads\n",
    "\n",
    "        # Generate Q, K, V with separate projections\n",
    "        q = self.q_proj(x).reshape(B, N, H, self.head_dim).transpose(1, 2)  # B, H, N, head_dim\n",
    "        k = self.k_proj(x).reshape(B, N, H, self.head_dim).transpose(1, 2)\n",
    "        v = self.v_proj(x).reshape(B, N, H, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Attention\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale  # B, H, N, N\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "        \n",
    "        # Apply attention to V\n",
    "        out = (attn @ v).transpose(1, 2).reshape(B, N, C)  # B, N, C\n",
    "        out = self.out_proj(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads=2, mlp_ratio=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.attn = MultiHeadAttention(dim, num_heads, dropout)\n",
    "        \n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, mlp_hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_hidden_dim, dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pre-norm architecture\n",
    "        x = x + self.attn(self.norm1(x))\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class CustomViTEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=1000,\n",
    "        num_tokens=32,\n",
    "        token_dim=8,\n",
    "        num_layers=4,\n",
    "        num_heads=2,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_tokens = num_tokens\n",
    "        self.token_dim = token_dim\n",
    "        \n",
    "        # Initial projection and reshape\n",
    "        self.input_proj = nn.Sequential(\n",
    "            nn.Linear(input_dim, num_tokens * token_dim),\n",
    "            # nn.LayerNorm(num_tokens * token_dim),\n",
    "            # nn.GELU(),\n",
    "            # # nn.Dropout(dropout),\n",
    "            # nn.Linear(num_tokens * token_dim, num_tokens * token_dim),\n",
    "            # # nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Positional embedding\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, num_tokens, token_dim) * 0.02)  # smaller init\n",
    "        \n",
    "        # Transformer layers\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(\n",
    "                dim=token_dim,\n",
    "                num_heads=num_heads,\n",
    "                mlp_ratio=2,\n",
    "                dropout=dropout\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.norm = nn.LayerNorm(token_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Project and reshape: [B, 1000] -> [B, 32, 8]\n",
    "        x = self.input_proj(x)\n",
    "        x = x.reshape(-1, self.num_tokens, self.token_dim)\n",
    "        \n",
    "        # Add positional embeddings and dropout\n",
    "        x = x + self.pos_embed\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Apply transformer blocks\n",
    "        # print(\"input shape: \", x.shape)\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "# Mirror image of encoder for decoder\n",
    "class CustomViTDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim=1000,\n",
    "        num_tokens=32,\n",
    "        token_dim=8,\n",
    "        num_layers=4,\n",
    "        num_heads=2,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_tokens = num_tokens\n",
    "        self.token_dim = token_dim\n",
    "        \n",
    "        # Positional embedding\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, num_tokens, token_dim) * 0.02)\n",
    "        \n",
    "        # Transformer layers\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(\n",
    "                dim=token_dim,\n",
    "                num_heads=num_heads,\n",
    "                mlp_ratio=2,\n",
    "                dropout=dropout\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.norm = nn.LayerNorm(token_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Output projection\n",
    "        self.output_proj = nn.Sequential(\n",
    "            nn.Linear(num_tokens * token_dim, output_dim),\n",
    "            # nn.LayerNorm(num_tokens * token_dim),\n",
    "            # nn.GELU(),\n",
    "            # # nn.Dropout(dropout),\n",
    "            # nn.Linear(num_tokens * token_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Add positional embeddings and dropout\n",
    "        x = x + self.pos_embed\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Apply transformer blocks\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.norm(x)\n",
    "        \n",
    "        # Project back to original dimension\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.output_proj(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torchmetrics.functional import pearson_corrcoef\n",
    "\n",
    "class VQVAE(L.LightningModule):\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_dim=1000, \n",
    "            hidden_dims=[512, 384, 256], \n",
    "            num_tokens=32,\n",
    "            num_layers=2,\n",
    "            codebook_size=1024, \n",
    "            codebook_dim=8,\n",
    "            commitment_weight=0.25,\n",
    "            quantizer_decay=0.99,\n",
    "            learning_rate=3e-4,\n",
    "            weight_decay=0.01\n",
    "            ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = CustomViTEncoder(num_layers=num_layers, token_dim=codebook_dim)\n",
    "        self.decoder = CustomViTDecoder(num_layers=num_layers, token_dim=codebook_dim)\n",
    "        self.quantizer = VectorQuantize(\n",
    "                dim=codebook_dim,\n",
    "                codebook_size=codebook_size,\n",
    "                decay=quantizer_decay,\n",
    "                commitment_weight=commitment_weight\n",
    "                )\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z_q, indices, commitment_loss = self.quantizer(z)\n",
    "        x_recon = self.decoder(z_q)\n",
    "        return x_recon, commitment_loss, indices\n",
    "    \n",
    "    def calculate_metrics(self, x, x_recon):\n",
    "        # Flatten the tensors for correlation calculation\n",
    "        x = x.to(torch.float64)\n",
    "        x_recon = x_recon.to(torch.float64)\n",
    "        x_flat = x.reshape(x.shape[0], -1)\n",
    "        x_recon_flat = x_recon.reshape(x_recon.shape[0], -1)\n",
    "        \n",
    "        # Calculate Pearson R for each sample in batch\n",
    "        correlations = torch.stack([\n",
    "            pearson_corrcoef(x_flat[i], x_recon_flat[i])\n",
    "            for i in range(x_flat.shape[0])\n",
    "        ])\n",
    "        avg_pearson_r = correlations.mean()\n",
    "        \n",
    "        # Calculate variance explained\n",
    "        total_variance = torch.var(x_flat, dim=1).sum()\n",
    "        residual_variance = torch.var(x_flat - x_recon_flat, dim=1).sum()\n",
    "        variance_explained = 1 - (residual_variance / total_variance)\n",
    "        \n",
    "        return avg_pearson_r, variance_explained\n",
    "\n",
    "\n",
    "    def training_step(self, batch: torch.Tensor, batch_idx: int) -> torch.Tensor:\n",
    "        x = batch[0]\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        x_recon, commitment_loss, _ = self(x)\n",
    "        \n",
    "        recon_loss = F.mse_loss(x_recon, x)\n",
    "        total_loss = recon_loss + commitment_loss\n",
    "\n",
    "        pearson_r, var = self.calculate_metrics(x, x_recon)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('train_loss', total_loss)\n",
    "        self.log('train_recon_loss', recon_loss)\n",
    "        self.log('train_commitment_loss', commitment_loss)\n",
    "        self.log('train_pearson_r', pearson_r)\n",
    "        self.log('train_variance', var)\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    def validation_step(self, batch: torch.Tensor, batch_idx: int) -> torch.Tensor:\n",
    "        x = batch[0]\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        x_recon, commitment_loss, _ = self(x)\n",
    "        \n",
    "        recon_loss = F.mse_loss(x_recon, x)\n",
    "        total_loss = recon_loss + commitment_loss\n",
    "\n",
    "        val_pearson_r, val_var = self.calculate_metrics(x, x_recon)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('val_loss', total_loss)\n",
    "        self.log('val_recon_loss', recon_loss)\n",
    "        self.log('val_commitment_loss', commitment_loss)\n",
    "        self.log('val_pearson_r', val_pearson_r)\n",
    "        self.log('val_variance', val_var)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Separate parameter groups for different learning rates\n",
    "        encoder_decoder_params = []\n",
    "        quantizer_params = []\n",
    "        \n",
    "        # Group parameters\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'quantizer' in name:\n",
    "                quantizer_params.append(param)\n",
    "            else:\n",
    "                encoder_decoder_params.append(param)\n",
    "        \n",
    "        # Create optimizer with parameter groups\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {\n",
    "                'params': encoder_decoder_params,\n",
    "                'lr': self.learning_rate,\n",
    "                'weight_decay': self.weight_decay\n",
    "            },\n",
    "            {\n",
    "                'params': quantizer_params,\n",
    "                'lr': self.learning_rate * 0.5,  # Lower learning rate for quantizer\n",
    "                'weight_decay': 0  # Usually no weight decay for quantizer\n",
    "            }\n",
    "        ], betas=(0.9, 0.999), eps=1e-8)\n",
    "        \n",
    "        # Scheduler setup\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=1e-6,\n",
    "            verbose=True,\n",
    "            threshold=1e-4,\n",
    "            threshold_mode='rel'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",  # Metric to monitor\n",
    "            }\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class FMRIDataset(Dataset):\n",
    "    def __init__(self, h5_file):\n",
    "        data_list = []\n",
    "        try:\n",
    "            with h5py.File(h5_file, 'r') as f:\n",
    "                for key in f.keys():\n",
    "                    data = torch.from_numpy(f[key][:]).float()\n",
    "                    data_list.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {h5_file}: {str(e)}\")\n",
    "        self.data = torch.cat(data_list, dim=0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Create separate datasets for train and val\n",
    "train_file = '/home/pranav/mihir/algonauts_challenge/algonauts_2025.competitors/fmri/sub-01/func/sub-01_task-friends_space-MNI152NLin2009cAsym_atlas-Schaefer18_parcel-1000Par7Net_desc-s123456_bold.h5'\n",
    "val_file = '/home/pranav/mihir/algonauts_challenge/algonauts_2025.competitors/fmri/sub-01/func/sub-01_task-movie10_space-MNI152NLin2009cAsym_atlas-Schaefer18_parcel-1000Par7Net_bold.h5'\n",
    "\n",
    "train_dataset = FMRIDataset(train_file)\n",
    "val_dataset = FMRIDataset(val_file)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 137913\n",
      "Validation samples: 24758\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "run_name = \"fmri_1_VIT_vq_64tok_16qdim\"\n",
    "project = \"fmri_vq_tokenizer\"\n",
    "wandb_logger = WandbLogger(\n",
    "    project=project,\n",
    "    name=run_name,\n",
    "    save_dir=\"wandb_logs/\"\n",
    ")\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=-1,\n",
    "    precision=32,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            dirpath=f'checkpoints/{project}/{run_name}',\n",
    "            filename='{epoch:02d}_{val_loss:.3f}',\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_top_k=1,\n",
    "            save_last=True\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            patience=10,\n",
    "            verbose=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name                       | Type              | Params | Mode \n",
      "--------------------------------------------------------------------------\n",
      "0  | encoder                    | CustomViTEncoder  | 515 K  | train\n",
      "1  | encoder.input_proj         | Sequential        | 512 K  | train\n",
      "2  | encoder.transformer_blocks | ModuleList        | 2.2 K  | train\n",
      "3  | encoder.norm               | LayerNorm         | 32     | train\n",
      "4  | encoder.dropout            | Dropout           | 0      | train\n",
      "5  | decoder                    | CustomViTDecoder  | 515 K  | train\n",
      "6  | decoder.transformer_blocks | ModuleList        | 2.2 K  | train\n",
      "7  | decoder.norm               | LayerNorm         | 32     | train\n",
      "8  | decoder.dropout            | Dropout           | 0      | train\n",
      "9  | decoder.output_proj        | Sequential        | 513 K  | train\n",
      "10 | quantizer                  | VectorQuantize    | 0      | train\n",
      "11 | quantizer.project_in       | Identity          | 0      | train\n",
      "12 | quantizer.project_out      | Identity          | 0      | train\n",
      "13 | quantizer._codebook        | EuclideanCodebook | 0      | train\n",
      "--------------------------------------------------------------------------\n",
      "1.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 M     Total params\n",
      "4.124     Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "torch.set_float32_matmul_precision('high')\n",
    "model = VQVAE(num_layers=1, num_tokens=64, codebook_dim=16)\n",
    "summary = ModelSummary(model, max_depth=2)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmihir-neal\u001b[0m (\u001b[33mmihirneal\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>wandb_logs/wandb/run-20250206_140123-yp0kx4r9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mihirneal/fmri_vq_tokenizer/runs/yp0kx4r9' target=\"_blank\">fmri_1_VIT_vq_64tok_16qdim</a></strong> to <a href='https://wandb.ai/mihirneal/fmri_vq_tokenizer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mihirneal/fmri_vq_tokenizer' target=\"_blank\">https://wandb.ai/mihirneal/fmri_vq_tokenizer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mihirneal/fmri_vq_tokenizer/runs/yp0kx4r9' target=\"_blank\">https://wandb.ai/mihirneal/fmri_vq_tokenizer/runs/yp0kx4r9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | encoder   | CustomViTEncoder | 515 K  | train\n",
      "1 | decoder   | CustomViTDecoder | 515 K  | train\n",
      "2 | quantizer | VectorQuantize   | 0      | train\n",
      "-------------------------------------------------------\n",
      "1.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 M     Total params\n",
      "4.124     Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326ebd67576b47e0a8694826a174960f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02784483f8344f7690abd2934fddfb82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc321f4f04a74bc398a2ebab0663478c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150e3c68a90b45f4a1fb30362c618e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.024 >= min_delta = 0.0. New best score: 0.167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89530b5630d648cdb275a6b1387f289d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af726e3df3434fb082828ed79d9ec0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.153\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784f7b3af31f4f5ba21073de648a0c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.006 >= min_delta = 0.0. New best score: 0.147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951e5a2d67ad4fc8ace094f2c25800d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10cfe1e8e9ac42d987a0b49462182d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.140\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b3c2c2cdf149cabcda29e3e690f8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.139\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5809c6950b904f3abf8e7740f5c95aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.136\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7770f40fadbb4f0c9bd7393385672459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c1c363a67b45498906cfb1bb68e5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.132\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0fff1c3e47b41ee94c48d66b43e09be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66b752580c8437190bf0fb18e8f3252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.131\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435f545151414a16b128f07c64fd6902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291be586455b4d62b33e4d5bcbbe8dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6773a3cfaf4ff288ba1847269ddb7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.130\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99910d5b22004c34b60184139a2a1103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9286dfd2ee5a436793b2f821cd2d4e4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e28220a0763c4d03bca9e843dfb3bfab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67511df869a4e10ac5c2fafcab8e25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1e782d41fa4500bc4d6397bb70f172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6eea8c3d07d4d4c9c5b5b3bc8958cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd92d8c0ed64cb6b210f484f6e4d145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f5f0fcb58e42d08d49f6378deb63cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5309330bc147ad9ef42183bf03c448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55aefbbe1f9d4fcdbf41863f1172b64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a96350e7f5004d30b10a22c5c31c2e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6122656f9e74a9abc7d9add379d24d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476ef9c5db8441dcad2c58c8d6d22ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5eea1e488d4453a09b508cfdafeea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36e458269c64008b1a851676c6b812f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3295c23dc7af4cce9aefab9a6c730db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0df46e81cd430c958666031173a99f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f6e1b7423f41a991f5a83538134c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1f11c52e904458aa64a827a7023edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95bb3e0ea61c4a9aa490bbb706b0ae98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c166d91f9564ba68ffff17d2441c3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5885533ace6944f3a69facf927b87312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e9b7eb1cc84f67a5199d93d9d08fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0061942b43448c999e09cd5c8247a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5bc2b9ae9c34e989261edd0269b14d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6429ee88979d42d2a09c904aaa31499a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 0.125. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇████</td></tr><tr><td>train_commitment_loss</td><td>▇█▅▃▁▂▃▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▃▃▂▄▅▂▂▁▁▂▂▂▂▂▃▁▂▂▁▂▂▁▂▂▁▂▂▃▁▂▃▂▂▂▂▁▁▂</td></tr><tr><td>train_pearson_r</td><td>▂▆▇▄▄▇▆▅▄▅▅▆▇▅▅▂▆██▇▅▆▆▇▆▃█▅▁▄▅▅▃▄▅▅▄▃▆▄</td></tr><tr><td>train_recon_loss</td><td>▇▅█▄▅▃▃▃▂▃▂▃▄▁▂▄▂▂▃▂▃▃▃▂▂▁▃▁▁▂▂▂▂▂▂▂▃▃▂▁</td></tr><tr><td>train_variance</td><td>▄▅▁█▁▃▄▇▅▃▄▇▆▄▂▆█▇█▇▆▆█▄▅▄▃▅▂▄▆▆▄▇▆▆▄▄▃▆</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>val_commitment_loss</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_pearson_r</td><td>▁▄▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>val_recon_loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_variance</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇▇▇▇▇▇██████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>41</td></tr><tr><td>train_commitment_loss</td><td>0.00035</td></tr><tr><td>train_loss</td><td>0.10246</td></tr><tr><td>train_pearson_r</td><td>0.82343</td></tr><tr><td>train_recon_loss</td><td>0.10211</td></tr><tr><td>train_variance</td><td>0.67574</td></tr><tr><td>trainer/global_step</td><td>181019</td></tr><tr><td>val_commitment_loss</td><td>0</td></tr><tr><td>val_loss</td><td>0.1253</td></tr><tr><td>val_pearson_r</td><td>0.79849</td></tr><tr><td>val_recon_loss</td><td>0.1253</td></tr><tr><td>val_variance</td><td>0.63277</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fmri_1_VIT_vq_64tok_16qdim</strong> at: <a href='https://wandb.ai/mihirneal/fmri_vq_tokenizer/runs/yp0kx4r9' target=\"_blank\">https://wandb.ai/mihirneal/fmri_vq_tokenizer/runs/yp0kx4r9</a><br> View project at: <a href='https://wandb.ai/mihirneal/fmri_vq_tokenizer' target=\"_blank\">https://wandb.ai/mihirneal/fmri_vq_tokenizer</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>wandb_logs/wandb/run-20250206_140123-yp0kx4r9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = VQVAE()\n",
    "model = VQVAE.load_from_checkpoint(\"/home/pranav/mihir/algonauts_challenge/algonauts2025/checkpoints/fmri_vqvae_res_gelu_8qdim_1024/epoch=44_val_loss=0.137.ckpt\")\n",
    "model.eval()\n",
    "val_data = []\n",
    "val_recon = []\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        x = batch[0].to(model.device)\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        x_recon, _, _ = model(x)\n",
    "        val_data.append(x)\n",
    "        val_recon.append(x_recon)\n",
    "\n",
    "val_data = torch.cat(val_data)\n",
    "val_recon = torch.cat(val_recon)\n",
    "\n",
    "#Calculating dead codes and perplexity\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize counters\n",
    "codebook_size = 1024\n",
    "counts = torch.zeros(codebook_size, device=\"cuda\")  # Use \"cpu\" if needed\n",
    "\n",
    "# Run inference on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader):\n",
    "        x = batch.to(model.device)\n",
    "        z_e = model.encoder(x)  # Get encoder output\n",
    "        z_q, indices, _ = model.quantizer(z_e)  # Assuming `vq_layer` returns indices\n",
    "        indices_flat = indices.view(-1)  # Flatten all batch/spatial dimensions\n",
    "        counts += torch.bincount(indices_flat, minlength=codebook_size)\n",
    "\n",
    "# Compute metrics\n",
    "num_dead_codes = (counts == 0).sum().item()\n",
    "prob = counts / (counts.sum() + 1e-10)\n",
    "perplexity = torch.exp(-torch.sum(prob * torch.log(prob + 1e-10)))\n",
    "\n",
    "print(f\"Dead codes: {num_dead_codes} / {codebook_size}\")\n",
    "print(f\"Perplexity: {perplexity.item():.1f} (max: {codebook_size})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot code frequencies\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(counts.cpu().numpy(), bins=50, log_scale=(False, True))\n",
    "plt.xlabel(\"Code Frequency (log scale)\")\n",
    "plt.title(\"Code Usage Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "codebook_vectors = model.quantizer.codebook.cpu().numpy()  # Shape [1024, 8]\n",
    "similarity = cosine_similarity(codebook_vectors)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(similarity, cmap=\"viridis\", vmin=-1, vmax=1)\n",
    "plt.colorbar(label=\"Cosine Similarity\")\n",
    "plt.title(\"Codebook Vector Similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Collect codebook vectors and their usage counts\n",
    "codebook = model.quantizer.codebook.cpu().numpy()\n",
    "counts_np = counts.cpu().numpy()\n",
    "\n",
    "# Run t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "codebook_2d = tsne.fit_transform(codebook)\n",
    "\n",
    "# Plot with color indicating usage frequency\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(codebook_2d[:, 0], codebook_2d[:, 1], c=np.log(counts_np + 1), cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Log(Usage Count + 1)\")\n",
    "plt.title(\"Codebook t-SNE Projection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_explained = 1 - torch.var(val_data - val_recon) / torch.var(val_data)\n",
    "pearson_r = torch.corrcoef(torch.stack([val_data.flatten(), val_recon.flatten()]))[0,1]\n",
    "mse = torch.mean((val_data - val_recon) ** 2)\n",
    "mae = torch.mean(torch.abs(val_data - val_recon))\n",
    "\n",
    "print(f\"Variance explained: {var_explained:.3f}\")\n",
    "print(f\"Pearson correlation: {pearson_r:.3f}\")\n",
    "print(f\"MSE: {mse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_codebook(model, val_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    usage_count = torch.zeros(model.quantizer.codebook_size, device=device)\n",
    "    total_tokens = 0\n",
    "    distances = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x = batch[0].to(device)\n",
    "            if len(x.shape) == 1:\n",
    "                x = x.unsqueeze(0)\n",
    "            # Get encoder output\n",
    "            z = model.encoder(x)\n",
    "            # Get quantizer outputs before quantization\n",
    "            z_flat = z.reshape(-1, z.shape[-1])\n",
    "            _, indices, _ = model.quantizer(z_flat)\n",
    "            \n",
    "            # Update usage count\n",
    "            unique, counts = torch.unique(indices, return_counts=True)\n",
    "            usage_count[unique] += counts\n",
    "            total_tokens += indices.numel()\n",
    "            \n",
    "            # Calculate distances to assigned codebook vectors\n",
    "            dists = torch.cdist(z_flat, model.quantizer.codebook)\n",
    "            distances.append(dists.min(dim=1)[0])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    usage_prob = usage_count / total_tokens\n",
    "    active_codes = (usage_count > 0).sum().item()\n",
    "    entropy = -(usage_prob * torch.log2(usage_prob + 1e-10)).sum().item()\n",
    "    distances = torch.cat(distances)\n",
    "    \n",
    "    print(f\"Active codebook vectors: {active_codes}/{model.quantizer.codebook_size}\")\n",
    "    print(f\"Codebook entropy: {entropy:.2f} bits\")\n",
    "    print(f\"Mean distance to codebook: {distances.mean():.4f}\")\n",
    "    print(f\"Distance std: {distances.std():.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'usage_count': usage_count.cpu(),\n",
    "        'usage_prob': usage_prob.cpu(),\n",
    "        'active_codes': active_codes,\n",
    "        'entropy': entropy,\n",
    "        'distances': distances.cpu(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_codebook(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.quantizer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
