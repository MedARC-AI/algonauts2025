{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"/ocean/projects/med220004p/clane2/algonauts25/algonauts_2025.competitors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_timeseries(path: Path) -> np.ndarray:\n",
    "    file = h5py.File(path)\n",
    "    timeseries = [scale(file[k][:]) for k in file]\n",
    "    timeseries = np.concatenate(timeseries)\n",
    "    return timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = (\n",
    "    DATA_ROOT\n",
    "    / \"fmri/sub-01/func/sub-01_task-friends_space-MNI152NLin2009cAsym_atlas-Schaefer18_parcel-1000Par7Net_desc-s123456_bold.h5\"\n",
    ")\n",
    "\n",
    "val_path = (\n",
    "    DATA_ROOT\n",
    "    / \"fmri/sub-01/func/sub-01_task-movie10_space-MNI152NLin2009cAsym_atlas-Schaefer18_parcel-1000Par7Net_bold.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_timeseries = load_timeseries(train_path)\n",
    "val_timeseries = load_timeseries(val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCATokenizer:\n",
    "    def __init__(self, estimator: PCA, vmax: float = 2.5, bins: int = 1024):\n",
    "        self.estimator = estimator\n",
    "        self.vmax = vmax\n",
    "        self.bins = bins\n",
    "    \n",
    "    def fit(self, X: np.ndarray):\n",
    "        self.estimator.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: np.ndarray) -> np.ndarray:\n",
    "        embed = self.estimator.transform(X)\n",
    "        scaled = np.clip((embed + self.vmax) / (2 * self.vmax), 0.0, 1.0)\n",
    "        ids = ((self.bins - 1) * scaled).astype(np.int64)\n",
    "        return ids\n",
    "\n",
    "    def inverse_transform(self, ids: np.ndarray) -> np.ndarray:\n",
    "        embed = 2 * self.vmax * (ids / (self.bins - 1)) - self.vmax\n",
    "        X = self.estimator.inverse_transform(embed)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.581, Val: 0.506\n"
     ]
    }
   ],
   "source": [
    "proj = PCA(n_components=32, whiten=True)\n",
    "tokenizer = PCATokenizer(proj, vmax=3.0, bins=1024)\n",
    "tokenizer.fit(train_timeseries)\n",
    "\n",
    "train_ids = tokenizer.transform(train_timeseries)\n",
    "train_recon = tokenizer.inverse_transform(train_ids)\n",
    "train_var = explained_variance_score(train_timeseries, train_recon)\n",
    "\n",
    "val_ids = tokenizer.transform(val_timeseries)\n",
    "val_recon = tokenizer.inverse_transform(val_ids)\n",
    "val_var = explained_variance_score(val_timeseries, val_recon)\n",
    "\n",
    "print(f\"Train: {train_var:.3f}, Val: {val_var:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
