out_dir: null

features:
  internvl3_8b/layers.20:
    model: internvl3_8b_8bit
    layer: language_model.model.layers.20.post_attention_layernorm
  
  internvl3_8b/layers.10:
    model: internvl3_8b_8bit
    layer: language_model.model.layers.10.post_attention_layernorm

  internvl3_14b/layers.30:
    model: InternVL3_14B
    layer: language_model.model.layers.30.post_attention_layernorm
  
  internvl3_8b_multiframe/layer.20:
    model: InternVL3_8B_multiframe
    layer: language_model.model.layers.20.post_attention_layernorm
    
  qwen-2-5-omni-7b/layers.20:
    model: qwen-2-5-omni-7b
    layer: model.layers.20.post_attention_layernorm
  
  qwen-2-5-omni-3b/layers.20:
    model: qwen2-5_3B
    layer: model.layers.20.post_attention_layernorm

  whisper/layers.12:
    model: whisper
    layer: layers.12.fc2
   
  whisper/layers.31:
    model: whisper
    layer: layers.31.fc2
  
  videomae2/model.blocks.25.mlp.fc2gp:
    model: videomae2
    layer: model.blocks.25.mlp.fc2gp
  
  videomae2/model.blocks.25.mlp.fc2avg:
    model: videomae2
    layer: model.blocks.25.mlp.fc2avg

  MFCC/audio:
    model: MFCC
    layer: audio
  
  bert-base-uncased/language_pooler_output: # Not sure why this is not working
    model: bert-base-uncased
    layer: language_pooler_output
  
  bert-base-uncased/language_last_hidden_state: # Not sure why this is not working
    model: bert-base-uncased
    layer: language_last_hidden_state
  
  modernBert/mean_pooling_output:
    model: modernBert
    layer: mean_pooling_output

  emonet/visual:
    model: emonet
    layer: visual
    stem: _20perTR

  llama_3.2_1B/layers.7:
    model: Llama-3.2-1B
    layer: model.layers.7

  llama_3.2_3B/layers.7:
    model: Llama-3.2-3B
    layer: model.layers.7

  llama_3.2_3B/layers.5:
    model: Llama-3.2-3B
    layer: model.layers.5

  llama_3.2_3B/layers.15:
    model: Llama-3.2-3B
    layer: model.layers.15
  
  llama_3.2_3B/layers.19:
    model: Llama-3.2-3B
    layer: model.layers.19
  
  llama_3.2_3B/layers.11:
    model: Llama-3.2-3B
    layer: model.layers.11

  llama_3.2_1b/layers.7:
    model: meta-llama__Llama-3.2-1B
    layer: model.layers.7
    stem: context-long
  
  llama_3.2_1b/layers.15:
    model: meta-llama__Llama-3.2-1B
    layer: model.layers.15
    stem: context-long

  dinov2/blocks.5:
    model: vit_giant_patch14_reg4_dinov2.lvd142m
    layer: blocks.5

  dinov2/blocks.15:
    model: vit_giant_patch14_reg4_dinov2.lvd142m
    layer: blocks.15

  dinov2/blocks.25:
    model: vit_giant_patch14_reg4_dinov2.lvd142m
    layer: blocks.25

  dinov2/blocks.35:
    model: vit_giant_patch14_reg4_dinov2.lvd142m
    layer: blocks.35

  dinov2/embedding:
    model: vit_giant_patch14_reg4_dinov2.lvd142m
    layer: embedding
  
  dinov2-giant/pooler_output:
    model: dinov2-giant
    layer: pooler_output
    
  vjepa2/encoder.layernorm_avg:
    model: vjepa2_avg_feat
    layer: encoder.layernorm_avg

include_features:
  - internvl3_8b/layers.20
  - whisper/layers.12
  - llama_3.2_1b/layers.7

test_set_name: ood

datasets_root: null

overwrite: false
device: cuda
