{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eff42bab-dca6-47c0-835b-648800c1b26a",
   "metadata": {},
   "source": [
    "# Setup (be sure to check which cuda:# gpu you are using!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5f1199e-a247-4c8a-a2de-f5f9ad59fa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from datetime import datetime\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import utility functions\n",
    "from utils import (\n",
    "    is_interactive,\n",
    "    to_builtin,\n",
    "    load_fmri, \n",
    "    align_features_and_fmri_samples,\n",
    "    calculate_metrics,\n",
    "    normalize_fmri,\n",
    "    check_fmri_stats,\n",
    "    load_friends_s7_features,\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "if is_interactive():\n",
    "    # Following allows you to change functions in other files and \n",
    "    # have this notebook automatically update with your revisions\n",
    "    get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "    get_ipython().run_line_magic('autoreload', '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2abaeb92-2f7f-42a4-aec0-dcd53d91e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK \"nvidia-smi\" IN TERMINAL AND PICK A GPU THAT IS NOT CURRENTLY ACTIVE\n",
    "device = torch.device('cuda:4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9960d98-07b7-4e12-bc10-07e0f3536306",
   "metadata": {},
   "source": [
    "# Defining dataset and model and additional utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34730a55-3528-4f7f-a6ab-63ca2aa9a5e0",
   "metadata": {},
   "source": [
    "## Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b9f269b-e590-4e77-808d-c1424eaa0b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlgonautsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for loading multimodal features and fMRI data.\n",
    "    \n",
    "    This dataset handles:\n",
    "    - Loading visual (InternVL) and audio (Whisper) features\n",
    "    - Aligning stimulus features with fMRI responses considering HRF delay\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        features_dir: Dict[str, Path],\n",
    "        fmri_dir: Path,\n",
    "        movies: List[str],\n",
    "        subject: int,\n",
    "        excluded_samples_start: int = 5,\n",
    "        excluded_samples_end: int = 5,\n",
    "        hrf_delay: int = 0,\n",
    "        stimulus_window: int = 12,\n",
    "        mean: Optional[np.ndarray] = None,\n",
    "        std: Optional[np.ndarray] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the dataset.\n",
    "        \n",
    "        Args:\n",
    "            features_dir: Dictionary mapping modality names to their feature directories\n",
    "            fmri_dir: Path to fMRI data directory\n",
    "            movies: List of movie identifiers to include\n",
    "            subject: Subject ID\n",
    "            excluded_samples_start: Number of initial TRs to exclude\n",
    "            excluded_samples_end: Number of final TRs to exclude\n",
    "            hrf_delay: Hemodynamic response function delay in TRs\n",
    "            stimulus_window: Number of feature chunks to use for modeling each TR\n",
    "            mean: Pre-computed mean for normalization (optional)\n",
    "            std: Pre-computed std for normalization (optional)\n",
    "        \"\"\"\n",
    "        self.features_dir = features_dir\n",
    "        self.fmri_dir = fmri_dir\n",
    "        self.movies = movies\n",
    "        self.subject = subject\n",
    "        self.excluded_samples_start = excluded_samples_start\n",
    "        self.excluded_samples_end = excluded_samples_end\n",
    "        self.hrf_delay = hrf_delay\n",
    "        self.stimulus_window = stimulus_window\n",
    "        \n",
    "        # Load stimulus features\n",
    "        print(f\"Loading stimulus features for subject {subject}...\")\n",
    "        self.stimuli_features = self._load_all_stimulus_features()\n",
    "        \n",
    "        # Load and align fMRI data\n",
    "        print(f\"Loading fMRI data for subject {subject}...\")\n",
    "        fmri_data = load_fmri(self.fmri_dir, subject)\n",
    "        \n",
    "        # Align features and fMRI\n",
    "        self.aligned_features, self.aligned_fmri = align_features_and_fmri_samples(\n",
    "            self.stimuli_features,\n",
    "            fmri_data,\n",
    "            self.excluded_samples_start,\n",
    "            self.excluded_samples_end,\n",
    "            self.hrf_delay,\n",
    "            self.stimulus_window,\n",
    "            self.movies\n",
    "        )\n",
    "        \n",
    "        # Compute or use provided normalization statistics\n",
    "        if mean is None and std is None:\n",
    "            print(\"Computing normalization statistics from training data...\")\n",
    "            _, self.mean, self.std = normalize_fmri(self.aligned_fmri)\n",
    "        else:\n",
    "            self.mean = mean\n",
    "            self.std = std\n",
    "        \n",
    "        # Print data statistics for debugging\n",
    "        check_fmri_stats(self.aligned_fmri, f\"Subject {subject} fMRI data\")\n",
    "        \n",
    "        print(f\"Dataset created: {len(self)} samples\")\n",
    "        print(f\"fMRI shape: {self.aligned_fmri.shape}\")\n",
    "    \n",
    "    def _load_all_stimulus_features(self) -> Dict[str, Dict[str, np.ndarray]]:\n",
    "        \"\"\"Load all stimulus features for the specified movies.\"\"\"\n",
    "        features = defaultdict(dict)\n",
    "        \n",
    "        for movie in self.movies:\n",
    "            if 'friends' in movie:\n",
    "                self._load_friends_features(movie, features)\n",
    "            else:\n",
    "                self._load_movie10_features(movie, features)\n",
    "        \n",
    "        # Remove language features since we're not using them\n",
    "        if 'language' in features:\n",
    "            del features['language']\n",
    "        \n",
    "        return dict(features)\n",
    "    \n",
    "    def _load_friends_features(self, movie: str, features: Dict):\n",
    "        \"\"\"Load features for Friends episodes.\"\"\"\n",
    "        season = movie.split('-')[1]\n",
    "        \n",
    "        # Load visual and audio features\n",
    "        audio_dir = self.features_dir['audio'] / 'audio'\n",
    "        episode_files = sorted([f for f in os.listdir(audio_dir) \n",
    "                               if f\"{season}e\" in f and '_features_' in f])\n",
    "        \n",
    "        for episode_file in episode_files:\n",
    "            episode_base = episode_file.split('_features_')[0]\n",
    "            episode_key = episode_base.split('_')[1]\n",
    "            \n",
    "            # Visual features\n",
    "            visual_path = self.features_dir['visual'] / 'visual' / f\"{episode_base}_features_visual.h5\"\n",
    "            with h5py.File(visual_path, 'r') as f:\n",
    "                features['visual'][episode_key] = f['language_model.model.layers.20.post_attention_layernorm'][:]\n",
    "            \n",
    "            # Audio features\n",
    "            audio_path = self.features_dir['audio'] / 'audio' / f\"{episode_base}_features_audio.h5\"\n",
    "            with h5py.File(audio_path, 'r') as f:\n",
    "                features['audio'][episode_key] = f['layers.12.fc2'][:]\n",
    "    \n",
    "    def _load_movie10_features(self, movie: str, features: Dict):\n",
    "        \"\"\"Load features for movie10 clips.\"\"\"\n",
    "        movie_name = movie.replace('movie10-', '')\n",
    "        \n",
    "        # Visual and audio features\n",
    "        audio_dir = self.features_dir['audio'] / 'audio'\n",
    "        partitions = sorted([f for f in os.listdir(audio_dir) \n",
    "                           if movie_name in f and '_features_' in f])\n",
    "        \n",
    "        for partition in partitions:\n",
    "            partition_base = partition.split('_features_')[0]\n",
    "            \n",
    "            # Visual features\n",
    "            visual_path = self.features_dir['visual'] / 'visual' / f\"{partition_base}_features_visual.h5\"\n",
    "            with h5py.File(visual_path, 'r') as f:\n",
    "                features['visual'][partition_base] = f['language_model.model.layers.20.post_attention_layernorm'][:]\n",
    "            \n",
    "            # Audio features\n",
    "            audio_path = self.features_dir['audio'] / 'audio' / f\"{partition_base}_features_audio.h5\"\n",
    "            with h5py.File(audio_path, 'r') as f:\n",
    "                features['audio'][partition_base] = f['layers.12.fc2'][:]\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.aligned_fmri.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        return {\n",
    "            'audio': torch.from_numpy(self.aligned_features['audio'][idx]).float(),\n",
    "            'video': torch.from_numpy(self.aligned_features['visual'][idx]).float(),\n",
    "            'fmri': torch.from_numpy(self.aligned_fmri[idx]).float()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b560b09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AudioVisualfMRIModel(\n",
       "  (vision_proj): Sequential(\n",
       "    (0): Linear(in_features=3584, out_features=1024, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (audio_proj): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=1024, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  )\n",
       "  (av_fusion): AudioVisualFusion(\n",
       "    (vision_audio_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (audio_vision_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (av_fusion_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (av_ffn): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Dropout(p=0.2, inplace=False)\n",
       "      (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (temporal_processor): TemporalProcessor(\n",
       "    (post_process): Sequential(\n",
       "      (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (temporal_aggregation): Linear(in_features=15, out_features=1, bias=True)\n",
       "  )\n",
       "  (fmri_proj): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Dropout(p=0.4, inplace=False)\n",
       "    (3): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from algo_mihir_replication import AudioVisualfMRIModel\n",
    "\n",
    "ckpt = \"/home/mihir/projects/algonauts2025/checkpoints/ALLDATAav_sub1_hrf0_sw15_20250624_000323/last.ckpt\"\n",
    "model_config = {\n",
    "        'latent_dim': 1024,\n",
    "        'vision_proj_dim': 1024,\n",
    "        'audio_proj_dim': 1024,\n",
    "        'dropout_prob': 0.4,\n",
    "        'encoder_dropout_prob': 0.2,\n",
    "        'num_attn_heads': 8,\n",
    "        'stimulus_window': 15,\n",
    "        'learning_rate': 1e-5,\n",
    "        'weight_decay': 0.04,\n",
    "        'alpha': 0.8\n",
    "    }\n",
    "model = AudioVisualfMRIModel.load_from_checkpoint(ckpt, config=model_config, strict=True)\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4a33c1-cb14-44fa-a15a-d7cc548d26c8",
   "metadata": {},
   "source": [
    "# Create submission entry for leaderboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10c518db-0e05-4b1a-a740-7098f8b89d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    load_friends_s7_features,\n",
    "    align_features_and_fmri_samples_friends_s7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24444a7a-eb62-44ba-a598-6366e6f63362",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_root_dir = Path.cwd()\n",
    "mihir_dir =  Path('/home/mihir/projects/')\n",
    "\n",
    "# Feature directories (no language features)\n",
    "features_dir = {\n",
    "    \"visual\": mihir_dir / 'datasets' / \"InternVL3_feat\",\n",
    "    \"audio\": mihir_dir / 'datasets' / 'whisper_feat' / 'whisper'\n",
    "}\n",
    "\n",
    "fmri_dir = mihir_dir / 'datasets' / 'algonauts_2025.competitors' / 'fmri'\n",
    "\n",
    "# Verify paths exist\n",
    "for name, path in features_dir.items():\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"{name} features directory not found: {path}\")\n",
    "if not fmri_dir.exists():\n",
    "    raise FileNotFoundError(f\"fMRI directory not found: {fmri_dir}\")\n",
    "features_s7 = load_friends_s7_features(features_dir, use_language=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb0318e3-366d-47e5-91fb-10ca4561241b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning stimulus and fMRI features of the four subjects:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning stimulus and fMRI features of the four subjects: 100%|██████████| 4/4 [01:06<00:00, 16.71s/it]\n"
     ]
    }
   ],
   "source": [
    "aligned_features_s7 = align_features_and_fmri_samples_friends_s7(\n",
    "    features_s7,\n",
    "    str(fmri_dir),  \n",
    "    hrf_delay=0,\n",
    "    stimulus_window=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b10b199-27e7-4061-b7e9-d2e7c5034091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating predictions for sub-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes for sub-01:   0%|          | 0/49 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes for sub-01: 100%|██████████| 49/49 [00:02<00:00, 23.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating predictions for sub-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes for sub-02: 100%|██████████| 49/49 [00:02<00:00, 22.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating predictions for sub-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes for sub-03: 100%|██████████| 49/49 [00:02<00:00, 22.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating predictions for sub-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes for sub-05: 100%|██████████| 49/49 [00:02<00:00, 21.89it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = {}\n",
    "subjects = [1, 2, 3, 5]\n",
    "batch_size = 32\n",
    "\n",
    "with torch.no_grad():\n",
    "    for subject in subjects:\n",
    "        subject_key = f\"sub-0{subject}\"\n",
    "        predictions[subject_key] = {}\n",
    "        \n",
    "        print(f\"\\nGenerating predictions for {subject_key}\")\n",
    "        \n",
    "        for episode in tqdm(aligned_features_s7[subject_key].keys(), desc=f\"Episodes for {subject_key}\"):\n",
    "            episode_features = aligned_features_s7[subject_key][episode]\n",
    "            num_samples = episode_features['visual'].shape[0]\n",
    "            \n",
    "            # Process in batches\n",
    "            all_predictions = []\n",
    "            \n",
    "            for i in range(0, num_samples, batch_size):\n",
    "                end_idx = min(i + batch_size, num_samples)\n",
    "                batch_size_actual = end_idx - i\n",
    "                \n",
    "                # Prepare batch\n",
    "                video_batch = torch.from_numpy(\n",
    "                    episode_features['visual'][i:end_idx]\n",
    "                ).float().to(device)\n",
    "                \n",
    "                audio_batch = torch.from_numpy(\n",
    "                    episode_features['audio'][i:end_idx]\n",
    "                ).float().to(device)\n",
    "                \n",
    "                # language_batch = torch.from_numpy(\n",
    "                #     episode_features['language'][i:end_idx]\n",
    "                # ).float().to(device)\n",
    "                \n",
    "                subject_ids = torch.tensor([subject] * batch_size_actual).to(device)\n",
    "                \n",
    "                # Generate predictions\n",
    "                batch_predictions = model(\n",
    "                    video_batch, audio_batch,\n",
    "                )\n",
    "                # batch_predictions = model(\n",
    "                #     video_batch, audio_batch, language_batch, subject_ids\n",
    "                # )\n",
    "                \n",
    "                all_predictions.append(batch_predictions.cpu().numpy())\n",
    "            \n",
    "            # Concatenate all predictions for this episode\n",
    "            episode_predictions = np.concatenate(all_predictions, axis=0)\n",
    "            \n",
    "            # Store as float32 to reduce file size\n",
    "            predictions[subject_key][episode] = episode_predictions.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "846044d8-b54c-423f-b621-f29cd8104abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving predictions to /home/mihir/projects/algonauts2025/saved_preds/av_sw15_hrf0\n",
      "\n",
      "Verifying output format:\n",
      "\n",
      "sub-01:\n",
      "  s07e01a: shape (460, 1000), dtype float32, size 1.75 MB\n",
      "  s07e01b: shape (494, 1000), dtype float32, size 1.88 MB\n",
      "  s07e02a: shape (492, 1000), dtype float32, size 1.88 MB\n",
      "  s07e02b: shape (526, 1000), dtype float32, size 2.01 MB\n",
      "  s07e03a: shape (417, 1000), dtype float32, size 1.59 MB\n",
      "  s07e03b: shape (452, 1000), dtype float32, size 1.72 MB\n",
      "  s07e04a: shape (447, 1000), dtype float32, size 1.71 MB\n",
      "  s07e04b: shape (482, 1000), dtype float32, size 1.84 MB\n",
      "  s07e05a: shape (454, 1000), dtype float32, size 1.73 MB\n",
      "  s07e05b: shape (488, 1000), dtype float32, size 1.86 MB\n",
      "  s07e06a: shape (478, 1000), dtype float32, size 1.82 MB\n",
      "  s07e06b: shape (513, 1000), dtype float32, size 1.96 MB\n",
      "  s07e07a: shape (473, 1000), dtype float32, size 1.80 MB\n",
      "  s07e07b: shape (507, 1000), dtype float32, size 1.93 MB\n",
      "  s07e08a: shape (474, 1000), dtype float32, size 1.81 MB\n",
      "  s07e08b: shape (509, 1000), dtype float32, size 1.94 MB\n",
      "  s07e09a: shape (450, 1000), dtype float32, size 1.72 MB\n",
      "  s07e09b: shape (484, 1000), dtype float32, size 1.85 MB\n",
      "  s07e10a: shape (459, 1000), dtype float32, size 1.75 MB\n",
      "  s07e10b: shape (493, 1000), dtype float32, size 1.88 MB\n",
      "  s07e11a: shape (464, 1000), dtype float32, size 1.77 MB\n",
      "  s07e11b: shape (498, 1000), dtype float32, size 1.90 MB\n",
      "  s07e12a: shape (452, 1000), dtype float32, size 1.72 MB\n",
      "  s07e12b: shape (486, 1000), dtype float32, size 1.85 MB\n",
      "  s07e13a: shape (539, 1000), dtype float32, size 2.06 MB\n",
      "  s07e13b: shape (574, 1000), dtype float32, size 2.19 MB\n",
      "  s07e14a: shape (466, 1000), dtype float32, size 1.78 MB\n",
      "  s07e14b: shape (500, 1000), dtype float32, size 1.91 MB\n",
      "  s07e15a: shape (566, 1000), dtype float32, size 2.16 MB\n",
      "  s07e15b: shape (600, 1000), dtype float32, size 2.29 MB\n",
      "  s07e16a: shape (398, 1000), dtype float32, size 1.52 MB\n",
      "  s07e16b: shape (402, 1000), dtype float32, size 1.53 MB\n",
      "  s07e16c: shape (432, 1000), dtype float32, size 1.65 MB\n",
      "  s07e17a: shape (433, 1000), dtype float32, size 1.65 MB\n",
      "  s07e17b: shape (467, 1000), dtype float32, size 1.78 MB\n",
      "  s07e18a: shape (477, 1000), dtype float32, size 1.82 MB\n",
      "  s07e18b: shape (511, 1000), dtype float32, size 1.95 MB\n",
      "  s07e19a: shape (437, 1000), dtype float32, size 1.67 MB\n",
      "  s07e19b: shape (471, 1000), dtype float32, size 1.80 MB\n",
      "  s07e20a: shape (454, 1000), dtype float32, size 1.73 MB\n",
      "  s07e20b: shape (488, 1000), dtype float32, size 1.86 MB\n",
      "  s07e21a: shape (429, 1000), dtype float32, size 1.64 MB\n",
      "  s07e21b: shape (464, 1000), dtype float32, size 1.77 MB\n",
      "  s07e22a: shape (471, 1000), dtype float32, size 1.80 MB\n",
      "  s07e22b: shape (505, 1000), dtype float32, size 1.93 MB\n",
      "  s07e23a: shape (480, 1000), dtype float32, size 1.83 MB\n",
      "  s07e23b: shape (484, 1000), dtype float32, size 1.85 MB\n",
      "  s07e23c: shape (484, 1000), dtype float32, size 1.85 MB\n",
      "  s07e23d: shape (515, 1000), dtype float32, size 1.96 MB\n",
      "  Total for sub-01: 89.64 MB\n",
      "\n",
      "sub-02:\n",
      "  s07e01a: shape (460, 1000), dtype float32, size 1.75 MB\n",
      "  s07e01b: shape (494, 1000), dtype float32, size 1.88 MB\n",
      "  s07e02a: shape (492, 1000), dtype float32, size 1.88 MB\n",
      "  s07e02b: shape (526, 1000), dtype float32, size 2.01 MB\n",
      "  s07e03a: shape (417, 1000), dtype float32, size 1.59 MB\n",
      "  s07e03b: shape (417, 1000), dtype float32, size 1.59 MB\n",
      "  s07e04a: shape (447, 1000), dtype float32, size 1.71 MB\n",
      "  s07e04b: shape (482, 1000), dtype float32, size 1.84 MB\n",
      "  s07e05a: shape (454, 1000), dtype float32, size 1.73 MB\n",
      "  s07e05b: shape (488, 1000), dtype float32, size 1.86 MB\n",
      "  s07e06a: shape (478, 1000), dtype float32, size 1.82 MB\n",
      "  s07e06b: shape (513, 1000), dtype float32, size 1.96 MB\n",
      "  s07e07a: shape (473, 1000), dtype float32, size 1.80 MB\n",
      "  s07e07b: shape (507, 1000), dtype float32, size 1.93 MB\n",
      "  s07e08a: shape (474, 1000), dtype float32, size 1.81 MB\n",
      "  s07e08b: shape (509, 1000), dtype float32, size 1.94 MB\n",
      "  s07e09a: shape (450, 1000), dtype float32, size 1.72 MB\n",
      "  s07e09b: shape (484, 1000), dtype float32, size 1.85 MB\n",
      "  s07e10a: shape (459, 1000), dtype float32, size 1.75 MB\n",
      "  s07e10b: shape (493, 1000), dtype float32, size 1.88 MB\n",
      "  s07e11a: shape (464, 1000), dtype float32, size 1.77 MB\n",
      "  s07e11b: shape (498, 1000), dtype float32, size 1.90 MB\n",
      "  s07e12a: shape (452, 1000), dtype float32, size 1.72 MB\n",
      "  s07e12b: shape (486, 1000), dtype float32, size 1.85 MB\n",
      "  s07e13a: shape (539, 1000), dtype float32, size 2.06 MB\n",
      "  s07e13b: shape (574, 1000), dtype float32, size 2.19 MB\n",
      "  s07e14a: shape (466, 1000), dtype float32, size 1.78 MB\n",
      "  s07e14b: shape (500, 1000), dtype float32, size 1.91 MB\n",
      "  s07e15a: shape (566, 1000), dtype float32, size 2.16 MB\n",
      "  s07e15b: shape (600, 1000), dtype float32, size 2.29 MB\n",
      "  s07e16a: shape (398, 1000), dtype float32, size 1.52 MB\n",
      "  s07e16b: shape (402, 1000), dtype float32, size 1.53 MB\n",
      "  s07e16c: shape (432, 1000), dtype float32, size 1.65 MB\n",
      "  s07e17a: shape (433, 1000), dtype float32, size 1.65 MB\n",
      "  s07e17b: shape (467, 1000), dtype float32, size 1.78 MB\n",
      "  s07e18a: shape (477, 1000), dtype float32, size 1.82 MB\n",
      "  s07e18b: shape (511, 1000), dtype float32, size 1.95 MB\n",
      "  s07e19a: shape (437, 1000), dtype float32, size 1.67 MB\n",
      "  s07e19b: shape (471, 1000), dtype float32, size 1.80 MB\n",
      "  s07e20a: shape (454, 1000), dtype float32, size 1.73 MB\n",
      "  s07e20b: shape (488, 1000), dtype float32, size 1.86 MB\n",
      "  s07e21a: shape (429, 1000), dtype float32, size 1.64 MB\n",
      "  s07e21b: shape (464, 1000), dtype float32, size 1.77 MB\n",
      "  s07e22a: shape (471, 1000), dtype float32, size 1.80 MB\n",
      "  s07e22b: shape (505, 1000), dtype float32, size 1.93 MB\n",
      "  s07e23a: shape (480, 1000), dtype float32, size 1.83 MB\n",
      "  s07e23b: shape (484, 1000), dtype float32, size 1.85 MB\n",
      "  s07e23c: shape (484, 1000), dtype float32, size 1.85 MB\n",
      "  s07e23d: shape (515, 1000), dtype float32, size 1.96 MB\n",
      "  Total for sub-02: 89.51 MB\n",
      "\n",
      "sub-03:\n",
      "  s07e01a: shape (460, 1000), dtype float32, size 1.75 MB\n",
      "  s07e01b: shape (494, 1000), dtype float32, size 1.88 MB\n",
      "  s07e02a: shape (492, 1000), dtype float32, size 1.88 MB\n",
      "  s07e02b: shape (526, 1000), dtype float32, size 2.01 MB\n",
      "  s07e03a: shape (417, 1000), dtype float32, size 1.59 MB\n",
      "  s07e03b: shape (452, 1000), dtype float32, size 1.72 MB\n",
      "  s07e04a: shape (447, 1000), dtype float32, size 1.71 MB\n",
      "  s07e04b: shape (482, 1000), dtype float32, size 1.84 MB\n",
      "  s07e05a: shape (454, 1000), dtype float32, size 1.73 MB\n",
      "  s07e05b: shape (488, 1000), dtype float32, size 1.86 MB\n",
      "  s07e06a: shape (478, 1000), dtype float32, size 1.82 MB\n",
      "  s07e06b: shape (513, 1000), dtype float32, size 1.96 MB\n",
      "  s07e07a: shape (473, 1000), dtype float32, size 1.80 MB\n",
      "  s07e07b: shape (507, 1000), dtype float32, size 1.93 MB\n",
      "  s07e08a: shape (474, 1000), dtype float32, size 1.81 MB\n",
      "  s07e08b: shape (509, 1000), dtype float32, size 1.94 MB\n",
      "  s07e09a: shape (450, 1000), dtype float32, size 1.72 MB\n",
      "  s07e09b: shape (484, 1000), dtype float32, size 1.85 MB\n",
      "  s07e10a: shape (459, 1000), dtype float32, size 1.75 MB\n",
      "  s07e10b: shape (493, 1000), dtype float32, size 1.88 MB\n",
      "  s07e11a: shape (464, 1000), dtype float32, size 1.77 MB\n",
      "  s07e11b: shape (498, 1000), dtype float32, size 1.90 MB\n",
      "  s07e12a: shape (452, 1000), dtype float32, size 1.72 MB\n",
      "  s07e12b: shape (486, 1000), dtype float32, size 1.85 MB\n",
      "  s07e13a: shape (539, 1000), dtype float32, size 2.06 MB\n",
      "  s07e13b: shape (574, 1000), dtype float32, size 2.19 MB\n",
      "  s07e14a: shape (466, 1000), dtype float32, size 1.78 MB\n",
      "  s07e14b: shape (500, 1000), dtype float32, size 1.91 MB\n",
      "  s07e15a: shape (566, 1000), dtype float32, size 2.16 MB\n",
      "  s07e15b: shape (600, 1000), dtype float32, size 2.29 MB\n",
      "  s07e16a: shape (398, 1000), dtype float32, size 1.52 MB\n",
      "  s07e16b: shape (402, 1000), dtype float32, size 1.53 MB\n",
      "  s07e16c: shape (432, 1000), dtype float32, size 1.65 MB\n",
      "  s07e17a: shape (433, 1000), dtype float32, size 1.65 MB\n",
      "  s07e17b: shape (467, 1000), dtype float32, size 1.78 MB\n",
      "  s07e18a: shape (477, 1000), dtype float32, size 1.82 MB\n",
      "  s07e18b: shape (511, 1000), dtype float32, size 1.95 MB\n",
      "  s07e19a: shape (437, 1000), dtype float32, size 1.67 MB\n",
      "  s07e19b: shape (471, 1000), dtype float32, size 1.80 MB\n",
      "  s07e20a: shape (454, 1000), dtype float32, size 1.73 MB\n",
      "  s07e20b: shape (488, 1000), dtype float32, size 1.86 MB\n",
      "  s07e21a: shape (429, 1000), dtype float32, size 1.64 MB\n",
      "  s07e21b: shape (464, 1000), dtype float32, size 1.77 MB\n",
      "  s07e22a: shape (471, 1000), dtype float32, size 1.80 MB\n",
      "  s07e22b: shape (505, 1000), dtype float32, size 1.93 MB\n",
      "  s07e23a: shape (480, 1000), dtype float32, size 1.83 MB\n",
      "  s07e23b: shape (484, 1000), dtype float32, size 1.85 MB\n",
      "  s07e23c: shape (484, 1000), dtype float32, size 1.85 MB\n",
      "  s07e23d: shape (515, 1000), dtype float32, size 1.96 MB\n",
      "  Total for sub-03: 89.64 MB\n",
      "\n",
      "sub-05:\n",
      "  s07e01a: shape (460, 1000), dtype float32, size 1.75 MB\n",
      "  s07e01b: shape (494, 1000), dtype float32, size 1.88 MB\n",
      "  s07e02a: shape (492, 1000), dtype float32, size 1.88 MB\n",
      "  s07e02b: shape (526, 1000), dtype float32, size 2.01 MB\n",
      "  s07e03a: shape (417, 1000), dtype float32, size 1.59 MB\n",
      "  s07e03b: shape (452, 1000), dtype float32, size 1.72 MB\n",
      "  s07e04a: shape (447, 1000), dtype float32, size 1.71 MB\n",
      "  s07e04b: shape (482, 1000), dtype float32, size 1.84 MB\n",
      "  s07e05a: shape (454, 1000), dtype float32, size 1.73 MB\n",
      "  s07e05b: shape (488, 1000), dtype float32, size 1.86 MB\n",
      "  s07e06a: shape (478, 1000), dtype float32, size 1.82 MB\n",
      "  s07e06b: shape (513, 1000), dtype float32, size 1.96 MB\n",
      "  s07e07a: shape (473, 1000), dtype float32, size 1.80 MB\n",
      "  s07e07b: shape (507, 1000), dtype float32, size 1.93 MB\n",
      "  s07e08a: shape (474, 1000), dtype float32, size 1.81 MB\n",
      "  s07e08b: shape (509, 1000), dtype float32, size 1.94 MB\n",
      "  s07e09a: shape (450, 1000), dtype float32, size 1.72 MB\n",
      "  s07e09b: shape (484, 1000), dtype float32, size 1.85 MB\n",
      "  s07e10a: shape (459, 1000), dtype float32, size 1.75 MB\n",
      "  s07e10b: shape (493, 1000), dtype float32, size 1.88 MB\n",
      "  s07e11a: shape (464, 1000), dtype float32, size 1.77 MB\n",
      "  s07e11b: shape (498, 1000), dtype float32, size 1.90 MB\n",
      "  s07e12a: shape (452, 1000), dtype float32, size 1.72 MB\n",
      "  s07e12b: shape (486, 1000), dtype float32, size 1.85 MB\n",
      "  s07e13a: shape (539, 1000), dtype float32, size 2.06 MB\n",
      "  s07e13b: shape (574, 1000), dtype float32, size 2.19 MB\n",
      "  s07e14a: shape (466, 1000), dtype float32, size 1.78 MB\n",
      "  s07e14b: shape (500, 1000), dtype float32, size 1.91 MB\n",
      "  s07e15a: shape (566, 1000), dtype float32, size 2.16 MB\n",
      "  s07e15b: shape (600, 1000), dtype float32, size 2.29 MB\n",
      "  s07e16a: shape (398, 1000), dtype float32, size 1.52 MB\n",
      "  s07e16b: shape (402, 1000), dtype float32, size 1.53 MB\n",
      "  s07e16c: shape (432, 1000), dtype float32, size 1.65 MB\n",
      "  s07e17a: shape (433, 1000), dtype float32, size 1.65 MB\n",
      "  s07e17b: shape (467, 1000), dtype float32, size 1.78 MB\n",
      "  s07e18a: shape (477, 1000), dtype float32, size 1.82 MB\n",
      "  s07e18b: shape (511, 1000), dtype float32, size 1.95 MB\n",
      "  s07e19a: shape (437, 1000), dtype float32, size 1.67 MB\n",
      "  s07e19b: shape (471, 1000), dtype float32, size 1.80 MB\n",
      "  s07e20a: shape (454, 1000), dtype float32, size 1.73 MB\n",
      "  s07e20b: shape (488, 1000), dtype float32, size 1.86 MB\n",
      "  s07e21a: shape (429, 1000), dtype float32, size 1.64 MB\n",
      "  s07e21b: shape (464, 1000), dtype float32, size 1.77 MB\n",
      "  s07e22a: shape (471, 1000), dtype float32, size 1.80 MB\n",
      "  s07e22b: shape (505, 1000), dtype float32, size 1.93 MB\n",
      "  s07e23a: shape (480, 1000), dtype float32, size 1.83 MB\n",
      "  s07e23b: shape (484, 1000), dtype float32, size 1.85 MB\n",
      "  s07e23c: shape (484, 1000), dtype float32, size 1.85 MB\n",
      "  s07e23d: shape (515, 1000), dtype float32, size 1.96 MB\n",
      "  Total for sub-05: 89.64 MB\n",
      "\n",
      "Prediction statistics:\n",
      "  Mean: -0.0002\n",
      "  Std: 0.2287\n",
      "  Min: -3.0238\n",
      "  Max: 2.4916\n",
      "\n",
      "Total file size: 358.43 MB\n",
      "\n",
      "Submission file created successfully!\n",
      "\n",
      "Next steps:\n",
      "1. Create zip file: zip -j av_sw15_hrf0.zip /home/mihir/projects/algonauts2025/saved_preds/av_sw15_hrf0/av_sw15_hrf0.npy\n",
      "2. Check zip size is under 15GB\n",
      "3. Upload to Codabench 'My Submissions' page\n",
      "4. Wait for processing (~few minutes)\n",
      "5. Check 'Results' page for leaderboard ranking\n",
      "\n",
      "Good luck!\n"
     ]
    }
   ],
   "source": [
    "# Save predictions\n",
    "exp_name = 'av_sw15_hrf0'\n",
    "submission_dir = Path('/home/mihir/projects/algonauts2025/saved_preds') / exp_name\n",
    "submission_npy = str(submission_dir)+f\"/{exp_name}.npy\"\n",
    "submission_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"\\nSaving predictions to {submission_dir}\")\n",
    "np.save(submission_npy, predictions)\n",
    "\n",
    "# Verify output format\n",
    "print(\"\\nVerifying output format:\")\n",
    "loaded_predictions = np.load(submission_npy, allow_pickle=True).item()\n",
    "\n",
    "total_size = 0\n",
    "all_predictions_flat = []\n",
    "\n",
    "for subject in [\"sub-01\", \"sub-02\", \"sub-03\", \"sub-05\"]:\n",
    "    if subject in loaded_predictions:\n",
    "        print(f\"\\n{subject}:\")\n",
    "        subject_size = 0\n",
    "        for episode, preds in loaded_predictions[subject].items():\n",
    "            episode_size = preds.nbytes / (1024 * 1024)  # Size in MB\n",
    "            subject_size += episode_size\n",
    "            print(f\"  {episode}: shape {preds.shape}, dtype {preds.dtype}, size {episode_size:.2f} MB\")\n",
    "            all_predictions_flat.extend(preds.flatten())\n",
    "        print(f\"  Total for {subject}: {subject_size:.2f} MB\")\n",
    "        total_size += subject_size\n",
    "    else:\n",
    "        print(f\"\\nWARNING: {subject} missing from predictions!\")\n",
    "\n",
    "# Check prediction statistics\n",
    "all_predictions_flat = np.array(all_predictions_flat)\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(f\"  Mean: {np.mean(all_predictions_flat):.4f}\")\n",
    "print(f\"  Std: {np.std(all_predictions_flat):.4f}\")\n",
    "print(f\"  Min: {np.min(all_predictions_flat):.4f}\")\n",
    "print(f\"  Max: {np.max(all_predictions_flat):.4f}\")\n",
    "\n",
    "print(f\"\\nTotal file size: {total_size:.2f} MB\")\n",
    "print(\"\\nSubmission file created successfully!\")\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"1. Create zip file: zip -j {exp_name}.zip {submission_npy}\")\n",
    "print(f\"2. Check zip size is under 15GB\")\n",
    "print(f\"3. Upload to Codabench 'My Submissions' page\")\n",
    "print(f\"4. Wait for processing (~few minutes)\")\n",
    "print(f\"5. Check 'Results' page for leaderboard ranking\")\n",
    "print(f\"\\nGood luck!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e122ba7a-3aa3-4015-9f7a-1d77495a84a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "inf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
