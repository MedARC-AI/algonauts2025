{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ea3101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f0d4e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECTS = (1, 2, 3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "080b0243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving output to: /home/connor/algonauts2025/feature_encoding/output/feature_encoding_v1\n"
     ]
    }
   ],
   "source": [
    "root_dir = Path(\"..\").resolve()\n",
    "\n",
    "data_dir = root_dir / \"algonauts_2025.competitors\"\n",
    "\n",
    "out_dir = Path(\".\") / \"output/feature_encoding_v1\"\n",
    "out_dir.mkdir(exist_ok=True, parents=True)\n",
    "print(\"Saving output to:\", out_dir.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfac842a",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "Aligned cross-subject fmri data loader. The data loader samples clips of synchronized activity from the same friends episodes across subjects. Each clip is shape `(n_subs, sample_length, dim)`.\n",
    "\n",
    "We also load pre-extracted features of the shape `(sample_length, dim)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ace3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_friends_run(run: str):\n",
    "    match = re.match(r\"s([0-9]+)e([0-9]+)([a-z])\", run)\n",
    "    if match is None:\n",
    "        raise ValueError(f\"Invalid friends run {run}\")\n",
    "\n",
    "    season = int(match.group(1))\n",
    "    episode = int(match.group(2))\n",
    "    part = match.group(3)\n",
    "    return season, episode, part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82dba735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_algonauts2025_friends_fmri(\n",
    "    root: str | Path,\n",
    "    subjects: list[int] | None = None,\n",
    "    seasons: list[int] | None = None,\n",
    ") -> dict[str, np.ndarray]:\n",
    "    subjects = subjects or SUBJECTS\n",
    "    seasons = seasons or list(range(1, 7))\n",
    "\n",
    "    files = {\n",
    "        sub: h5py.File(\n",
    "            Path(root)\n",
    "            / f\"fmri/sub-{sub:02d}/func\"\n",
    "            / f\"sub-{sub:02d}_task-friends_space-MNI152NLin2009cAsym_atlas-Schaefer18_parcel-1000Par7Net_desc-s123456_bold.h5\"\n",
    "        )\n",
    "        for sub in subjects\n",
    "    }\n",
    "\n",
    "    episode_key_maps = defaultdict(dict)\n",
    "    seasons_set = set(seasons)\n",
    "    for sub, file in files.items():\n",
    "        for key in file.keys():\n",
    "            entities = dict([ent.split(\"-\", 1) for ent in key.split(\"_\")])\n",
    "            episode = entities[\"task\"]\n",
    "            season, _, _ = parse_friends_run(episode)\n",
    "            if season in seasons_set:\n",
    "                episode_key_maps[episode][sub] = key\n",
    "\n",
    "    episode_list = sorted(\n",
    "        [\n",
    "            episode for episode, map in episode_key_maps.items()\n",
    "            if len(map) == len(subjects)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    data = {}\n",
    "    for episode in episode_list:\n",
    "        samples = []\n",
    "        length = None\n",
    "        for sub in subjects:\n",
    "            key = episode_key_maps[episode][sub]\n",
    "            sample = files[sub][key][:]\n",
    "            sub_length = len(sample)\n",
    "            samples.append(sample)\n",
    "            length = min(length, sub_length) if length else sub_length\n",
    "        data[episode] = np.stack([sample[:length] for sample in samples])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39af2de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_movie10_run(run: str):\n",
    "    match = re.match(r\"([a-z]+)([0-9]+)\", run)\n",
    "    if match is None:\n",
    "        raise ValueError(f\"Invalid movie run {run}\")\n",
    "\n",
    "    movie = match.group(1)\n",
    "    part = int(match.group(2))\n",
    "    return movie, part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "086c74f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_algonauts2025_movie10_fmri(\n",
    "    root: str | Path,\n",
    "    subjects: list[int] | None = None,\n",
    "    movies: list[str] | None = None,\n",
    "    runs: list[int] | None = None,\n",
    ") -> dict[str, np.ndarray]:\n",
    "    subjects = subjects or SUBJECTS\n",
    "    movies = movies or [\"bourne\", \"wolf\", \"figures\", \"life\"]\n",
    "    runs = runs or [1, 2]\n",
    "\n",
    "    files = {\n",
    "        sub: h5py.File(\n",
    "            Path(root)\n",
    "            / f\"fmri/sub-{sub:02d}/func\"\n",
    "            / f\"sub-{sub:02d}_task-movie10_space-MNI152NLin2009cAsym_atlas-Schaefer18_parcel-1000Par7Net_bold.h5\"\n",
    "        )\n",
    "        for sub in subjects\n",
    "    }\n",
    "\n",
    "    episode_key_maps = defaultdict(dict)\n",
    "    movies_set = set(movies)\n",
    "    for sub, file in files.items():\n",
    "        for key in file.keys():\n",
    "            entities = dict([ent.split(\"-\", 1) for ent in key.split(\"_\")])\n",
    "            episode = entities[\"task\"]\n",
    "            run = int(entities.get(\"run\", 1))\n",
    "            movie, _ = parse_movie10_run(episode)\n",
    "            if movie in movies_set and run in runs:\n",
    "                episode_key_maps[(episode, run)][sub] = key\n",
    "\n",
    "    episode_list = sorted(\n",
    "        [\n",
    "            episode for episode, map in episode_key_maps.items()\n",
    "            if len(map) == len(subjects)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    data = {}\n",
    "    for episode in episode_list:\n",
    "        samples = []\n",
    "        length = None\n",
    "        for sub in subjects:\n",
    "            key = episode_key_maps[episode][sub]\n",
    "            sample = files[sub][key][:]\n",
    "            sub_length = len(sample)\n",
    "            samples.append(sample)\n",
    "            length = min(length, sub_length) if length else sub_length\n",
    "        data[episode] = np.stack([sample[:length] for sample in samples])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2ec5e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "friends_train_fmri = load_algonauts2025_friends_fmri(data_dir, seasons=range(1, 6))\n",
    "friends_val_fmri = load_algonauts2025_friends_fmri(data_dir, seasons=[6])\n",
    "movie10_test_fmri = load_algonauts2025_movie10_fmri(data_dir, runs=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c5bfb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['s01e01a', 's01e01b', 's01e02a', 's01e02b', 's01e03a', 's01e03b', 's01e04a', 's01e04b', 's01e05a', 's01e05b', 's01e06a', 's01e06b', 's01e07a', 's01e07b', 's01e08a', 's01e08b', 's01e09a', 's01e09b', 's01e10a', 's01e10b', 's01e11a', 's01e11b', 's01e12a', 's01e12b', 's01e13a', 's01e13b', 's01e14a', 's01e14b', 's01e15a', 's01e15b', 's01e16a', 's01e16b', 's01e17a', 's01e17b', 's01e18a', 's01e18b', 's01e19a', 's01e19b', 's01e20a', 's01e20b', 's01e21a', 's01e21b', 's01e22a', 's01e22b', 's01e23a', 's01e23b', 's01e24a', 's01e24b', 's02e01a', 's02e01b', 's02e02a', 's02e02b', 's02e03a', 's02e03b', 's02e04a', 's02e04b', 's02e05a', 's02e05b', 's02e06a', 's02e06b', 's02e07a', 's02e07b', 's02e08a', 's02e08b', 's02e09a', 's02e09b', 's02e10a', 's02e10b', 's02e11a', 's02e11b', 's02e12a', 's02e12b', 's02e13a', 's02e13b', 's02e14a', 's02e14b', 's02e15a', 's02e15b', 's02e16a', 's02e16b', 's02e17a', 's02e17b', 's02e18a', 's02e18b', 's02e19a', 's02e19b', 's02e20a', 's02e20b', 's02e21a', 's02e21b', 's02e22a', 's02e22b', 's02e23a', 's02e23b', 's02e24a', 's02e24b', 's03e01a', 's03e01b', 's03e02a', 's03e02b', 's03e03a', 's03e03b', 's03e04a', 's03e04b', 's03e05a', 's03e05b', 's03e06a', 's03e06b', 's03e07a', 's03e07b', 's03e08a', 's03e08b', 's03e09a', 's03e09b', 's03e10a', 's03e10b', 's03e11a', 's03e11b', 's03e12a', 's03e12b', 's03e13a', 's03e13b', 's03e14a', 's03e14b', 's03e15a', 's03e15b', 's03e16a', 's03e16b', 's03e17a', 's03e17b', 's03e18a', 's03e18b', 's03e19a', 's03e19b', 's03e20a', 's03e20b', 's03e21a', 's03e21b', 's03e22a', 's03e22b', 's03e23a', 's03e23b', 's03e24a', 's03e24b', 's03e25a', 's03e25b', 's04e02a', 's04e02b', 's04e03a', 's04e03b', 's04e04a', 's04e04b', 's04e05a', 's04e05b', 's04e06a', 's04e06b', 's04e07a', 's04e07b', 's04e08a', 's04e08b', 's04e09a', 's04e09b', 's04e10a', 's04e10b', 's04e11a', 's04e11b', 's04e12a', 's04e12b', 's04e13a', 's04e14a', 's04e14b', 's04e15a', 's04e15b', 's04e16a', 's04e16b', 's04e17a', 's04e17b', 's04e18a', 's04e18b', 's04e19a', 's04e19b', 's04e20a', 's04e20b', 's04e21a', 's04e21b', 's04e22a', 's04e22b', 's04e23a', 's04e23b', 's04e23c', 's04e23d', 's05e01a', 's05e01b', 's05e02a', 's05e02b', 's05e03a', 's05e03b', 's05e04a', 's05e04b', 's05e05a', 's05e05b', 's05e06a', 's05e06b', 's05e07a', 's05e07b', 's05e08a', 's05e08b', 's05e09a', 's05e09b', 's05e10a', 's05e10b', 's05e11a', 's05e11b', 's05e12a', 's05e12b', 's05e13a', 's05e13b', 's05e14a', 's05e14b', 's05e15a', 's05e15b', 's05e16a', 's05e16b', 's05e17a', 's05e17b', 's05e18a', 's05e18b', 's05e19a', 's05e19b', 's05e20b', 's05e21a', 's05e21b', 's05e22a', 's05e22b', 's05e23a', 's05e23b', 's05e23c', 's05e23d'])\n",
      "dict_keys(['s06e01a', 's06e01b', 's06e02a', 's06e02b', 's06e03b', 's06e04a', 's06e04b', 's06e05a', 's06e05b', 's06e06a', 's06e06b', 's06e07a', 's06e07b', 's06e08a', 's06e08b', 's06e09a', 's06e09b', 's06e10a', 's06e10b', 's06e11a', 's06e11b', 's06e12a', 's06e12b', 's06e13a', 's06e13b', 's06e14a', 's06e14b', 's06e15a', 's06e15b', 's06e15c', 's06e15d', 's06e17a', 's06e17b', 's06e18a', 's06e18b', 's06e19a', 's06e19b', 's06e20a', 's06e20b', 's06e21a', 's06e21b', 's06e22a', 's06e22b', 's06e23a', 's06e23b', 's06e24a', 's06e24b', 's06e24c', 's06e24d'])\n",
      "dict_keys([('bourne01', 1), ('bourne02', 1), ('bourne03', 1), ('bourne04', 1), ('bourne05', 1), ('bourne06', 1), ('bourne07', 1), ('bourne08', 1), ('bourne09', 1), ('bourne10', 1), ('figures01', 1), ('figures02', 1), ('figures03', 1), ('figures04', 1), ('figures05', 1), ('figures06', 1), ('figures07', 1), ('figures08', 1), ('figures09', 1), ('figures10', 1), ('figures11', 1), ('figures12', 1), ('life01', 1), ('life02', 1), ('life03', 1), ('life04', 1), ('life05', 1), ('wolf01', 1), ('wolf02', 1), ('wolf03', 1), ('wolf04', 1), ('wolf05', 1), ('wolf06', 1), ('wolf07', 1), ('wolf08', 1), ('wolf09', 1), ('wolf10', 1), ('wolf11', 1), ('wolf12', 1), ('wolf13', 1), ('wolf14', 1), ('wolf15', 1), ('wolf16', 1), ('wolf17', 1)])\n"
     ]
    }
   ],
   "source": [
    "print(friends_train_fmri.keys())\n",
    "print(friends_val_fmri.keys())\n",
    "print(movie10_test_fmri.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf2af657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample shape (NTC): (4, 468, 1000) float32\n"
     ]
    }
   ],
   "source": [
    "sample = friends_train_fmri[\"s01e05b\"]\n",
    "print(\"Sample shape (NTC):\", sample.shape, sample.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71e140a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Algonauts2025Dataset(IterableDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fmri_data: dict[str, np.ndarray],\n",
    "        feat_data: list[dict[str, np.ndarray]] | None = None,\n",
    "        sample_length: int | None = 128,\n",
    "        num_samples: int | None = None,\n",
    "        shuffle: bool = True,\n",
    "        seed: int | None = None,\n",
    "    ):\n",
    "        self.fmri_data = fmri_data\n",
    "        self.feat_data = feat_data\n",
    "\n",
    "        self.episode_list = list(fmri_data)\n",
    "        self.sample_length = sample_length\n",
    "        self.num_samples = num_samples\n",
    "        self.shuffle = shuffle\n",
    "        self.seed = seed\n",
    "\n",
    "        self._rng = np.random.default_rng(seed)\n",
    "    \n",
    "    def _iter_shuffle(self):\n",
    "        sample_idx = 0\n",
    "        while True:\n",
    "            episode_order = self._rng.permutation(len(self.episode_list))\n",
    "\n",
    "            for ii in episode_order:\n",
    "                episode = self.episode_list[ii]\n",
    "                feat_episode = episode[0] if isinstance(episode, tuple) else episode\n",
    "\n",
    "                fmri = torch.from_numpy(self.fmri_data[episode]).float()\n",
    "    \n",
    "                if self.feat_data:\n",
    "                    feats = [torch.from_numpy(data[feat_episode]).float() for data in self.feat_data]\n",
    "                else:\n",
    "                    feats = feat_samples = None\n",
    "\n",
    "                # Nb, fmri and feature length often off by 1 or 2.\n",
    "                # But assuming time locked to start.\n",
    "                length = fmri.shape[1]\n",
    "                if feats:\n",
    "                    length = min(length, min(feat.shape[0] for feat in feats))\n",
    "\n",
    "                if self.sample_length:\n",
    "                    # Random segment of run\n",
    "                    offset = int(self._rng.integers(0, length - self.sample_length + 1))\n",
    "                    fmri_sample = fmri[:, offset: offset + self.sample_length]\n",
    "                    if feats:\n",
    "                        feat_samples = [\n",
    "                            feat[offset: offset + self.sample_length] for feat in feats\n",
    "                        ]\n",
    "                else:\n",
    "                    # Take full run\n",
    "                    # Nb this only works for batch size 1 since runs are different length\n",
    "                    fmri_sample = fmri[:, :length]\n",
    "                    if feats:\n",
    "                        feat_samples = [feat[:length] for feat in feats]\n",
    "\n",
    "                if feat_samples:\n",
    "                    yield episode, fmri_sample, feat_samples\n",
    "                else:\n",
    "                    yield episode, fmri_sample\n",
    "\n",
    "                sample_idx += 1\n",
    "                if self.num_samples and sample_idx >= self.num_samples:\n",
    "                    return\n",
    "\n",
    "    def _iter_ordered(self):\n",
    "        sample_idx = 0\n",
    "        for episode in self.episode_list:\n",
    "            feat_episode = episode[0] if isinstance(episode, tuple) else episode\n",
    "            fmri = torch.from_numpy(self.fmri_data[episode]).float()\n",
    "            if self.feat_data:\n",
    "                feats = [torch.from_numpy(data[feat_episode]).float() for data in self.feat_data]\n",
    "            else:\n",
    "                feats = feat_samples = None\n",
    "\n",
    "            length = fmri.shape[1]\n",
    "            if feats:\n",
    "                length = min(length, min(feat.shape[0] for feat in feats))\n",
    "\n",
    "            sample_length = self.sample_length or length\n",
    "\n",
    "            for offset in range(0, length - sample_length + 1, sample_length):\n",
    "                fmri_sample = fmri[:, offset: offset + sample_length]\n",
    "                if feats:\n",
    "                    feat_samples = [feat[offset: offset + sample_length] for feat in feats]\n",
    "\n",
    "                if feat_samples:\n",
    "                    yield episode, fmri_sample, feat_samples\n",
    "                else:\n",
    "                    yield episode, fmri_sample\n",
    "\n",
    "                sample_idx += 1\n",
    "                if self.num_samples and sample_idx >= self.num_samples:\n",
    "                    return\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            yield from self._iter_shuffle()\n",
    "        else:\n",
    "            yield from self._iter_ordered()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518765d4",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "- whisper\n",
    "  - layers:\n",
    "    - layers.12.fc2\n",
    "    - layers.25.fc2\n",
    "    - layers.31.fc2\n",
    "    - layer_norm\n",
    "  - dim: 1280\n",
    "- internvl3_8b_8bit\n",
    "  - layers:\n",
    "    - language_model.model.layers.10.post_attention_layernorm\n",
    "    - language_model.model.layers.15.post_attention_layernorm\n",
    "    - language_model.model.layers.20.post_attention_layernorm\n",
    "    - language_model.model.norm\n",
    "  - dim: 3584\n",
    "- Llama-3.2-1B\n",
    "  - layers:\n",
    "    - model.layers.7\n",
    "    - model.layers.11\n",
    "    - model.layers.15\n",
    "  - dim: 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "621ed291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_medarc_features(\n",
    "    root: str | Path,\n",
    "    model: str,\n",
    "    layer: str,\n",
    "    series: str = \"friends\"\n",
    ") -> dict[str, np.ndarray]:\n",
    "    paths = sorted((Path(root) / model / series).rglob(\"*.h5\"))\n",
    "\n",
    "    features = {}\n",
    "    for path in paths:\n",
    "        episode = path.stem.split(\"_\")[-1]  # friends_s01e01a, bourne01\n",
    "        with h5py.File(path) as f:\n",
    "            features[episode] = f[layer][:].squeeze()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d3b71dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_merged_features(\n",
    "    path: str | Path,\n",
    "    layer: str,\n",
    ") -> dict[str, np.ndarray]:\n",
    "    with h5py.File(path) as f:\n",
    "        features = {k: f[k][layer][:] for k in f}\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6e7c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "medarc_feature_root = root_dir / \"features.medarc\"\n",
    "merged_feature_root = root_dir / \"features.merged\"\n",
    "\n",
    "stimuli_features_friends = {}\n",
    "stimuli_features_movie10 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8df2f0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "medarc_models_layers = [\n",
    "    (\"whisper\", \"layers.12.fc2\"),\n",
    "    (\"whisper\", \"layers.31.fc2\"),\n",
    "    (\"internvl3_8b_8bit\", \"language_model.model.layers.10.post_attention_layernorm\"),\n",
    "    (\"internvl3_8b_8bit\", \"language_model.model.layers.20.post_attention_layernorm\"),\n",
    "]\n",
    "\n",
    "for model, layer in medarc_models_layers:\n",
    "    stimuli_features_friends[f\"{model}/{layer}\"] = load_medarc_features(\n",
    "        medarc_feature_root, model=model, layer=layer, series=\"friends\",\n",
    "    )\n",
    "    stimuli_features_movie10[f\"{model}/{layer}\"] = load_medarc_features(\n",
    "        medarc_feature_root, model=model, layer=layer, series=\"movie10\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "833d2ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_models_layers = [\n",
    "    (\"Llama-3.2-1B\", \"model.layers.7\"),\n",
    "    (\"Llama-3.2-1B\", \"model.layers.15\"),\n",
    "]\n",
    "\n",
    "for model, layer in merged_models_layers:\n",
    "    # TODO: this path is awkward\n",
    "    stimuli_features_friends[f\"{model}/{layer}\"] = load_merged_features(\n",
    "        path=merged_feature_root / f\"friends/meta-llama__{model}/context-long.h5\",\n",
    "        layer=layer,\n",
    "    )\n",
    "    stimuli_features_movie10[f\"{model}/{layer}\"] = load_merged_features(\n",
    "        path=merged_feature_root / f\"movie10/meta-llama__{model}/context-long.h5\",\n",
    "        layer=layer,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec03c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Algonauts2025Dataset(\n",
    "    movie10_test_fmri,\n",
    "    list(stimuli_features_movie10.values()),\n",
    "    sample_length=64,\n",
    "    num_samples=10000,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b27cf23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "187it [00:00, 1866.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:02, 4038.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time=2.480s, MB/s=3938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_bytes = 0\n",
    "tic = time.monotonic()\n",
    "for task, fmri_sample, feat_samples in tqdm(dataset):\n",
    "    total_bytes += fmri_sample.numel() * 4\n",
    "rt = time.monotonic() - tic\n",
    "tput = total_bytes / 1024 ** 2 / rt \n",
    "print(f\"run time={rt:.3f}s, MB/s={tput:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d773fe25",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ac685ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7097a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv1d(nn.Conv1d):\n",
    "    \"\"\"Conv1d layer with a causal mask, to only \"attend\" to past time points.\"\"\"\n",
    "    attn_mask: torch.Tensor\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int,\n",
    "        stride: int = 1,\n",
    "        padding: str | int = 0,\n",
    "        dilation: int = 1,\n",
    "        groups: int = 1,\n",
    "        bias: bool = True,\n",
    "    ):\n",
    "        assert kernel_size % 2 == 1, \"causal conv requires odd kernel size\"\n",
    "        super().__init__(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "        attn_mask = torch.zeros(kernel_size)\n",
    "        attn_mask[:kernel_size // 2 + 1] = 1.0\n",
    "        self.weight.data.mul_(attn_mask)\n",
    "        self.register_buffer(\"attn_mask\", attn_mask)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        weight = self.weight * self.attn_mask\n",
    "        return F.conv1d(\n",
    "            input, weight, self.bias, self.stride, self.padding, self.dilation, self.groups\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19f4e646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLinear(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        kernel_size: int = 11,\n",
    "        causal: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        conv_layer = CausalConv1d if causal else nn.Conv1d\n",
    "        self.conv = conv_layer(\n",
    "            in_features,\n",
    "            in_features,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=\"same\",\n",
    "            groups=in_features,\n",
    "        )\n",
    "        self.fc = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: (N, L, C)\n",
    "        x = x.transpose(-1, -2)\n",
    "        x = self.conv(x)\n",
    "        x = x.transpose(-1, -2)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinearConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        kernel_size: int = 11,\n",
    "        causal: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        conv_layer = CausalConv1d if causal else nn.Conv1d\n",
    "        self.fc = nn.Linear(in_features, out_features)\n",
    "        self.conv = conv_layer(\n",
    "            out_features,\n",
    "            out_features,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=\"same\",\n",
    "            groups=out_features,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: (N, L, C)\n",
    "        x = self.fc(x)\n",
    "        x = x.transpose(-1, -2)\n",
    "        x = self.conv(x)\n",
    "        x = x.transpose(-1, -2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f326f945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLinear(\n",
      "  (conv): CausalConv1d(1000, 1000, kernel_size=(11,), stride=(1,), padding=same, groups=1000)\n",
      "  (fc): Linear(in_features=1000, out_features=256, bias=True)\n",
      ")\n",
      "torch.Size([16, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "encoder = ConvLinear(\n",
    "    in_features=1000,\n",
    "    out_features=256,\n",
    "    causal=True\n",
    ")\n",
    "print(encoder)\n",
    "\n",
    "# (N, L, C)\n",
    "x = torch.randn(16, 64, 1000)\n",
    "embed = encoder.forward(x)\n",
    "print(embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85f20db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatEmbed(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feat_dim: int = 2048,\n",
    "        embed_dim: int = 256,\n",
    "        kernel_size: int = 33,\n",
    "        causal: bool = True,\n",
    "        normalize: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(feat_dim) if normalize else nn.Identity()\n",
    "        if kernel_size > 1:\n",
    "            self.embed = LinearConv(\n",
    "                feat_dim, embed_dim, kernel_size=kernel_size, causal=causal\n",
    "            )\n",
    "        else:\n",
    "            self.embed = nn.Linear(feat_dim, embed_dim)\n",
    "    \n",
    "    def forward(self, input: torch.Tensor):\n",
    "        return self.embed(self.norm(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b0e338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiSubjectConvLinearEncoderV3(nn.Module):\n",
    "    \"\"\"\n",
    "    - Added support for multiple features\n",
    "    \"\"\"\n",
    "    weight: torch.Tensor\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_subjects: int = 4,\n",
    "        feat_dims: tuple[int, ...] = (2048,),\n",
    "        embed_dim: int = 256,\n",
    "        target_dim: int = 1000,\n",
    "        encoder_kernel_size: int = 33,\n",
    "        decoder_kernel_size: int = 0,\n",
    "        encoder_causal: bool = True,\n",
    "        encoder_normalize: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_subjects = num_subjects\n",
    "\n",
    "        self.feat_embeds = nn.ModuleList(\n",
    "            [\n",
    "                FeatEmbed(\n",
    "                    feat_dim,\n",
    "                    embed_dim,\n",
    "                    kernel_size=encoder_kernel_size,\n",
    "                    causal=encoder_causal,\n",
    "                    normalize=encoder_normalize,\n",
    "                )\n",
    "                for feat_dim in feat_dims\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if decoder_kernel_size > 1:\n",
    "            decoder_linear = partial(ConvLinear, kernel_size=decoder_kernel_size)\n",
    "        else:\n",
    "            decoder_linear = nn.Linear\n",
    "\n",
    "        self.shared_decoder = nn.Linear(embed_dim, target_dim)\n",
    "        self.subject_decoders = nn.ModuleList(\n",
    "            [\n",
    "                decoder_linear(embed_dim, target_dim) for _ in range(num_subjects)\n",
    "            ]\n",
    "        )\n",
    "        self.apply(init_weights)\n",
    "    \n",
    "    def forward(self, inputs: list[torch.Tensor]):\n",
    "        # input: (N, L, D)\n",
    "        # output: (N, S, L, C)\n",
    "        embed = sum(feat_embed(input) for input, feat_embed in zip(inputs, self.feat_embeds))\n",
    "        shared_output = self.shared_decoder(embed)\n",
    "        subject_output = torch.stack(\n",
    "            [decoder(embed) for decoder in self.subject_decoders],\n",
    "            dim=1,\n",
    "        )\n",
    "        output = subject_output + shared_output[:, None]\n",
    "        return output\n",
    "\n",
    "\n",
    "def init_weights(m: nn.Module):\n",
    "    if isinstance(m, (nn.Conv1d, nn.Conv2d, nn.Linear)):\n",
    "        nn.init.trunc_normal_(m.weight, std=0.02)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2262fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiSubjectConvLinearEncoderV3(\n",
      "  (feat_embeds): ModuleList(\n",
      "    (0): FeatEmbed(\n",
      "      (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "      (embed): LinearConv(\n",
      "        (fc): Linear(in_features=2048, out_features=64, bias=True)\n",
      "        (conv): CausalConv1d(64, 64, kernel_size=(33,), stride=(1,), padding=same, groups=64)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (shared_decoder): Linear(in_features=64, out_features=1000, bias=True)\n",
      "  (subject_decoders): ModuleList(\n",
      "    (0-3): 4 x Linear(in_features=64, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = MultiSubjectConvLinearEncoderV3(embed_dim=64)\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da72aca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4, 256, 1000])\n"
     ]
    }
   ],
   "source": [
    "# (N, L, C)\n",
    "x = torch.randn(16, 256, 2048)\n",
    "z = encoder.forward([x])\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c7580e",
   "metadata": {},
   "source": [
    "Test loading cross encoding checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2f1d9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys: ['feat_embeds.0.norm.weight', 'feat_embeds.0.norm.bias', 'feat_embeds.0.embed.fc.weight', 'feat_embeds.0.embed.fc.bias', 'feat_embeds.0.embed.conv.weight', 'feat_embeds.0.embed.conv.bias', 'feat_embeds.0.embed.conv.attn_mask']\n",
      "Unexpected keys: ['weight', 'shared_encoder.weight', 'shared_encoder.bias', 'subject_encoders.0.fc.weight', 'subject_encoders.0.fc.bias', 'subject_encoders.0.conv.weight', 'subject_encoders.0.conv.bias', 'subject_encoders.1.fc.weight', 'subject_encoders.1.fc.bias', 'subject_encoders.1.conv.weight', 'subject_encoders.1.conv.bias', 'subject_encoders.2.fc.weight', 'subject_encoders.2.fc.bias', 'subject_encoders.2.conv.weight', 'subject_encoders.2.conv.bias', 'subject_encoders.3.fc.weight', 'subject_encoders.3.fc.bias', 'subject_encoders.3.conv.weight', 'subject_encoders.3.conv.bias']\n"
     ]
    }
   ],
   "source": [
    "cross_encoding_dir = root_dir / \"cross_encoding/output/cross_encoding_v3\"\n",
    "\n",
    "cross_encoder_ckpt = torch.load(\n",
    "    cross_encoding_dir / \"ckpt.pt\", map_location=\"cpu\", weights_only=False\n",
    ")\n",
    "\n",
    "missing_keys, unexpected_keys = encoder.load_state_dict(\n",
    "    cross_encoder_ckpt[\"model\"], strict=False\n",
    ")\n",
    "print(\"Missing keys:\", missing_keys)\n",
    "print(\"Unexpected keys:\", unexpected_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a1e89",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d098e1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from timm.utils import AverageMeter, random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15803c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    *,\n",
    "    epoch: int,\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch_batches: int | None,\n",
    "    device: torch.device,\n",
    "):\n",
    "    model.train()\n",
    "    \n",
    "    use_cuda = device.type == \"cuda\"\n",
    "    if use_cuda:\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    loss_m = AverageMeter()\n",
    "    data_time_m = AverageMeter()\n",
    "    step_time_m = AverageMeter()\n",
    "\n",
    "    epoch_batches = len(train_loader) if epoch_batches is None else epoch_batches\n",
    "    first_step = epoch * epoch_batches\n",
    "\n",
    "    end = time.monotonic()\n",
    "    for batch_idx, (_, sample, feats) in enumerate(train_loader):\n",
    "        step = first_step + batch_idx\n",
    "        feats = [feat.to(device) for feat in feats]\n",
    "        sample = sample.to(device)\n",
    "        batch_size = sample.size(0)\n",
    "        data_time = time.monotonic() - end\n",
    "\n",
    "        # forward pass\n",
    "        output = model(feats)\n",
    "        loss = F.mse_loss(output, sample)\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        if math.isnan(loss_item) or math.isinf(loss_item):\n",
    "            raise RuntimeError(\"NaN/Inf loss encountered on step %d; exiting\", step)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # end of iteration timing\n",
    "        if use_cuda:\n",
    "            torch.cuda.synchronize()\n",
    "        step_time = time.monotonic() - end\n",
    "\n",
    "        loss_m.update(loss_item, batch_size)\n",
    "        data_time_m.update(data_time, batch_size)\n",
    "        step_time_m.update(step_time, batch_size)\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            tput = batch_size / step_time_m.avg\n",
    "            if use_cuda:\n",
    "                alloc_mem_gb = torch.cuda.max_memory_allocated() / 1e9\n",
    "                res_mem_gb = torch.cuda.max_memory_reserved() / 1e9\n",
    "            else:\n",
    "                alloc_mem_gb = res_mem_gb = 0.0\n",
    "\n",
    "            print(\n",
    "                f\"Train: {epoch:>3d} [{batch_idx:>3d}/{epoch_batches}][{step:>6d}]\"\n",
    "                f\"  Loss: {loss_m.val:#.3g} ({loss_m.avg:#.3g})\"\n",
    "                f\"  Time: {data_time_m.avg:.3f},{step_time_m.avg:.3f} {tput:.0f}/s\"\n",
    "                f\"  Mem: {alloc_mem_gb:.2f},{res_mem_gb:.2f} GB\"\n",
    "            )\n",
    "\n",
    "        # Restart timer for next iteration\n",
    "        end = time.monotonic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "133ff529",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(\n",
    "    *,\n",
    "    epoch: int,\n",
    "    model: torch.nn.Module,\n",
    "    val_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    use_cuda = device.type == \"cuda\"\n",
    "\n",
    "    loss_m = AverageMeter()\n",
    "    data_time_m = AverageMeter()\n",
    "    step_time_m = AverageMeter()\n",
    "\n",
    "    samples = []\n",
    "    outputs = []\n",
    "\n",
    "    end = time.monotonic()\n",
    "    for batch_idx, (_, sample, feats) in enumerate(val_loader):\n",
    "        sample = sample.to(device)\n",
    "        feats = [feat.to(device) for feat in feats]\n",
    "        batch_size = sample.size(0)\n",
    "        data_time = time.monotonic() - end\n",
    "\n",
    "        # forward pass\n",
    "        output = model(feats)\n",
    "        loss = F.mse_loss(output, sample)\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        # end of iteration timing\n",
    "        if use_cuda:\n",
    "            torch.cuda.synchronize()\n",
    "        step_time = time.monotonic() - end\n",
    "\n",
    "        loss_m.update(loss_item, batch_size)\n",
    "        data_time_m.update(data_time, batch_size)\n",
    "        step_time_m.update(step_time, batch_size)\n",
    "\n",
    "        N, S, L, C = sample.shape\n",
    "        assert N, S == (1, 4)\n",
    "        samples.append(sample.cpu().numpy().swapaxes(0, 1).reshape((S, N*L, C)))\n",
    "        outputs.append(output.cpu().numpy().swapaxes(0, 1).reshape((S, N*L, C)))\n",
    "\n",
    "        # Reset timer\n",
    "        end = time.monotonic()\n",
    "\n",
    "    # (S, N, C)\n",
    "    samples = np.concatenate(samples, axis=1)\n",
    "    outputs = np.concatenate(outputs, axis=1)\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    # Encoding accuracy metrics\n",
    "    dim = samples.shape[-1]\n",
    "    acc = 0.0\n",
    "    acc_map = np.zeros(dim)\n",
    "    for ii, sub in enumerate(SUBJECTS):\n",
    "        y_true = samples[ii].reshape(-1, dim)\n",
    "        y_pred = outputs[ii].reshape(-1, dim)\n",
    "        metrics[f\"acc_map_sub-{sub}\"] = acc_map_i = pearsonr_score(y_true, y_pred)\n",
    "        metrics[f\"acc_sub-{sub}\"] = acc_i = np.mean(acc_map_i)\n",
    "        acc_map += acc_map_i / len(SUBJECTS)\n",
    "        acc += acc_i / len(SUBJECTS)\n",
    "\n",
    "    metrics[\"acc_map_avg\"] = acc_map\n",
    "    metrics[\"acc_avg\"] = acc\n",
    "    accs_fmt = \",\".join(\n",
    "        f\"{val:.3f}\" for key, val in metrics.items() if key.startswith(\"acc_sub-\")\n",
    "    )\n",
    "\n",
    "    tput = batch_size / step_time_m.avg\n",
    "    print(\n",
    "        f\"Val: {epoch:>3d}\"\n",
    "        f\"  Loss: {loss_m.avg:#.3g}\"\n",
    "        f\"  Acc: {accs_fmt} ({acc:.3f})\"\n",
    "        f\"  Time: {data_time_m.avg:.3f},{step_time_m.avg:.3f} {tput:.0f}/s\"\n",
    "    )\n",
    "\n",
    "    return acc, metrics\n",
    "\n",
    "\n",
    "def pearsonr_score(\n",
    "    y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-7\n",
    ") -> np.ndarray:\n",
    "    assert y_true.ndim == y_pred.ndim == 2\n",
    "\n",
    "    y_true = y_true - y_true.mean(axis=0)\n",
    "    y_true = y_true / (np.linalg.norm(y_true, axis=0) + eps)\n",
    "\n",
    "    y_pred = y_pred - y_pred.mean(axis=0)\n",
    "    y_pred = y_pred / (np.linalg.norm(y_pred, axis=0) + eps)\n",
    "\n",
    "    score = (y_true * y_pred).sum(axis=0)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b16d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3315\n",
    "batch_size = 4\n",
    "sample_length = 256\n",
    "n_train_samples = 500\n",
    "lr = 3e-4\n",
    "weight_decay = 0.1\n",
    "epochs = 10\n",
    "\n",
    "embed_dim = 64\n",
    "encoder_kernel_size = 33\n",
    "decoder_kernel_size = 0\n",
    "\n",
    "freeze_decoder = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5903e6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 3315, 'batch_size': 4, 'sample_length': 256, 'n_train_samples': 500, 'lr': 0.0003, 'weight_decay': 0.1, 'epochs': 10, 'embed_dim': 64, 'encoder_kernel_size': 33, 'decoder_kernel_size': 0, 'freeze_decoder': True}\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    k: globals()[k] for k in\n",
    "    [\n",
    "        \"seed\",\n",
    "        \"batch_size\",\n",
    "        \"sample_length\",\n",
    "        \"n_train_samples\",\n",
    "        \"lr\",\n",
    "        \"weight_decay\",\n",
    "        \"epochs\",\n",
    "        \"embed_dim\",\n",
    "        \"encoder_kernel_size\",\n",
    "        \"decoder_kernel_size\",\n",
    "        \"freeze_decoder\",\n",
    "        ]\n",
    "}\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "979c7ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cuda:1\n"
     ]
    }
   ],
   "source": [
    "random_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eeec7f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Algonauts2025Dataset(\n",
    "    friends_train_fmri,\n",
    "    list(stimuli_features_friends.values()),\n",
    "    sample_length=sample_length,\n",
    "    num_samples=n_train_samples,\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "val_dataset = Algonauts2025Dataset(\n",
    "    friends_val_fmri,\n",
    "    list(stimuli_features_friends.values()),\n",
    "    sample_length=None,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_dataset = Algonauts2025Dataset(\n",
    "    movie10_test_fmri,\n",
    "    list(stimuli_features_movie10.values()),\n",
    "    sample_length=None,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47e85b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63089de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample shape: (4, 4, 256, 1000)\n",
      "Feats shape: [(4, 256, 1280), (4, 256, 1280), (4, 256, 3584), (4, 256, 3584), (4, 256, 2048), (4, 256, 2048)]\n",
      "Sample dtype: torch.float32\n",
      "Feats dtype: [torch.float32, torch.float32, torch.float32, torch.float32, torch.float32, torch.float32]\n"
     ]
    }
   ],
   "source": [
    "_, sample, feats = next(iter(train_loader))\n",
    "print(\"Sample shape:\", tuple(sample.shape))\n",
    "print(\"Feats shape:\", [tuple(feat.shape) for feat in feats])\n",
    "print(\"Sample dtype:\", sample.dtype)\n",
    "print(\"Feats dtype:\", [feat.dtype for feat in feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b72c4c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys: ['feat_embeds.0.norm.weight', 'feat_embeds.0.norm.bias', 'feat_embeds.0.embed.fc.weight', 'feat_embeds.0.embed.fc.bias', 'feat_embeds.0.embed.conv.weight', 'feat_embeds.0.embed.conv.bias', 'feat_embeds.0.embed.conv.attn_mask', 'feat_embeds.1.norm.weight', 'feat_embeds.1.norm.bias', 'feat_embeds.1.embed.fc.weight', 'feat_embeds.1.embed.fc.bias', 'feat_embeds.1.embed.conv.weight', 'feat_embeds.1.embed.conv.bias', 'feat_embeds.1.embed.conv.attn_mask', 'feat_embeds.2.norm.weight', 'feat_embeds.2.norm.bias', 'feat_embeds.2.embed.fc.weight', 'feat_embeds.2.embed.fc.bias', 'feat_embeds.2.embed.conv.weight', 'feat_embeds.2.embed.conv.bias', 'feat_embeds.2.embed.conv.attn_mask', 'feat_embeds.3.norm.weight', 'feat_embeds.3.norm.bias', 'feat_embeds.3.embed.fc.weight', 'feat_embeds.3.embed.fc.bias', 'feat_embeds.3.embed.conv.weight', 'feat_embeds.3.embed.conv.bias', 'feat_embeds.3.embed.conv.attn_mask', 'feat_embeds.4.norm.weight', 'feat_embeds.4.norm.bias', 'feat_embeds.4.embed.fc.weight', 'feat_embeds.4.embed.fc.bias', 'feat_embeds.4.embed.conv.weight', 'feat_embeds.4.embed.conv.bias', 'feat_embeds.4.embed.conv.attn_mask', 'feat_embeds.5.norm.weight', 'feat_embeds.5.norm.bias', 'feat_embeds.5.embed.fc.weight', 'feat_embeds.5.embed.fc.bias', 'feat_embeds.5.embed.conv.weight', 'feat_embeds.5.embed.conv.bias', 'feat_embeds.5.embed.conv.attn_mask']\n",
      "Unexpected keys: ['weight', 'shared_encoder.weight', 'shared_encoder.bias', 'subject_encoders.0.fc.weight', 'subject_encoders.0.fc.bias', 'subject_encoders.0.conv.weight', 'subject_encoders.0.conv.bias', 'subject_encoders.1.fc.weight', 'subject_encoders.1.fc.bias', 'subject_encoders.1.conv.weight', 'subject_encoders.1.conv.bias', 'subject_encoders.2.fc.weight', 'subject_encoders.2.fc.bias', 'subject_encoders.2.conv.weight', 'subject_encoders.2.conv.bias', 'subject_encoders.3.fc.weight', 'subject_encoders.3.fc.bias', 'subject_encoders.3.conv.weight', 'subject_encoders.3.conv.bias']\n",
      "Model: MultiSubjectConvLinearEncoderV3(\n",
      "  (feat_embeds): ModuleList(\n",
      "    (0-1): 2 x FeatEmbed(\n",
      "      (norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      (embed): LinearConv(\n",
      "        (fc): Linear(in_features=1280, out_features=64, bias=True)\n",
      "        (conv): CausalConv1d(64, 64, kernel_size=(33,), stride=(1,), padding=same, groups=64)\n",
      "      )\n",
      "    )\n",
      "    (2-3): 2 x FeatEmbed(\n",
      "      (norm): LayerNorm((3584,), eps=1e-05, elementwise_affine=True)\n",
      "      (embed): LinearConv(\n",
      "        (fc): Linear(in_features=3584, out_features=64, bias=True)\n",
      "        (conv): CausalConv1d(64, 64, kernel_size=(33,), stride=(1,), padding=same, groups=64)\n",
      "      )\n",
      "    )\n",
      "    (4-5): 2 x FeatEmbed(\n",
      "      (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "      (embed): LinearConv(\n",
      "        (fc): Linear(in_features=2048, out_features=64, bias=True)\n",
      "        (conv): CausalConv1d(64, 64, kernel_size=(33,), stride=(1,), padding=same, groups=64)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (shared_decoder): Linear(in_features=64, out_features=1000, bias=True)\n",
      "  (subject_decoders): ModuleList(\n",
      "    (0-3): 4 x Linear(in_features=64, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "Num params: 1.25M (0.93M)\n"
     ]
    }
   ],
   "source": [
    "model = MultiSubjectConvLinearEncoderV3(\n",
    "    feat_dims=[1280, 1280, 3584, 3584, 2048, 2048],\n",
    "    embed_dim=embed_dim,\n",
    "    encoder_kernel_size=encoder_kernel_size,\n",
    "    decoder_kernel_size=decoder_kernel_size,\n",
    ")\n",
    "\n",
    "if freeze_decoder:\n",
    "    missing_keys, unexpected_keys = model.load_state_dict(\n",
    "        cross_encoder_ckpt[\"model\"], strict=False\n",
    "    )\n",
    "    for p in model.shared_decoder.parameters():\n",
    "        p.requires_grad_(False)\n",
    "    for p in model.subject_decoders.parameters():\n",
    "        p.requires_grad_(False)\n",
    "    print(\"Missing keys:\", missing_keys)\n",
    "    print(\"Unexpected keys:\", unexpected_keys)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "param_count = sum(p.numel() for p in model.parameters())\n",
    "train_param_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Model:\", model)\n",
    "print(f\"Num params: {param_count/1e6:.2f}M ({train_param_count/1e6:.2f}M)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f213ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "epoch_batches = n_train_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0953c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train friends s1-5\n",
      "Train:   0 [  0/125][     0]  Loss: 0.370 (0.370)  Time: 0.371,1.985 2/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [ 10/125][    10]  Loss: 0.364 (0.370)  Time: 0.050,0.250 16/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [ 20/125][    20]  Loss: 0.359 (0.365)  Time: 0.034,0.141 28/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [ 30/125][    30]  Loss: 0.349 (0.362)  Time: 0.029,0.102 39/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [ 40/125][    40]  Loss: 0.361 (0.361)  Time: 0.025,0.082 49/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [ 50/125][    50]  Loss: 0.364 (0.360)  Time: 0.023,0.070 57/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [ 60/125][    60]  Loss: 0.345 (0.358)  Time: 0.022,0.061 65/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [ 70/125][    70]  Loss: 0.341 (0.356)  Time: 0.021,0.055 72/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [ 80/125][    80]  Loss: 0.336 (0.355)  Time: 0.020,0.050 79/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [ 90/125][    90]  Loss: 0.345 (0.353)  Time: 0.019,0.047 86/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [100/125][   100]  Loss: 0.338 (0.352)  Time: 0.018,0.044 91/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [110/125][   110]  Loss: 0.333 (0.351)  Time: 0.018,0.041 97/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [120/125][   120]  Loss: 0.331 (0.350)  Time: 0.017,0.039 102/s  Mem: 0.00,0.00 GB\n",
      "Eval friends s6\n",
      "Val:   0  Loss: 0.340  Acc: 0.240,0.249,0.266,0.231 (0.246)  Time: 0.006,0.007 139/s\n",
      "Eval movie10\n",
      "Val:   0  Loss: 0.356  Acc: 0.194,0.175,0.192,0.163 (0.181)  Time: 0.005,0.006 162/s\n",
      "Train friends s1-5\n",
      "Train:   1 [  5/125][   130]  Loss: 0.352 (0.337)  Time: 0.012,0.017 240/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [ 15/125][   140]  Loss: 0.340 (0.338)  Time: 0.012,0.016 249/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [ 25/125][   150]  Loss: 0.338 (0.338)  Time: 0.012,0.016 251/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [ 35/125][   160]  Loss: 0.345 (0.338)  Time: 0.012,0.016 252/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [ 45/125][   170]  Loss: 0.342 (0.338)  Time: 0.012,0.016 252/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [ 55/125][   180]  Loss: 0.333 (0.337)  Time: 0.012,0.016 253/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [ 65/125][   190]  Loss: 0.315 (0.337)  Time: 0.012,0.016 254/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [ 75/125][   200]  Loss: 0.322 (0.337)  Time: 0.012,0.016 254/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [ 85/125][   210]  Loss: 0.338 (0.336)  Time: 0.012,0.016 254/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [ 95/125][   220]  Loss: 0.338 (0.336)  Time: 0.012,0.016 254/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [105/125][   230]  Loss: 0.333 (0.336)  Time: 0.012,0.016 254/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [115/125][   240]  Loss: 0.331 (0.336)  Time: 0.012,0.016 254/s  Mem: 0.00,0.00 GB\n",
      "Eval friends s6\n",
      "Val:   1  Loss: 0.336  Acc: 0.260,0.267,0.286,0.247 (0.265)  Time: 0.005,0.006 157/s\n",
      "Eval movie10\n",
      "Val:   1  Loss: 0.354  Acc: 0.212,0.191,0.209,0.176 (0.197)  Time: 0.005,0.006 166/s\n",
      "Train friends s1-5\n",
      "Train:   2 [  0/125][   250]  Loss: 0.331 (0.331)  Time: 0.140,0.341 12/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [ 10/125][   260]  Loss: 0.330 (0.333)  Time: 0.024,0.046 87/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [ 20/125][   270]  Loss: 0.344 (0.333)  Time: 0.019,0.032 125/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [ 30/125][   280]  Loss: 0.334 (0.333)  Time: 0.017,0.027 149/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [ 40/125][   290]  Loss: 0.330 (0.333)  Time: 0.016,0.024 164/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [ 50/125][   300]  Loss: 0.346 (0.333)  Time: 0.015,0.023 174/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [ 60/125][   310]  Loss: 0.328 (0.333)  Time: 0.015,0.022 181/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [ 70/125][   320]  Loss: 0.331 (0.332)  Time: 0.015,0.022 185/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [ 80/125][   330]  Loss: 0.325 (0.332)  Time: 0.015,0.021 190/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [ 90/125][   340]  Loss: 0.329 (0.332)  Time: 0.014,0.021 194/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [100/125][   350]  Loss: 0.330 (0.332)  Time: 0.014,0.020 197/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [110/125][   360]  Loss: 0.330 (0.332)  Time: 0.014,0.020 200/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [120/125][   370]  Loss: 0.334 (0.332)  Time: 0.014,0.020 202/s  Mem: 0.00,0.00 GB\n",
      "Eval friends s6\n",
      "Val:   2  Loss: 0.334  Acc: 0.268,0.275,0.294,0.254 (0.272)  Time: 0.006,0.007 134/s\n",
      "Eval movie10\n",
      "Val:   2  Loss: 0.353  Acc: 0.221,0.198,0.216,0.183 (0.204)  Time: 0.005,0.006 164/s\n",
      "Train friends s1-5\n",
      "Train:   3 [  5/125][   380]  Loss: 0.334 (0.332)  Time: 0.013,0.019 215/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [ 15/125][   390]  Loss: 0.330 (0.331)  Time: 0.012,0.017 233/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [ 25/125][   400]  Loss: 0.335 (0.331)  Time: 0.012,0.017 237/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [ 35/125][   410]  Loss: 0.336 (0.330)  Time: 0.012,0.017 239/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [ 45/125][   420]  Loss: 0.320 (0.330)  Time: 0.012,0.017 241/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [ 55/125][   430]  Loss: 0.330 (0.329)  Time: 0.012,0.017 241/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [ 65/125][   440]  Loss: 0.329 (0.329)  Time: 0.012,0.017 242/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [ 75/125][   450]  Loss: 0.317 (0.329)  Time: 0.012,0.017 241/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [ 85/125][   460]  Loss: 0.325 (0.329)  Time: 0.012,0.017 242/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [ 95/125][   470]  Loss: 0.324 (0.329)  Time: 0.012,0.017 242/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [105/125][   480]  Loss: 0.322 (0.329)  Time: 0.012,0.017 242/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [115/125][   490]  Loss: 0.334 (0.329)  Time: 0.012,0.016 243/s  Mem: 0.00,0.00 GB\n",
      "Eval friends s6\n",
      "Val:   3  Loss: 0.334  Acc: 0.271,0.279,0.298,0.257 (0.276)  Time: 0.005,0.006 165/s\n",
      "Eval movie10\n",
      "Val:   3  Loss: 0.352  Acc: 0.223,0.201,0.218,0.185 (0.207)  Time: 0.004,0.005 189/s\n",
      "Train friends s1-5\n",
      "Train:   4 [  0/125][   500]  Loss: 0.327 (0.327)  Time: 0.014,0.024 163/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [ 10/125][   510]  Loss: 0.323 (0.325)  Time: 0.012,0.017 241/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [ 20/125][   520]  Loss: 0.327 (0.327)  Time: 0.012,0.016 248/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [ 30/125][   530]  Loss: 0.332 (0.327)  Time: 0.012,0.016 248/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [ 40/125][   540]  Loss: 0.354 (0.329)  Time: 0.012,0.016 250/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [ 50/125][   550]  Loss: 0.338 (0.329)  Time: 0.012,0.016 250/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [ 60/125][   560]  Loss: 0.327 (0.329)  Time: 0.012,0.016 250/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [ 70/125][   570]  Loss: 0.336 (0.328)  Time: 0.012,0.016 250/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [ 80/125][   580]  Loss: 0.324 (0.328)  Time: 0.012,0.016 250/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [ 90/125][   590]  Loss: 0.330 (0.328)  Time: 0.012,0.016 250/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [100/125][   600]  Loss: 0.330 (0.328)  Time: 0.012,0.016 251/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [110/125][   610]  Loss: 0.328 (0.328)  Time: 0.012,0.016 251/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [120/125][   620]  Loss: 0.325 (0.328)  Time: 0.012,0.016 251/s  Mem: 0.00,0.00 GB\n",
      "Eval friends s6\n",
      "Val:   4  Loss: 0.334  Acc: 0.273,0.278,0.298,0.258 (0.277)  Time: 0.005,0.006 164/s\n",
      "Eval movie10\n",
      "Val:   4  Loss: 0.352  Acc: 0.224,0.200,0.219,0.185 (0.207)  Time: 0.005,0.006 166/s\n",
      "Train friends s1-5\n",
      "Train:   5 [  5/125][   630]  Loss: 0.322 (0.326)  Time: 0.015,0.019 208/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [ 15/125][   640]  Loss: 0.322 (0.328)  Time: 0.014,0.018 219/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [ 25/125][   650]  Loss: 0.333 (0.326)  Time: 0.014,0.018 223/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [ 35/125][   660]  Loss: 0.327 (0.326)  Time: 0.014,0.018 224/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [ 45/125][   670]  Loss: 0.333 (0.326)  Time: 0.014,0.018 225/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [ 55/125][   680]  Loss: 0.327 (0.326)  Time: 0.014,0.018 219/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [ 65/125][   690]  Loss: 0.315 (0.326)  Time: 0.014,0.018 220/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [ 75/125][   700]  Loss: 0.321 (0.326)  Time: 0.014,0.018 221/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [ 85/125][   710]  Loss: 0.321 (0.326)  Time: 0.014,0.018 222/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [ 95/125][   720]  Loss: 0.328 (0.326)  Time: 0.014,0.018 224/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [105/125][   730]  Loss: 0.325 (0.326)  Time: 0.014,0.018 226/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [115/125][   740]  Loss: 0.317 (0.326)  Time: 0.013,0.018 228/s  Mem: 0.00,0.00 GB\n",
      "Eval friends s6\n",
      "Val:   5  Loss: 0.333  Acc: 0.273,0.279,0.300,0.258 (0.277)  Time: 0.006,0.007 137/s\n",
      "Eval movie10\n",
      "Val:   5  Loss: 0.352  Acc: 0.224,0.199,0.217,0.184 (0.206)  Time: 0.005,0.006 161/s\n",
      "Train friends s1-5\n",
      "Train:   6 [  0/125][   750]  Loss: 0.319 (0.319)  Time: 0.016,0.024 169/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [ 10/125][   760]  Loss: 0.324 (0.323)  Time: 0.014,0.018 219/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [ 20/125][   770]  Loss: 0.318 (0.323)  Time: 0.014,0.018 224/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [ 30/125][   780]  Loss: 0.319 (0.324)  Time: 0.014,0.018 225/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [ 40/125][   790]  Loss: 0.324 (0.324)  Time: 0.014,0.018 224/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [ 50/125][   800]  Loss: 0.322 (0.324)  Time: 0.014,0.018 224/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [ 60/125][   810]  Loss: 0.333 (0.324)  Time: 0.014,0.018 225/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [ 70/125][   820]  Loss: 0.333 (0.323)  Time: 0.014,0.018 227/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [ 80/125][   830]  Loss: 0.325 (0.323)  Time: 0.013,0.018 228/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [ 90/125][   840]  Loss: 0.323 (0.323)  Time: 0.013,0.017 229/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [100/125][   850]  Loss: 0.333 (0.323)  Time: 0.013,0.017 230/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [110/125][   860]  Loss: 0.329 (0.323)  Time: 0.013,0.017 230/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [120/125][   870]  Loss: 0.316 (0.323)  Time: 0.013,0.017 229/s  Mem: 0.00,0.00 GB\n",
      "Eval friends s6\n",
      "Val:   6  Loss: 0.333  Acc: 0.273,0.279,0.300,0.258 (0.278)  Time: 0.006,0.008 129/s\n",
      "Eval movie10\n",
      "Val:   6  Loss: 0.354  Acc: 0.222,0.199,0.217,0.183 (0.205)  Time: 0.005,0.006 158/s\n",
      "Train friends s1-5\n",
      "Train:   7 [  5/125][   880]  Loss: 0.348 (0.325)  Time: 0.015,0.020 202/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [ 15/125][   890]  Loss: 0.319 (0.325)  Time: 0.014,0.019 214/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [ 25/125][   900]  Loss: 0.325 (0.324)  Time: 0.014,0.019 215/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [ 35/125][   910]  Loss: 0.326 (0.322)  Time: 0.014,0.019 215/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [ 45/125][   920]  Loss: 0.318 (0.322)  Time: 0.014,0.019 214/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [ 55/125][   930]  Loss: 0.333 (0.322)  Time: 0.015,0.019 213/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [ 65/125][   940]  Loss: 0.323 (0.322)  Time: 0.015,0.019 213/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [ 75/125][   950]  Loss: 0.323 (0.322)  Time: 0.015,0.019 213/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [ 85/125][   960]  Loss: 0.324 (0.322)  Time: 0.014,0.019 215/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [ 95/125][   970]  Loss: 0.333 (0.322)  Time: 0.014,0.019 216/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [105/125][   980]  Loss: 0.321 (0.322)  Time: 0.014,0.018 217/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [115/125][   990]  Loss: 0.328 (0.322)  Time: 0.014,0.018 218/s  Mem: 0.00,0.00 GB\n",
      "Eval friends s6\n",
      "Val:   7  Loss: 0.334  Acc: 0.273,0.279,0.298,0.257 (0.277)  Time: 0.005,0.006 156/s\n",
      "Eval movie10\n",
      "Val:   7  Loss: 0.354  Acc: 0.221,0.198,0.215,0.182 (0.204)  Time: 0.004,0.005 182/s\n",
      "Train friends s1-5\n",
      "Train:   8 [  0/125][  1000]  Loss: 0.321 (0.321)  Time: 0.015,0.021 189/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [ 10/125][  1010]  Loss: 0.324 (0.321)  Time: 0.013,0.017 229/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [ 20/125][  1020]  Loss: 0.309 (0.321)  Time: 0.013,0.017 233/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [ 30/125][  1030]  Loss: 0.333 (0.321)  Time: 0.013,0.017 234/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [ 40/125][  1040]  Loss: 0.325 (0.322)  Time: 0.013,0.017 234/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [ 50/125][  1050]  Loss: 0.322 (0.322)  Time: 0.013,0.017 234/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [ 60/125][  1060]  Loss: 0.318 (0.322)  Time: 0.013,0.017 231/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [ 70/125][  1070]  Loss: 0.314 (0.322)  Time: 0.013,0.017 230/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [ 80/125][  1080]  Loss: 0.329 (0.322)  Time: 0.013,0.017 230/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [ 90/125][  1090]  Loss: 0.331 (0.322)  Time: 0.013,0.018 228/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [100/125][  1100]  Loss: 0.319 (0.322)  Time: 0.013,0.018 227/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [110/125][  1110]  Loss: 0.322 (0.321)  Time: 0.013,0.018 228/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [120/125][  1120]  Loss: 0.324 (0.321)  Time: 0.013,0.018 228/s  Mem: 0.00,0.00 GB\n",
      "Eval friends s6\n",
      "Val:   8  Loss: 0.334  Acc: 0.272,0.277,0.297,0.255 (0.275)  Time: 0.006,0.007 145/s\n",
      "Eval movie10\n",
      "Val:   8  Loss: 0.355  Acc: 0.220,0.197,0.213,0.181 (0.203)  Time: 0.005,0.007 152/s\n",
      "Train friends s1-5\n",
      "Train:   9 [  5/125][  1130]  Loss: 0.324 (0.320)  Time: 0.014,0.019 215/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [ 15/125][  1140]  Loss: 0.310 (0.318)  Time: 0.013,0.017 233/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [ 25/125][  1150]  Loss: 0.316 (0.319)  Time: 0.013,0.017 238/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [ 35/125][  1160]  Loss: 0.321 (0.319)  Time: 0.012,0.017 241/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [ 45/125][  1170]  Loss: 0.314 (0.320)  Time: 0.012,0.017 242/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [ 55/125][  1180]  Loss: 0.320 (0.320)  Time: 0.012,0.017 242/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [ 65/125][  1190]  Loss: 0.323 (0.320)  Time: 0.012,0.016 243/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [ 75/125][  1200]  Loss: 0.316 (0.320)  Time: 0.012,0.016 244/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [ 85/125][  1210]  Loss: 0.314 (0.320)  Time: 0.012,0.016 244/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [ 95/125][  1220]  Loss: 0.311 (0.320)  Time: 0.012,0.016 244/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [105/125][  1230]  Loss: 0.315 (0.321)  Time: 0.012,0.016 245/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [115/125][  1240]  Loss: 0.318 (0.321)  Time: 0.012,0.016 245/s  Mem: 0.00,0.00 GB\n",
      "Eval friends s6\n",
      "Val:   9  Loss: 0.335  Acc: 0.270,0.276,0.296,0.255 (0.274)  Time: 0.005,0.006 165/s\n",
      "Eval movie10\n",
      "Val:   9  Loss: 0.356  Acc: 0.218,0.194,0.211,0.178 (0.200)  Time: 0.005,0.006 176/s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(\"Train friends s1-5\")\n",
    "    train_one_epoch(\n",
    "        epoch=epoch,\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        optimizer=optimizer,\n",
    "        epoch_batches=epoch_batches,\n",
    "        device=device,\n",
    "    )\n",
    "    print(\"Eval friends s6\")\n",
    "    val_acc, val_metrics = validate(\n",
    "        epoch=epoch,\n",
    "        model=model,\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "    )\n",
    "    print(\"Eval movie10\")\n",
    "    test_acc, test_metrics = validate(\n",
    "        epoch=epoch,\n",
    "        model=model,\n",
    "        val_loader=test_loader,\n",
    "        device=device,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322777c0",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "First layer per model\n",
    "\n",
    "```\n",
    "Eval friends s6\n",
    "Val:   9  Loss: 0.335  Acc: 0.266,0.271,0.292,0.251 (0.270)  Time: 0.003,0.004 235/s\n",
    "Eval movie10\n",
    "Val:   9  Loss: 0.356  Acc: 0.214,0.190,0.208,0.177 (0.197)  Time: 0.003,0.004 257/s\n",
    "```\n",
    "\n",
    "First and last layers per model\n",
    "\n",
    "```\n",
    "Eval friends s6\n",
    "Val:   9  Loss: 0.335  Acc: 0.270,0.276,0.296,0.255 (0.274)  Time: 0.006,0.007 150/s\n",
    "Eval movie10\n",
    "Val:   9  Loss: 0.356  Acc: 0.218,0.194,0.211,0.178 (0.200)  Time: 0.005,0.006 164/s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e683cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
