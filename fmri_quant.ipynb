{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import os, sys\n",
    "sys.path.insert(0, '/home/ri4541/algonauts2025/vector-quantize-pytorch/vector_quantize_pytorch')\n",
    "import vector_quantize_pytorch\n",
    "from vector_quantize_pytorch import VectorQuantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert dim % num_heads == 0, f\"dim {dim} must be divisible by num_heads {num_heads}\"\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dim // num_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        \n",
    "        # Separate projections for Q, K, V\n",
    "        self.q_proj = nn.Linear(dim, dim)\n",
    "        self.k_proj = nn.Linear(dim, dim)\n",
    "        self.v_proj = nn.Linear(dim, dim)\n",
    "        \n",
    "        self.out_proj = nn.Linear(dim, dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape  # batch, num_tokens, channels\n",
    "        H = self.num_heads\n",
    "\n",
    "        # Generate Q, K, V with separate projections\n",
    "        q = self.q_proj(x).reshape(B, N, H, self.head_dim).transpose(1, 2)  # B, H, N, head_dim\n",
    "        k = self.k_proj(x).reshape(B, N, H, self.head_dim).transpose(1, 2)\n",
    "        v = self.v_proj(x).reshape(B, N, H, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Attention\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale  # B, H, N, N\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "        \n",
    "        # Apply attention to V\n",
    "        out = (attn @ v).transpose(1, 2).reshape(B, N, C)  # B, N, C\n",
    "        out = self.out_proj(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads=2, mlp_ratio=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.attn = MultiHeadAttention(dim, num_heads, dropout)\n",
    "        \n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, mlp_hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_hidden_dim, dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pre-norm architecture\n",
    "        x = x + self.attn(self.norm1(x))\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class CustomViTEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=1000,\n",
    "        num_tokens=32,\n",
    "        token_dim=8,\n",
    "        num_layers=4,\n",
    "        num_heads=2,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_tokens = num_tokens\n",
    "        self.token_dim = token_dim\n",
    "        \n",
    "        # Initial projection and reshape\n",
    "        self.input_proj = nn.Sequential(\n",
    "            nn.Linear(input_dim, num_tokens * token_dim),\n",
    "            # nn.LayerNorm(num_tokens * token_dim),\n",
    "            # nn.GELU(),\n",
    "            # # nn.Dropout(dropout),\n",
    "            # nn.Linear(num_tokens * token_dim, num_tokens * token_dim),\n",
    "            # # nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Positional embedding\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, num_tokens, token_dim) * 0.02)  # smaller init\n",
    "        \n",
    "        # Transformer layers\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(\n",
    "                dim=token_dim,\n",
    "                num_heads=num_heads,\n",
    "                mlp_ratio=2,\n",
    "                dropout=dropout\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.norm = nn.LayerNorm(token_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Project and reshape: [B, 1000] -> [B, 32, 8]\n",
    "        x = self.input_proj(x)\n",
    "        x = x.reshape(-1, self.num_tokens, self.token_dim)\n",
    "        \n",
    "        # Add positional embeddings and dropout\n",
    "        x = x + self.pos_embed\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Apply transformer blocks\n",
    "        # print(\"input shape: \", x.shape)\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "# Mirror image of encoder for decoder\n",
    "class CustomViTDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim=1000,\n",
    "        num_tokens=32,\n",
    "        token_dim=8,\n",
    "        num_layers=4,\n",
    "        num_heads=2,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_tokens = num_tokens\n",
    "        self.token_dim = token_dim\n",
    "        \n",
    "        # Positional embedding\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, num_tokens, token_dim) * 0.02)\n",
    "        \n",
    "        # Transformer layers\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(\n",
    "                dim=token_dim,\n",
    "                num_heads=num_heads,\n",
    "                mlp_ratio=2,\n",
    "                dropout=dropout\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.norm = nn.LayerNorm(token_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Output projection\n",
    "        self.output_proj = nn.Sequential(\n",
    "            nn.Linear(num_tokens * token_dim, output_dim),\n",
    "            # nn.LayerNorm(num_tokens * token_dim),\n",
    "            # nn.GELU(),\n",
    "            # # nn.Dropout(dropout),\n",
    "            # nn.Linear(num_tokens * token_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Add positional embeddings and dropout\n",
    "        x = x + self.pos_embed\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Apply transformer blocks\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.norm(x)\n",
    "        \n",
    "        # Project back to original dimension\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.output_proj(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torchmetrics.functional import pearson_corrcoef\n",
    "\n",
    "class VQVAE(L.LightningModule):\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_dim=1000, \n",
    "            hidden_dims=[512, 384, 256], \n",
    "            num_tokens=32,\n",
    "            num_layers=2,\n",
    "            codebook_size=1024, \n",
    "            codebook_dim=8,\n",
    "            commitment_weight=0.25,\n",
    "            quantizer_decay=0.99,\n",
    "            learning_rate=3e-4,\n",
    "            weight_decay=0.01\n",
    "            ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = CustomViTEncoder(num_layers=num_layers, token_dim=codebook_dim)\n",
    "        self.decoder = CustomViTDecoder(num_layers=num_layers, token_dim=codebook_dim)\n",
    "        self.quantizer = VectorQuantize(\n",
    "                dim=codebook_dim,\n",
    "                codebook_size=codebook_size,\n",
    "                decay=quantizer_decay,\n",
    "                commitment_weight=commitment_weight,\n",
    "                )\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        #Temperature scheduling for Vector Quantizer\n",
    "        self.temp = 1.0\n",
    "        self.min_temp = 0.5\n",
    "        self.temp_anneal_rate = 0.999\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "    # def on_train_batch_start(self, batch, batch_idx):\n",
    "    #     self.temp = max(self.min_temp, self.temp * self.temp_anneal_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        # if self.training:\n",
    "        #     z = z / self.temp\n",
    "        z_q, indices, commitment_loss = self.quantizer(z)\n",
    "        x_recon = self.decoder(z_q)\n",
    "        return x_recon, commitment_loss, indices\n",
    "    \n",
    "    def calculate_metrics(self, x, x_recon):\n",
    "        # Flatten the tensors for correlation calculation\n",
    "        x = x.to(torch.float64)\n",
    "        x_recon = x_recon.to(torch.float64)\n",
    "        x_flat = x.reshape(x.shape[0], -1)\n",
    "        x_recon_flat = x_recon.reshape(x_recon.shape[0], -1)\n",
    "        \n",
    "        # Calculate Pearson R for each sample in batch\n",
    "        correlations = torch.stack([\n",
    "            pearson_corrcoef(x_flat[i], x_recon_flat[i])\n",
    "            for i in range(x_flat.shape[0])\n",
    "        ])\n",
    "        avg_pearson_r = correlations.mean()\n",
    "        \n",
    "        # Calculate variance explained\n",
    "        total_variance = torch.var(x_flat, dim=1).sum()\n",
    "        residual_variance = torch.var(x_flat - x_recon_flat, dim=1).sum()\n",
    "        variance_explained = 1 - (residual_variance / total_variance)\n",
    "        \n",
    "        return avg_pearson_r, variance_explained\n",
    "\n",
    "\n",
    "    def training_step(self, batch: torch.Tensor, batch_idx: int) -> torch.Tensor:\n",
    "        x = batch[0]\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        x_recon, commitment_loss, _ = self(x)\n",
    "        \n",
    "        recon_loss = F.mse_loss(x_recon, x)\n",
    "        total_loss = recon_loss + commitment_loss\n",
    "\n",
    "        pearson_r, var = self.calculate_metrics(x, x_recon)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('train_loss', total_loss)\n",
    "        self.log('temperature', self.temp)\n",
    "        self.log('train_recon_loss', recon_loss)\n",
    "        self.log('train_commitment_loss', commitment_loss)\n",
    "        self.log('train_pearson_r', pearson_r)\n",
    "        self.log('train_variance', var)\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    def validation_step(self, batch: torch.Tensor, batch_idx: int) -> torch.Tensor:\n",
    "        x = batch[0]\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        x_recon, commitment_loss, _ = self(x)\n",
    "        \n",
    "        recon_loss = F.mse_loss(x_recon, x)\n",
    "        total_loss = recon_loss + commitment_loss\n",
    "\n",
    "        val_pearson_r, val_var = self.calculate_metrics(x, x_recon)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('val_loss', total_loss)\n",
    "        self.log('val_recon_loss', recon_loss)\n",
    "        self.log('val_pearson_r', val_pearson_r)\n",
    "        self.log('val_variance', val_var)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Separate parameter groups for different learning rates\n",
    "        encoder_decoder_params = []\n",
    "        quantizer_params = []\n",
    "        \n",
    "        # Group parameters\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'quantizer' in name:\n",
    "                quantizer_params.append(param)\n",
    "            else:\n",
    "                encoder_decoder_params.append(param)\n",
    "        \n",
    "        # Create optimizer with parameter groups\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {\n",
    "                'params': encoder_decoder_params,\n",
    "                'lr': self.learning_rate,\n",
    "                'weight_decay': self.weight_decay\n",
    "            },\n",
    "            {\n",
    "                'params': quantizer_params,\n",
    "                'lr': self.learning_rate * 0.5,  # Lower learning rate for quantizer\n",
    "                'weight_decay': 0  # Usually no weight decay for quantizer\n",
    "            }\n",
    "        ], betas=(0.9, 0.999), eps=1e-8)\n",
    "        \n",
    "        # Scheduler setup\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=1e-6,\n",
    "            verbose=True,\n",
    "            threshold=1e-4,\n",
    "            threshold_mode='rel'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",  # Metric to monitor\n",
    "            }\n",
    "        }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class FMRIDataset(Dataset):\n",
    "    def __init__(self, h5_file):\n",
    "        data_list = []\n",
    "        try:\n",
    "            with h5py.File(h5_file, 'r') as f:\n",
    "                for key in f.keys():\n",
    "                    data = torch.from_numpy(f[key][:]).float()\n",
    "                    data_list.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {h5_file}: {str(e)}\")\n",
    "        self.data = torch.cat(data_list, dim=0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Create separate datasets for train and val\n",
    "train_file = '/scratch/gpfs/ri4541/algonauts_2025.competitors/fmri/sub-01/func/sub-01_task-friends_space-MNI152NLin2009cAsym_atlas-Schaefer18_parcel-1000Par7Net_desc-s123456_bold.h5'\n",
    "val_file = '/scratch/gpfs/ri4541/algonauts_2025.competitors/fmri/sub-01/func/sub-01_task-movie10_space-MNI152NLin2009cAsym_atlas-Schaefer18_parcel-1000Par7Net_bold.h5'\n",
    "assert os.path.exists(train_file)\n",
    "assert os.path.exists(val_file)\n",
    "train_dataset = FMRIDataset(train_file)\n",
    "val_dataset = FMRIDataset(val_file)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 137913\n",
      "Validation samples: 24758\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_MODE'] = 'offline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/scratch/gpfs/ri4541/miniconda3/envs/algonauts/lib/python3.13/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "if not utils.is_interactive():\n",
    "    from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "    run_name = \"test5\"\n",
    "    project = \"fmri_vq_tokenizer\"\n",
    "    wandb_logger = WandbLogger(\n",
    "        project=project,\n",
    "        name=run_name,\n",
    "        save_dir=\"wandb_logs/\",\n",
    "        offline=True,\n",
    "        save_code=True\n",
    ")\n",
    "else:\n",
    "    wandb_logger = None\n",
    "    run_name = \"testing\"\n",
    "    project = \"testing\"\n",
    "    \n",
    "    \n",
    "trainer = L.Trainer(\n",
    "    max_epochs=-1,\n",
    "    precision=32,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            dirpath=f'checkpoints/{project}/{run_name}',\n",
    "            filename='{epoch:02d}_{val_loss:.3f}',\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_top_k=1,\n",
    "            save_last=True\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            patience=10,\n",
    "            verbose=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name                       | Type              | Params | Mode \n",
      "--------------------------------------------------------------------------\n",
      "0  | encoder                    | CustomViTEncoder  | 515 K  | train\n",
      "1  | encoder.input_proj         | Sequential        | 512 K  | train\n",
      "2  | encoder.transformer_blocks | ModuleList        | 2.2 K  | train\n",
      "3  | encoder.norm               | LayerNorm         | 32     | train\n",
      "4  | encoder.dropout            | Dropout           | 0      | train\n",
      "5  | decoder                    | CustomViTDecoder  | 515 K  | train\n",
      "6  | decoder.transformer_blocks | ModuleList        | 2.2 K  | train\n",
      "7  | decoder.norm               | LayerNorm         | 32     | train\n",
      "8  | decoder.dropout            | Dropout           | 0      | train\n",
      "9  | decoder.output_proj        | Sequential        | 513 K  | train\n",
      "10 | quantizer                  | VectorQuantize    | 0      | train\n",
      "11 | quantizer.project_in       | Identity          | 0      | train\n",
      "12 | quantizer.project_out      | Identity          | 0      | train\n",
      "13 | quantizer._codebook        | EuclideanCodebook | 0      | train\n",
      "--------------------------------------------------------------------------\n",
      "1.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 M     Total params\n",
      "4.124     Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "torch.set_float32_matmul_precision('high')\n",
    "model = VQVAE(num_layers=1, codebook_dim=16, codebook_size=1024, commitment_weight=0.8)\n",
    "summary = ModelSummary(model, max_depth=2)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | encoder   | CustomViTEncoder | 515 K  | train\n",
      "1 | decoder   | CustomViTDecoder | 515 K  | train\n",
      "2 | quantizer | VectorQuantize   | 0      | train\n",
      "-------------------------------------------------------\n",
      "1.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 M     Total params\n",
      "4.124     Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a522bbafea044470b07421f01cd59cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fab521200064dddbdde6f2011e4e281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90603ca6b669411496ed7b6b0ac3c6b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef4d4cf0c354d3c97828c8a40bc11c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.0. New best score: 0.178\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dac77bb107043bba58c1faa01839d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb26170484d5415caf27b62908985397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75a6cfe5f3b4cb59035d189ca849186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.020 >= min_delta = 0.0. New best score: 0.152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b4f288711444338f7e76d86353254e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.007 >= min_delta = 0.0. New best score: 0.144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0c64f2696f4a2d9b754c231d6ce36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.141\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e93a53b32394565a6ed9660d50092b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.139\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24902319ebee4514ae795e91fe14fc62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.138\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22ed7c843f14c3dbe3b9986d45f272c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6d3cb84a144e05b051c1caf4fee09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6398a10f7a8e40109bb1bf7b773413f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4830f2a22bbc43deb8acd11014f94e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7385f30eca954ebab95d77e5f8552197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.002 >= min_delta = 0.0. New best score: 0.132\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa119bceeeea467db8bfe0d92af798a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.131\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7b3bc9e1c44b5485e92e3f276b8016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.131\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e971981e55d646759b6b7e27be40e3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.130\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e05670884324c34b3103d11e2f0c94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f337c07bd14b12a627da9d3f788c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65e6199bf2c4a9f8db05e9c5cf86fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3756094d9748b0991c3fde704f27f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.127\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819a9de25a5d4107bdae7ba5a56137a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628780262a154fd288e9e5c2ec604937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.127\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53e4f30f79942b895cba25644ccedde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "638839d7d6924f608d545984ddb2c747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e45b32eebd43bfa1b61c97c6789ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca67f49088c247bd877366b2aa765a10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.000 >= min_delta = 0.0. New best score: 0.127\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fec53300b7a46f2b7db4d251fa97d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 0.126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc5eb8ee51b4de8bad1997773dc50d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4bed31418a943b8ae805c2d6d2615e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c067213da584b9da5a02d7c65c7a8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb55c8011aaa478dbd738428efa35e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56fcfdbae1f4b879d2198c81f0568e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b0195ae53b41449fc452d3bf4caddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b16a302e2e4c7388c6762e3aee6df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd047deafee404a9f40c246541b5859",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8489f768290f477b84456e01c9ced7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0519959d4ef48e58d399de67f4e03f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 0.126. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not utils.is_interactive():\n",
    "    import wandb\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/scratch/gpfs/ri4541/algonauts2025/checkpoints/fmri_vq_tokenizer/fmri_1_VIT_vq_08comm_16qdim/epoch=55_val_pearson_r=0.800.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model = VQVAE()\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mVQVAE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/scratch/gpfs/ri4541/algonauts2025/checkpoints/fmri_vq_tokenizer/fmri_1_VIT_vq_08comm_16qdim/epoch=55_val_pearson_r=0.800.ckpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      4\u001b[0m val_data \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/scratch/gpfs/ri4541/miniconda3/envs/algonauts/lib/python3.13/site-packages/lightning/pytorch/utilities/model_helpers.py:125\u001b[0m, in \u001b[0;36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` cannot be called on an instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gpfs/ri4541/miniconda3/envs/algonauts/lib/python3.13/site-packages/lightning/pytorch/core/module.py:1581\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1500\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1579\u001b[0m \n\u001b[1;32m   1580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1581\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1589\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m/scratch/gpfs/ri4541/miniconda3/envs/algonauts/lib/python3.13/site-packages/lightning/pytorch/core/saving.py:63\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m map_location \u001b[38;5;241m=\u001b[39m map_location \u001b[38;5;129;01mor\u001b[39;00m _default_map_location\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[0;32m---> 63\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# convert legacy checkpoints to the new format\u001b[39;00m\n\u001b[1;32m     66\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m _pl_migrate_checkpoint(\n\u001b[1;32m     67\u001b[0m     checkpoint, checkpoint_path\u001b[38;5;241m=\u001b[39m(checkpoint_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint_path, (\u001b[38;5;28mstr\u001b[39m, Path)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     68\u001b[0m )\n",
      "File \u001b[0;32m/scratch/gpfs/ri4541/miniconda3/envs/algonauts/lib/python3.13/site-packages/lightning/fabric/utilities/cloud_io.py:59\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(path_or_url, map_location, weights_only)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload_state_dict_from_url(\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28mstr\u001b[39m(path_or_url),\n\u001b[1;32m     55\u001b[0m         map_location\u001b[38;5;241m=\u001b[39mmap_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     56\u001b[0m         weights_only\u001b[38;5;241m=\u001b[39mweights_only,\n\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     58\u001b[0m fs \u001b[38;5;241m=\u001b[39m get_filesystem(path_or_url)\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m     61\u001b[0m         f,\n\u001b[1;32m     62\u001b[0m         map_location\u001b[38;5;241m=\u001b[39mmap_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     63\u001b[0m         weights_only\u001b[38;5;241m=\u001b[39mweights_only,\n\u001b[1;32m     64\u001b[0m     )\n",
      "File \u001b[0;32m/scratch/gpfs/ri4541/miniconda3/envs/algonauts/lib/python3.13/site-packages/fsspec/spec.py:1310\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1309\u001b[0m     ac \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mautocommit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_intrans)\n\u001b[0;32m-> 1310\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1319\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m/scratch/gpfs/ri4541/miniconda3/envs/algonauts/lib/python3.13/site-packages/fsspec/implementations/local.py:200\u001b[0m, in \u001b[0;36mLocalFileSystem._open\u001b[0;34m(self, path, mode, block_size, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent(path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gpfs/ri4541/miniconda3/envs/algonauts/lib/python3.13/site-packages/fsspec/implementations/local.py:364\u001b[0m, in \u001b[0;36mLocalFileOpener.__init__\u001b[0;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;241m=\u001b[39m get_compression(path, compression)\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocksize \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[0;32m--> 364\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/gpfs/ri4541/miniconda3/envs/algonauts/lib/python3.13/site-packages/fsspec/implementations/local.py:369\u001b[0m, in \u001b[0;36mLocalFileOpener._open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf\u001b[38;5;241m.\u001b[39mclosed:\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m--> 369\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression:\n\u001b[1;32m    371\u001b[0m             compress \u001b[38;5;241m=\u001b[39m compr[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/scratch/gpfs/ri4541/algonauts2025/checkpoints/fmri_vq_tokenizer/fmri_1_VIT_vq_08comm_16qdim/epoch=55_val_pearson_r=0.800.ckpt'"
     ]
    }
   ],
   "source": [
    "# model = VQVAE()\n",
    "model = VQVAE.load_from_checkpoint(\"/scratch/gpfs/ri4541/algonauts2025/checkpoints/fmri_vq_tokenizer/fmri_1_VIT_vq_08comm_16qdim/epoch=55_val_pearson_r=0.800.ckpt\")\n",
    "model.eval()\n",
    "val_data = []\n",
    "val_recon = []\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        x = batch[0].to(model.device)\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        x_recon, _, _ = model(x)\n",
    "        val_data.append(x)\n",
    "        val_recon.append(x_recon)\n",
    "\n",
    "val_data = torch.cat(val_data)\n",
    "val_recon = torch.cat(val_recon)\n",
    "\n",
    "#Calculating dead codes and perplexity\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize counters\n",
    "codebook_size = 1024\n",
    "counts = torch.zeros(codebook_size, device=\"cuda\")  # Use \"cpu\" if needed\n",
    "\n",
    "# Run inference on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader):\n",
    "        x = batch.to(model.device)\n",
    "        z_e = model.encoder(x)  # Get encoder output\n",
    "        z_q, indices, _ = model.quantizer(z_e)  # Assuming `vq_layer` returns indices\n",
    "        indices_flat = indices.view(-1)  # Flatten all batch/spatial dimensions\n",
    "        counts += torch.bincount(indices_flat, minlength=codebook_size)\n",
    "\n",
    "# Compute metrics\n",
    "num_dead_codes = (counts == 0).sum().item()\n",
    "prob = counts / (counts.sum() + 1e-10)\n",
    "perplexity = torch.exp(-torch.sum(prob * torch.log(prob + 1e-10)))\n",
    "\n",
    "print(f\"Dead codes: {num_dead_codes} / {codebook_size}\")\n",
    "print(f\"Perplexity: {perplexity.item():.1f} (max: {codebook_size})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot code frequencies\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(counts.cpu().numpy(), bins=50, log_scale=(False, True))\n",
    "plt.xlabel(\"Code Frequency (log scale)\")\n",
    "plt.title(\"Code Usage Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "codebook_vectors = model.quantizer.codebook.cpu().numpy()  # Shape [1024, 8]\n",
    "similarity = cosine_similarity(codebook_vectors)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(similarity, cmap=\"viridis\", vmin=-1, vmax=1)\n",
    "plt.colorbar(label=\"Cosine Similarity\")\n",
    "plt.title(\"Codebook Vector Similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Collect codebook vectors and their usage counts\n",
    "codebook = model.quantizer.codebook.cpu().numpy()\n",
    "counts_np = counts.cpu().numpy()\n",
    "\n",
    "# Run t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "codebook_2d = tsne.fit_transform(codebook)\n",
    "\n",
    "# Plot with color indicating usage frequency\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(codebook_2d[:, 0], codebook_2d[:, 1], c=np.log(counts_np + 1), cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Log(Usage Count + 1)\")\n",
    "plt.title(\"Codebook t-SNE Projection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_explained = 1 - torch.var(val_data - val_recon) / torch.var(val_data)\n",
    "pearson_r = torch.corrcoef(torch.stack([val_data.flatten(), val_recon.flatten()]))[0,1]\n",
    "mse = torch.mean((val_data - val_recon) ** 2)\n",
    "mae = torch.mean(torch.abs(val_data - val_recon))\n",
    "\n",
    "print(f\"Variance explained: {var_explained:.3f}\")\n",
    "print(f\"Pearson correlation: {pearson_r:.3f}\")\n",
    "print(f\"MSE: {mse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_codebook(model, val_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    usage_count = torch.zeros(model.quantizer.codebook_size, device=device)\n",
    "    total_tokens = 0\n",
    "    distances = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x = batch[0].to(device)\n",
    "            if len(x.shape) == 1:\n",
    "                x = x.unsqueeze(0)\n",
    "            # Get encoder output\n",
    "            z = model.encoder(x)\n",
    "            # Get quantizer outputs before quantization\n",
    "            z_flat = z.reshape(-1, z.shape[-1])\n",
    "            _, indices, _ = model.quantizer(z_flat)\n",
    "            \n",
    "            # Update usage count\n",
    "            unique, counts = torch.unique(indices, return_counts=True)\n",
    "            usage_count[unique] += counts\n",
    "            total_tokens += indices.numel()\n",
    "            \n",
    "            # Calculate distances to assigned codebook vectors\n",
    "            dists = torch.cdist(z_flat, model.quantizer.codebook)\n",
    "            distances.append(dists.min(dim=1)[0])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    usage_prob = usage_count / total_tokens\n",
    "    active_codes = (usage_count > 0).sum().item()\n",
    "    entropy = -(usage_prob * torch.log2(usage_prob + 1e-10)).sum().item()\n",
    "    distances = torch.cat(distances)\n",
    "    \n",
    "    print(f\"Active codebook vectors: {active_codes}/{model.quantizer.codebook_size}\")\n",
    "    print(f\"Codebook entropy: {entropy:.2f} bits\")\n",
    "    print(f\"Mean distance to codebook: {distances.mean():.4f}\")\n",
    "    print(f\"Distance std: {distances.std():.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'usage_count': usage_count.cpu(),\n",
    "        'usage_prob': usage_prob.cpu(),\n",
    "        'active_codes': active_codes,\n",
    "        'entropy': entropy,\n",
    "        'distances': distances.cpu(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_codebook(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algonauts",
   "language": "python",
   "name": "algonauts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
