{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from vector_quantize_pytorch import VectorQuantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "   def __init__(self, in_dim, out_dim):\n",
    "       super().__init__()\n",
    "       self.downsample = in_dim != out_dim\n",
    "       self.net = nn.Sequential(\n",
    "           nn.Linear(in_dim, out_dim),\n",
    "           nn.LayerNorm(out_dim),\n",
    "           nn.GELU(),\n",
    "           nn.Linear(out_dim, out_dim),\n",
    "           nn.LayerNorm(out_dim),\n",
    "           nn.GELU()\n",
    "       )\n",
    "       if self.downsample:\n",
    "           self.proj = nn.Linear(in_dim, out_dim)\n",
    "   \n",
    "   def forward(self, x):\n",
    "       if self.downsample:\n",
    "           return self.proj(x) + self.net(x)\n",
    "       return x + self.net(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "   def __init__(self, input_dim=1000, hidden_dims=[512, 384, 256], num_tokens=32, codebook_dim=64):\n",
    "       super().__init__()\n",
    "       \n",
    "       # Initial projection with one residual block\n",
    "       self.input_proj = ResidualBlock(input_dim, hidden_dims[0])\n",
    "       \n",
    "       # Main network with one residual block per layer\n",
    "       layers = []\n",
    "       for i in range(len(hidden_dims)-1):\n",
    "           layers.append(ResidualBlock(hidden_dims[i], hidden_dims[i+1]))\n",
    "       self.layers = nn.Sequential(*layers)\n",
    "       \n",
    "       # Project to token space with one residual block\n",
    "       self.token_proj = ResidualBlock(hidden_dims[-1], num_tokens * codebook_dim)\n",
    "       \n",
    "       self.num_tokens = num_tokens\n",
    "       self.codebook_dim = codebook_dim\n",
    "       \n",
    "   def forward(self, x):\n",
    "       x = self.input_proj(x)\n",
    "       x = self.layers(x)\n",
    "       x = self.token_proj(x)\n",
    "       return x.view(x.shape[0], self.num_tokens, self.codebook_dim)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "   def __init__(self, output_dim=1000, hidden_dims=[256, 384, 512], num_tokens=32, codebook_dim=64):\n",
    "       super().__init__()\n",
    "       \n",
    "       # Process tokens with one residual block\n",
    "       self.token_proj = ResidualBlock(num_tokens * codebook_dim, hidden_dims[0])\n",
    "       \n",
    "       # Main network with one residual block per layer\n",
    "       layers = []\n",
    "       for i in range(len(hidden_dims)-1):\n",
    "           layers.append(ResidualBlock(hidden_dims[i], hidden_dims[i+1]))\n",
    "       self.layers = nn.Sequential(*layers)\n",
    "       \n",
    "       # Final projection with one residual block\n",
    "       self.output_proj = ResidualBlock(hidden_dims[-1], output_dim)\n",
    "       \n",
    "   def forward(self, x):\n",
    "       # x shape: [batch_size, num_tokens, codebook_dim] \n",
    "       x = x.reshape(x.shape[0], -1)  # Flatten tokens\n",
    "       x = self.token_proj(x)\n",
    "       x = self.layers(x)\n",
    "       return self.output_proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torchmetrics.functional import pearson_corrcoef\n",
    "\n",
    "class VQVAE(L.LightningModule):\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_dim=1000, \n",
    "            hidden_dims=[512, 384, 256], \n",
    "            num_tokens=32, \n",
    "            codebook_size=1024, \n",
    "            codebook_dim=8,\n",
    "            commitment_weight=0.25,\n",
    "            quantizer_decay=0.99,\n",
    "            learning_rate=3e-4,\n",
    "            weight_decay=0.01\n",
    "            ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(input_dim, hidden_dims, num_tokens, codebook_dim)\n",
    "        self.decoder = Decoder(input_dim, hidden_dims[::-1], num_tokens, codebook_dim)\n",
    "        self.quantizer = VectorQuantize(\n",
    "                dim=codebook_dim,\n",
    "                codebook_size=codebook_size,\n",
    "                decay=quantizer_decay,\n",
    "                commitment_weight=commitment_weight\n",
    "                )\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z_q, indices, commitment_loss = self.quantizer(z)\n",
    "        x_recon = self.decoder(z_q)\n",
    "        return x_recon, commitment_loss, indices\n",
    "    \n",
    "    def calculate_metrics(self, x, x_recon):\n",
    "        # Flatten the tensors for correlation calculation\n",
    "        x_flat = x.reshape(x.shape[0], -1)\n",
    "        x_recon_flat = x_recon.reshape(x_recon.shape[0], -1)\n",
    "        \n",
    "        # Calculate Pearson R for each sample in batch\n",
    "        correlations = torch.stack([\n",
    "            pearson_corrcoef(x_flat[i], x_recon_flat[i])\n",
    "            for i in range(x_flat.shape[0])\n",
    "        ])\n",
    "        avg_pearson_r = correlations.mean()\n",
    "        \n",
    "        # Calculate variance explained\n",
    "        total_variance = torch.var(x_flat, dim=1).sum()\n",
    "        residual_variance = torch.var(x_flat - x_recon_flat, dim=1).sum()\n",
    "        variance_explained = 1 - (residual_variance / total_variance)\n",
    "        \n",
    "        return avg_pearson_r, variance_explained\n",
    "\n",
    "\n",
    "    def training_step(self, batch: torch.Tensor, batch_idx: int) -> torch.Tensor:\n",
    "        x = batch[0]\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        x_recon, commitment_loss, _ = self(x)\n",
    "        \n",
    "        recon_loss = F.mse_loss(x_recon, x)\n",
    "        total_loss = recon_loss + commitment_loss\n",
    "\n",
    "        pearson_r, var = self.calculate_metrics(x, x_recon)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('train_loss', total_loss)\n",
    "        self.log('train_recon_loss', recon_loss)\n",
    "        self.log('train_commitment_loss', commitment_loss)\n",
    "        self.log('train_pearson_r', pearson_r)\n",
    "        self.log('train_variance', var)\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    def validation_step(self, batch: torch.Tensor, batch_idx: int) -> torch.Tensor:\n",
    "        x = batch[0]\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        x_recon, commitment_loss, _ = self(x)\n",
    "        \n",
    "        recon_loss = F.mse_loss(x_recon, x)\n",
    "        total_loss = recon_loss + commitment_loss\n",
    "\n",
    "        val_pearson_r, val_var = self.calculate_metrics(x, x_recon)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('val_loss', total_loss)\n",
    "        self.log('val_recon_loss', recon_loss)\n",
    "        self.log('val_commitment_loss', commitment_loss)\n",
    "        self.log('val_pearson_r', val_pearson_r)\n",
    "        self.log('val_variance', val_var)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.learning_rate,  # Learning rate\n",
    "            betas=(0.9, 0.999),  # Beta parameters\n",
    "            eps=1e-8,  # Epsilon to prevent division by zero\n",
    "            weight_decay=self.weight_decay  # Weight decay for regularization\n",
    "        )\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class FMRIDataset(Dataset):\n",
    "    def __init__(self, h5_file):\n",
    "        data_list = []\n",
    "        try:\n",
    "            with h5py.File(h5_file, 'r') as f:\n",
    "                for key in f.keys():\n",
    "                    data = torch.from_numpy(f[key][:]).float()\n",
    "                    data_list.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {h5_file}: {str(e)}\")\n",
    "        self.data = torch.cat(data_list, dim=0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Create separate datasets for train and val\n",
    "train_file = '/home/pranav/mihir/algonauts_challenge/algonauts_2025.competitors/fmri/sub-01/func/sub-01_task-friends_space-MNI152NLin2009cAsym_atlas-Schaefer18_parcel-1000Par7Net_desc-s123456_bold.h5'\n",
    "val_file = '/home/pranav/mihir/algonauts_challenge/algonauts_2025.competitors/fmri/sub-01/func/sub-01_task-movie10_space-MNI152NLin2009cAsym_atlas-Schaefer18_parcel-1000Par7Net_bold.h5'\n",
    "\n",
    "train_dataset = FMRIDataset(train_file)\n",
    "val_dataset = FMRIDataset(val_file)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 137913\n",
      "Validation samples: 24758\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "run_name = \"fmri_vqvae_res_gelu_8qdim_1024\"\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"algonauts2025\",\n",
    "    name=run_name,\n",
    "    save_dir=\"wandb_logs/\"\n",
    ")\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=50,\n",
    "    precision=32,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            dirpath=f'checkpoints/{run_name}',\n",
    "            filename='{epoch:02d}_{val_loss:.3f}',\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_top_k=1,\n",
    "            save_last=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name                  | Type              | Params | Mode \n",
      "---------------------------------------------------------------------\n",
      "0  | encoder               | Encoder           | 2.2 M  | train\n",
      "1  | encoder.input_proj    | ResidualBlock     | 1.3 M  | train\n",
      "2  | encoder.layers        | Sequential        | 807 K  | train\n",
      "3  | encoder.token_proj    | ResidualBlock     | 132 K  | train\n",
      "4  | decoder               | Decoder           | 3.2 M  | train\n",
      "5  | decoder.token_proj    | ResidualBlock     | 132 K  | train\n",
      "6  | decoder.layers        | Sequential        | 1.0 M  | train\n",
      "7  | decoder.output_proj   | ResidualBlock     | 2.0 M  | train\n",
      "8  | quantizer             | VectorQuantize    | 0      | train\n",
      "9  | quantizer.project_in  | Identity          | 0      | train\n",
      "10 | quantizer.project_out | Identity          | 0      | train\n",
      "11 | quantizer._codebook   | EuclideanCodebook | 0      | train\n",
      "---------------------------------------------------------------------\n",
      "5.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.4 M     Total params\n",
      "21.596    Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "torch.set_float32_matmul_precision('high')\n",
    "model = VQVAE()\n",
    "summary = ModelSummary(model, max_depth=2)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VQVAE(\n",
       "  (encoder): Encoder(\n",
       "    (input_proj): ResidualBlock(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=1000, out_features=512, bias=True)\n",
       "        (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (5): GELU(approximate='none')\n",
       "      )\n",
       "      (proj): Linear(in_features=1000, out_features=512, bias=True)\n",
       "    )\n",
       "    (layers): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=512, out_features=384, bias=True)\n",
       "          (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (4): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (5): GELU(approximate='none')\n",
       "        )\n",
       "        (proj): Linear(in_features=512, out_features=384, bias=True)\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=256, bias=True)\n",
       "          (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (5): GELU(approximate='none')\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (token_proj): ResidualBlock(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (5): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (token_proj): ResidualBlock(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (5): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "    (layers): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=384, bias=True)\n",
       "          (1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (4): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (5): GELU(approximate='none')\n",
       "        )\n",
       "        (proj): Linear(in_features=256, out_features=384, bias=True)\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=384, out_features=512, bias=True)\n",
       "          (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (2): GELU(approximate='none')\n",
       "          (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (5): GELU(approximate='none')\n",
       "        )\n",
       "        (proj): Linear(in_features=384, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (output_proj): ResidualBlock(\n",
       "      (net): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=1000, bias=True)\n",
       "        (1): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): GELU(approximate='none')\n",
       "        (3): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "        (4): LayerNorm((1000,), eps=1e-05, elementwise_affine=True)\n",
       "        (5): GELU(approximate='none')\n",
       "      )\n",
       "      (proj): Linear(in_features=512, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (quantizer): VectorQuantize(\n",
       "    (project_in): Identity()\n",
       "    (project_out): Identity()\n",
       "    (_codebook): EuclideanCodebook()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmihir-neal\u001b[0m (\u001b[33mmihirneal\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>wandb_logs/wandb/run-20250124_145831-zmu4es3o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mihirneal/algonauts2025/runs/zmu4es3o' target=\"_blank\">fmri_vqvae_res_gelu_8qdim_1024</a></strong> to <a href='https://wandb.ai/mihirneal/algonauts2025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mihirneal/algonauts2025' target=\"_blank\">https://wandb.ai/mihirneal/algonauts2025</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mihirneal/algonauts2025/runs/zmu4es3o' target=\"_blank\">https://wandb.ai/mihirneal/algonauts2025/runs/zmu4es3o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type           | Params | Mode \n",
      "-----------------------------------------------------\n",
      "0 | encoder   | Encoder        | 2.2 M  | train\n",
      "1 | decoder   | Decoder        | 3.2 M  | train\n",
      "2 | quantizer | VectorQuantize | 0      | train\n",
      "-----------------------------------------------------\n",
      "5.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "5.4 M     Total params\n",
      "21.596    Total estimated model params size (MB)\n",
      "78        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecdc3ac7483d4129963eda4c0a12dc01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98dfa07961d949cf8070c017e0bf1c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660afe6812c34754a97b4caff78a1ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3261f530a34cd4b0946388ca229127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7538de5f6844411e914d27b1137ec27e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a0df57679943e5869c093eddd04e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47230678ada4d22aef16bcb8beb3a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb366bcdce6642fbb3eaceeb0adb5d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb7360d13a74e43a85455b8bc57407f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0203c958014cf8800dcff5797400d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3979eef834014d558c01f5f666731a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892baa1debf641b6885f9c73038d3a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867d2d3d1c5849c5b0bba042808899cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7fb17b57be148e3910f14e8a6bcf6fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76f6e7df7cc4b1faa60f38b71066880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31aa09168c8f482fb06bf84eb1da1422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9ad9147b0e490d9dfed3059c2f4bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3eb34b30e8545a5ad52cde7beef93d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53143c2616bd4a3c97cbc51d82dc0f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c459208f2464da48961c41425a5f9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1793f6e7ad1c4bc68c475bf2a7cb7275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd4b746bec842bcaeefdedb590bb04e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb0ed5d649946889214187e90960912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b6616a8a2d44acac75e20a9d61709a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d8c514ac47431080686d92af42b21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7ad7c238be4168996b7565bf8659e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28b7b9b965a429e8e3715d518c73c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98098dc57a147c28fef17c4be663b5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4ad4bcc846477f8cba075ea7e14602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a9e6ae404d4b5a85245dcb8d26e039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd9260327a14dce9362505ed4d262bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa6dec812d041b1b5f5fc30d12a91e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e97a4722ad342dd9dcbdd686a8f5cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b469647d1faf4ca58fb1abd1b322bacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda600b56978498e900646fc124ec1c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6463f8b173d435f8b8d3be876b5f01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f5089441c34434b694ca2f8f71cfcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f004e3739c0c46019b89ef51ea9a5224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69353da39d44c2ca1ddd06d59c3cf92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b68d66b77d41cab217923c761a7028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b44f8c792c74e8ba290604f3dcd4a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b0cad8f9754ac399e64bcb610f42b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce33611d5a1f4975ab8d14c158eb7c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd310f0bde54dc1b3ff63684639bd3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac90c12e14d406baf8328b5c130b181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e59bea1abf45268b18484174f19728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4efde61033514bc19e2e39c23d3f93c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6f488b47004dc187f7d627cc241fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2adc7f35d0424e2298e1a3a2fab6b60f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0eef29712e34a17b0c03cba2e9798e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e565815bcf0c469fa4418aacc523b8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f292cb079a4d399e16c3323dfcd9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 774/774 [00:01<00:00, 524.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dead codes: 0 / 1024\n",
      "Perplexity: 870.3 (max: 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model = VQVAE()\n",
    "model = VQVAE.load_from_checkpoint(\"/home/pranav/mihir/algonauts_challenge/algonauts2025/checkpoints/fmri_vqvae_res_gelu_8qdim_1024/epoch=44_val_loss=0.137.ckpt\")\n",
    "model.eval()\n",
    "val_data = []\n",
    "val_recon = []\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        x = batch[0].to(model.device)\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        x_recon, _, _ = model(x)\n",
    "        val_data.append(x)\n",
    "        val_recon.append(x_recon)\n",
    "\n",
    "val_data = torch.cat(val_data)\n",
    "val_recon = torch.cat(val_recon)\n",
    "\n",
    "#Calculating dead codes and perplexity\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize counters\n",
    "codebook_size = 1024\n",
    "counts = torch.zeros(codebook_size, device=\"cuda\")  # Use \"cpu\" if needed\n",
    "\n",
    "# Run inference on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader):\n",
    "        x = batch.to(model.device)\n",
    "        z_e = model.encoder(x)  # Get encoder output\n",
    "        z_q, indices, _ = model.quantizer(z_e)  # Assuming `vq_layer` returns indices\n",
    "        indices_flat = indices.view(-1)  # Flatten all batch/spatial dimensions\n",
    "        counts += torch.bincount(indices_flat, minlength=codebook_size)\n",
    "\n",
    "# Compute metrics\n",
    "num_dead_codes = (counts == 0).sum().item()\n",
    "prob = counts / (counts.sum() + 1e-10)\n",
    "perplexity = torch.exp(-torch.sum(prob * torch.log(prob + 1e-10)))\n",
    "\n",
    "print(f\"Dead codes: {num_dead_codes} / {codebook_size}\")\n",
    "print(f\"Perplexity: {perplexity.item():.1f} (max: {codebook_size})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot code frequencies\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(counts.cpu().numpy(), bins=50, log_scale=(False, True))\n",
    "plt.xlabel(\"Code Frequency (log scale)\")\n",
    "plt.title(\"Code Usage Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "codebook_vectors = model.quantizer.codebook.cpu().numpy()  # Shape [1024, 8]\n",
    "similarity = cosine_similarity(codebook_vectors)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(similarity, cmap=\"viridis\", vmin=-1, vmax=1)\n",
    "plt.colorbar(label=\"Cosine Similarity\")\n",
    "plt.title(\"Codebook Vector Similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Collect codebook vectors and their usage counts\n",
    "codebook = model.quantizer.codebook.cpu().numpy()\n",
    "counts_np = counts.cpu().numpy()\n",
    "\n",
    "# Run t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "codebook_2d = tsne.fit_transform(codebook)\n",
    "\n",
    "# Plot with color indicating usage frequency\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(codebook_2d[:, 0], codebook_2d[:, 1], c=np.log(counts_np + 1), cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Log(Usage Count + 1)\")\n",
    "plt.title(\"Codebook t-SNE Projection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained: 0.628\n",
      "Pearson correlation: 0.792\n",
      "MSE: 0.137\n",
      "MAE: 0.290\n"
     ]
    }
   ],
   "source": [
    "var_explained = 1 - torch.var(val_data - val_recon) / torch.var(val_data)\n",
    "pearson_r = torch.corrcoef(torch.stack([val_data.flatten(), val_recon.flatten()]))[0,1]\n",
    "mse = torch.mean((val_data - val_recon) ** 2)\n",
    "mae = torch.mean(torch.abs(val_data - val_recon))\n",
    "\n",
    "print(f\"Variance explained: {var_explained:.3f}\")\n",
    "print(f\"Pearson correlation: {pearson_r:.3f}\")\n",
    "print(f\"MSE: {mse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_codebook(model, val_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    usage_count = torch.zeros(model.quantizer.codebook_size, device=device)\n",
    "    total_tokens = 0\n",
    "    distances = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x = batch[0].to(device)\n",
    "            if len(x.shape) == 1:\n",
    "                x = x.unsqueeze(0)\n",
    "            # Get encoder output\n",
    "            z = model.encoder(x)\n",
    "            # Get quantizer outputs before quantization\n",
    "            z_flat = z.reshape(-1, z.shape[-1])\n",
    "            _, indices, _ = model.quantizer(z_flat)\n",
    "            \n",
    "            # Update usage count\n",
    "            unique, counts = torch.unique(indices, return_counts=True)\n",
    "            usage_count[unique] += counts\n",
    "            total_tokens += indices.numel()\n",
    "            \n",
    "            # Calculate distances to assigned codebook vectors\n",
    "            dists = torch.cdist(z_flat, model.quantizer.codebook)\n",
    "            distances.append(dists.min(dim=1)[0])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    usage_prob = usage_count / total_tokens\n",
    "    active_codes = (usage_count > 0).sum().item()\n",
    "    entropy = -(usage_prob * torch.log2(usage_prob + 1e-10)).sum().item()\n",
    "    distances = torch.cat(distances)\n",
    "    \n",
    "    print(f\"Active codebook vectors: {active_codes}/{model.quantizer.codebook_size}\")\n",
    "    print(f\"Codebook entropy: {entropy:.2f} bits\")\n",
    "    print(f\"Mean distance to codebook: {distances.mean():.4f}\")\n",
    "    print(f\"Distance std: {distances.std():.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'usage_count': usage_count.cpu(),\n",
    "        'usage_prob': usage_prob.cpu(),\n",
    "        'active_codes': active_codes,\n",
    "        'entropy': entropy,\n",
    "        'distances': distances.cpu(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_codebook(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.quantizer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
