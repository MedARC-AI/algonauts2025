{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from vector_quantize_pytorch import VectorQuantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class ResidualBlock(nn.Module):\n",
    "#    def __init__(self, in_dim, out_dim):\n",
    "#        super().__init__()\n",
    "#        self.downsample = in_dim != out_dim\n",
    "#        self.net = nn.Sequential(\n",
    "#            nn.Linear(in_dim, out_dim),\n",
    "#            nn.LayerNorm(out_dim),\n",
    "#            nn.GELU(),\n",
    "#            nn.Linear(out_dim, out_dim),\n",
    "#            nn.LayerNorm(out_dim),\n",
    "#            nn.GELU()\n",
    "#        )\n",
    "#        if self.downsample:\n",
    "#            self.proj = nn.Linear(in_dim, out_dim)\n",
    "   \n",
    "#    def forward(self, x):\n",
    "#        if self.downsample:\n",
    "#            return self.proj(x) + self.net(x)\n",
    "#        return x + self.net(x)\n",
    "\n",
    "# class Encoder(nn.Module):\n",
    "#    def __init__(self, input_dim=1000, hidden_dims=[512, 384, 256], num_tokens=32, codebook_dim=64):\n",
    "#        super().__init__()\n",
    "       \n",
    "#        # Initial projection with one residual block\n",
    "#        self.input_proj = ResidualBlock(input_dim, hidden_dims[0])\n",
    "       \n",
    "#        # Main network with one residual block per layer\n",
    "#        layers = []\n",
    "#        for i in range(len(hidden_dims)-1):\n",
    "#            layers.append(ResidualBlock(hidden_dims[i], hidden_dims[i+1]))\n",
    "#        self.layers = nn.Sequential(*layers)\n",
    "       \n",
    "#        # Project to token space with one residual block\n",
    "#        self.token_proj = ResidualBlock(hidden_dims[-1], num_tokens * codebook_dim)\n",
    "       \n",
    "#        self.num_tokens = num_tokens\n",
    "#        self.codebook_dim = codebook_dim\n",
    "       \n",
    "#    def forward(self, x):\n",
    "#        x = self.input_proj(x)\n",
    "#        x = self.layers(x)\n",
    "#        x = self.token_proj(x)\n",
    "#        return x.view(x.shape[0], self.num_tokens, self.codebook_dim)\n",
    "\n",
    "# class Decoder(nn.Module):\n",
    "#    def __init__(self, output_dim=1000, hidden_dims=[256, 384, 512], num_tokens=32, codebook_dim=64):\n",
    "#        super().__init__()\n",
    "       \n",
    "#        # Process tokens with one residual block\n",
    "#        self.token_proj = ResidualBlock(num_tokens * codebook_dim, hidden_dims[0])\n",
    "       \n",
    "#        # Main network with one residual block per layer\n",
    "#        layers = []\n",
    "#        for i in range(len(hidden_dims)-1):\n",
    "#            layers.append(ResidualBlock(hidden_dims[i], hidden_dims[i+1]))\n",
    "#        self.layers = nn.Sequential(*layers)\n",
    "       \n",
    "#        # Final projection with one residual block\n",
    "#        self.output_proj = ResidualBlock(hidden_dims[-1], output_dim)\n",
    "       \n",
    "#    def forward(self, x):\n",
    "#        # x shape: [batch_size, num_tokens, codebook_dim] \n",
    "#        x = x.reshape(x.shape[0], -1)  # Flatten tokens\n",
    "#        x = self.token_proj(x)\n",
    "#        x = self.layers(x)\n",
    "#        return self.output_proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, dim, num_heads=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert dim % num_heads == 0, f\"dim {dim} must be divisible by num_heads {num_heads}\"\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = dim // num_heads\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        \n",
    "        # Separate projections for Q, K, V\n",
    "        self.q_proj = nn.Linear(dim, dim)\n",
    "        self.k_proj = nn.Linear(dim, dim)\n",
    "        self.v_proj = nn.Linear(dim, dim)\n",
    "        \n",
    "        self.out_proj = nn.Linear(dim, dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape  # batch, num_tokens, channels\n",
    "        H = self.num_heads\n",
    "\n",
    "        # Generate Q, K, V with separate projections\n",
    "        q = self.q_proj(x).reshape(B, N, H, self.head_dim).transpose(1, 2)  # B, H, N, head_dim\n",
    "        k = self.k_proj(x).reshape(B, N, H, self.head_dim).transpose(1, 2)\n",
    "        v = self.v_proj(x).reshape(B, N, H, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Attention\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale  # B, H, N, N\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "        \n",
    "        # Apply attention to V\n",
    "        out = (attn @ v).transpose(1, 2).reshape(B, N, C)  # B, N, C\n",
    "        out = self.out_proj(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads=2, mlp_ratio=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.attn = MultiHeadAttention(dim, num_heads, dropout)\n",
    "        \n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, mlp_hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_hidden_dim, dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pre-norm architecture\n",
    "        x = x + self.attn(self.norm1(x))\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class CustomViTEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=1000,\n",
    "        num_tokens=32,\n",
    "        token_dim=8,\n",
    "        num_layers=4,\n",
    "        num_heads=2,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_tokens = num_tokens\n",
    "        self.token_dim = token_dim\n",
    "        \n",
    "        # Initial projection and reshape\n",
    "        self.input_proj = nn.Sequential(\n",
    "            nn.Linear(input_dim, num_tokens * token_dim),\n",
    "            # nn.LayerNorm(num_tokens * token_dim),\n",
    "            # nn.GELU(),\n",
    "            # # nn.Dropout(dropout),\n",
    "            # nn.Linear(num_tokens * token_dim, num_tokens * token_dim),\n",
    "            # # nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "        # Positional embedding\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, num_tokens, token_dim) * 0.02)  # smaller init\n",
    "        \n",
    "        # Transformer layers\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(\n",
    "                dim=token_dim,\n",
    "                num_heads=num_heads,\n",
    "                mlp_ratio=2,\n",
    "                dropout=dropout\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.norm = nn.LayerNorm(token_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Project and reshape: [B, 1000] -> [B, 32, 8]\n",
    "        x = self.input_proj(x)\n",
    "        x = x.reshape(-1, self.num_tokens, self.token_dim)\n",
    "        \n",
    "        # Add positional embeddings and dropout\n",
    "        x = x + self.pos_embed\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Apply transformer blocks\n",
    "        # print(\"input shape: \", x.shape)\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "# Mirror image of encoder for decoder\n",
    "class CustomViTDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        output_dim=1000,\n",
    "        num_tokens=32,\n",
    "        token_dim=8,\n",
    "        num_layers=4,\n",
    "        num_heads=2,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_tokens = num_tokens\n",
    "        self.token_dim = token_dim\n",
    "        \n",
    "        # Positional embedding\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, num_tokens, token_dim) * 0.02)\n",
    "        \n",
    "        # Transformer layers\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(\n",
    "                dim=token_dim,\n",
    "                num_heads=num_heads,\n",
    "                mlp_ratio=2,\n",
    "                dropout=dropout\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        self.norm = nn.LayerNorm(token_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Output projection\n",
    "        self.output_proj = nn.Sequential(\n",
    "            nn.Linear(num_tokens * token_dim, output_dim),\n",
    "            # nn.LayerNorm(num_tokens * token_dim),\n",
    "            # nn.GELU(),\n",
    "            # # nn.Dropout(dropout),\n",
    "            # nn.Linear(num_tokens * token_dim, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Add positional embeddings and dropout\n",
    "        x = x + self.pos_embed\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Apply transformer blocks\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.norm(x)\n",
    "        \n",
    "        # Project back to original dimension\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.output_proj(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from torchmetrics.functional import pearson_corrcoef\n",
    "\n",
    "class VQVAE(L.LightningModule):\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_dim=1000, \n",
    "            hidden_dims=[512, 384, 256], \n",
    "            num_tokens=32,\n",
    "            num_layers=2,\n",
    "            codebook_size=1024, \n",
    "            codebook_dim=8,\n",
    "            commitment_weight=0.25,\n",
    "            quantizer_decay=0.99,\n",
    "            learning_rate=3e-4,\n",
    "            weight_decay=0.01\n",
    "            ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = CustomViTEncoder(num_layers=num_layers, token_dim=codebook_dim)\n",
    "        self.decoder = CustomViTDecoder(num_layers=num_layers, token_dim=codebook_dim)\n",
    "        self.quantizer = VectorQuantize(\n",
    "                dim=codebook_dim,\n",
    "                codebook_size=codebook_size,\n",
    "                decay=quantizer_decay,\n",
    "                commitment_weight=commitment_weight,\n",
    "                )\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        #Temperature scheduling for Vector Quantizer\n",
    "        self.temp = 1.0\n",
    "        self.min_temp = 0.5\n",
    "        self.temp_anneal_rate = 0.999\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "    # def on_train_batch_start(self, batch, batch_idx):\n",
    "    #     self.temp = max(self.min_temp, self.temp * self.temp_anneal_rate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        # if self.training:\n",
    "        #     z = z / self.temp\n",
    "        z_q, indices, commitment_loss = self.quantizer(z)\n",
    "        x_recon = self.decoder(z_q)\n",
    "        return x_recon, commitment_loss, indices\n",
    "    \n",
    "    def calculate_metrics(self, x, x_recon):\n",
    "        # Flatten the tensors for correlation calculation\n",
    "        x = x.to(torch.float64)\n",
    "        x_recon = x_recon.to(torch.float64)\n",
    "        x_flat = x.reshape(x.shape[0], -1)\n",
    "        x_recon_flat = x_recon.reshape(x_recon.shape[0], -1)\n",
    "        \n",
    "        # Calculate Pearson R for each sample in batch\n",
    "        correlations = torch.stack([\n",
    "            pearson_corrcoef(x_flat[i], x_recon_flat[i])\n",
    "            for i in range(x_flat.shape[0])\n",
    "        ])\n",
    "        avg_pearson_r = correlations.mean()\n",
    "        \n",
    "        # Calculate variance explained\n",
    "        total_variance = torch.var(x_flat, dim=1).sum()\n",
    "        residual_variance = torch.var(x_flat - x_recon_flat, dim=1).sum()\n",
    "        variance_explained = 1 - (residual_variance / total_variance)\n",
    "        \n",
    "        return avg_pearson_r, variance_explained\n",
    "\n",
    "\n",
    "    def training_step(self, batch: torch.Tensor, batch_idx: int) -> torch.Tensor:\n",
    "        x = batch[0]\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        x_recon, commitment_loss, _ = self(x)\n",
    "        \n",
    "        recon_loss = F.mse_loss(x_recon, x)\n",
    "        total_loss = recon_loss + commitment_loss\n",
    "\n",
    "        pearson_r, var = self.calculate_metrics(x, x_recon)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('train_loss', total_loss)\n",
    "        self.log('temperature', self.temp)\n",
    "        self.log('train_recon_loss', recon_loss)\n",
    "        self.log('train_commitment_loss', commitment_loss)\n",
    "        self.log('train_pearson_r', pearson_r)\n",
    "        self.log('train_variance', var)\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    def validation_step(self, batch: torch.Tensor, batch_idx: int) -> torch.Tensor:\n",
    "        x = batch[0]\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        x_recon, commitment_loss, _ = self(x)\n",
    "        \n",
    "        recon_loss = F.mse_loss(x_recon, x)\n",
    "        total_loss = recon_loss + commitment_loss\n",
    "\n",
    "        val_pearson_r, val_var = self.calculate_metrics(x, x_recon)\n",
    "        \n",
    "        # Log metrics\n",
    "        self.log('val_loss', total_loss)\n",
    "        self.log('val_recon_loss', recon_loss)\n",
    "        self.log('val_pearson_r', val_pearson_r)\n",
    "        self.log('val_variance', val_var)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # Separate parameter groups for different learning rates\n",
    "        encoder_decoder_params = []\n",
    "        quantizer_params = []\n",
    "        \n",
    "        # Group parameters\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'quantizer' in name:\n",
    "                quantizer_params.append(param)\n",
    "            else:\n",
    "                encoder_decoder_params.append(param)\n",
    "        \n",
    "        # Create optimizer with parameter groups\n",
    "        optimizer = torch.optim.AdamW([\n",
    "            {\n",
    "                'params': encoder_decoder_params,\n",
    "                'lr': self.learning_rate,\n",
    "                'weight_decay': self.weight_decay\n",
    "            },\n",
    "            {\n",
    "                'params': quantizer_params,\n",
    "                'lr': self.learning_rate * 0.5,  # Lower learning rate for quantizer\n",
    "                'weight_decay': 0  # Usually no weight decay for quantizer\n",
    "            }\n",
    "        ], betas=(0.9, 0.999), eps=1e-8)\n",
    "        \n",
    "        # Scheduler setup\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            mode='min',\n",
    "            factor=0.5,\n",
    "            patience=10,\n",
    "            min_lr=1e-6,\n",
    "            verbose=True,\n",
    "            threshold=1e-4,\n",
    "            threshold_mode='rel'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\",  # Metric to monitor\n",
    "            }\n",
    "        }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class FMRIDataset(Dataset):\n",
    "    def __init__(self, h5_file):\n",
    "        data_list = []\n",
    "        try:\n",
    "            with h5py.File(h5_file, 'r') as f:\n",
    "                for key in f.keys():\n",
    "                    data = torch.from_numpy(f[key][:]).float()\n",
    "                    data_list.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {h5_file}: {str(e)}\")\n",
    "        self.data = torch.cat(data_list, dim=0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Create separate datasets for train and val\n",
    "train_file = '/home/pranav/mihir/algonauts_challenge/algonauts_2025.competitors/fmri/sub-01/func/sub-01_task-friends_space-MNI152NLin2009cAsym_atlas-Schaefer18_parcel-1000Par7Net_desc-s123456_bold.h5'\n",
    "val_file = '/home/pranav/mihir/algonauts_challenge/algonauts_2025.competitors/fmri/sub-01/func/sub-01_task-movie10_space-MNI152NLin2009cAsym_atlas-Schaefer18_parcel-1000Par7Net_bold.h5'\n",
    "\n",
    "train_dataset = FMRIDataset(train_file)\n",
    "val_dataset = FMRIDataset(val_file)\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 137913\n",
      "Validation samples: 24758\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "run_name = \"fmri_1_VIT_vq_08comm_16qdim\"\n",
    "project = \"fmri_vq_tokenizer\"\n",
    "wandb_logger = WandbLogger(\n",
    "    project=project,\n",
    "    name=run_name,\n",
    "    save_dir=\"wandb_logs/\"\n",
    ")\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=-1,\n",
    "    precision=32,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            dirpath=f'checkpoints/{project}/{run_name}',\n",
    "            filename='{epoch:02d}_{val_loss:.3f}',\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_top_k=1,\n",
    "            save_last=True\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            patience=10,\n",
    "            verbose=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   | Name                       | Type              | Params | Mode \n",
      "--------------------------------------------------------------------------\n",
      "0  | encoder                    | CustomViTEncoder  | 515 K  | train\n",
      "1  | encoder.input_proj         | Sequential        | 512 K  | train\n",
      "2  | encoder.transformer_blocks | ModuleList        | 2.2 K  | train\n",
      "3  | encoder.norm               | LayerNorm         | 32     | train\n",
      "4  | encoder.dropout            | Dropout           | 0      | train\n",
      "5  | decoder                    | CustomViTDecoder  | 515 K  | train\n",
      "6  | decoder.transformer_blocks | ModuleList        | 2.2 K  | train\n",
      "7  | decoder.norm               | LayerNorm         | 32     | train\n",
      "8  | decoder.dropout            | Dropout           | 0      | train\n",
      "9  | decoder.output_proj        | Sequential        | 513 K  | train\n",
      "10 | quantizer                  | VectorQuantize    | 0      | train\n",
      "11 | quantizer.project_in       | Identity          | 0      | train\n",
      "12 | quantizer.project_out      | Identity          | 0      | train\n",
      "13 | quantizer._codebook        | EuclideanCodebook | 0      | train\n",
      "--------------------------------------------------------------------------\n",
      "1.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 M     Total params\n",
      "4.124     Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "torch.set_float32_matmul_precision('high')\n",
    "model = VQVAE(num_layers=1, codebook_dim=16, codebook_size=1024, commitment_weight=0.8)\n",
    "summary = ModelSummary(model, max_depth=2)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmihir-neal\u001b[0m (\u001b[33mmihirneal\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>wandb_logs/wandb/run-20250208_070236-vdxpsnzh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mihirneal/fmri_vq_tokenizer/runs/vdxpsnzh' target=\"_blank\">fmri_1_VIT_vq_08comm_16qdim</a></strong> to <a href='https://wandb.ai/mihirneal/fmri_vq_tokenizer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mihirneal/fmri_vq_tokenizer' target=\"_blank\">https://wandb.ai/mihirneal/fmri_vq_tokenizer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mihirneal/fmri_vq_tokenizer/runs/vdxpsnzh' target=\"_blank\">https://wandb.ai/mihirneal/fmri_vq_tokenizer/runs/vdxpsnzh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | encoder   | CustomViTEncoder | 515 K  | train\n",
      "1 | decoder   | CustomViTDecoder | 515 K  | train\n",
      "2 | quantizer | VectorQuantize   | 0      | train\n",
      "-------------------------------------------------------\n",
      "1.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 M     Total params\n",
      "4.124     Total estimated model params size (MB)\n",
      "44        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26472812d1a648d488fab16af1e78ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c58da5d2e424586971542abc95fca22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec1818729fc4c869b57368eecec884f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved. New best score: 0.619\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe3f689ad53423e9abdb42c64962fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.067 >= min_delta = 0.0. New best score: 0.685\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ade1600de9042f889b1bc60df05785b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.008 >= min_delta = 0.0. New best score: 0.693\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77dba21caf834708a7f3bbb1c27247a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.005 >= min_delta = 0.0. New best score: 0.698\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d36cbb1dc40419ca0ec96d7cc5f5faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.035 >= min_delta = 0.0. New best score: 0.733\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd1eddcf41b491a940781860628236d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.020 >= min_delta = 0.0. New best score: 0.753\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd050743c0543e58b64c296b4600588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.010 >= min_delta = 0.0. New best score: 0.763\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab30d604e6a46a4b36e019012143e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.006 >= min_delta = 0.0. New best score: 0.769\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a4798343084aec8ccbec0ca0a3c3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.002 >= min_delta = 0.0. New best score: 0.771\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdbd5715da94faf947b5a26f98bfce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.002 >= min_delta = 0.0. New best score: 0.773\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d996d79f4e7b4347a127808d72d9c6c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.001 >= min_delta = 0.0. New best score: 0.774\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38fca195e9f94a4f8f080ef50bb0604e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.003 >= min_delta = 0.0. New best score: 0.777\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d059910951402e94cc7db3ba5395cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.004 >= min_delta = 0.0. New best score: 0.781\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481e642189894f81998b3481915efe27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.002 >= min_delta = 0.0. New best score: 0.783\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b59b87118d41289a4bd8f7da200d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.003 >= min_delta = 0.0. New best score: 0.786\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50f677f9d46456ca151ccf7103ad0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.000 >= min_delta = 0.0. New best score: 0.786\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967961aa43574f6d9470b47da4eb7ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.002 >= min_delta = 0.0. New best score: 0.788\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d1745fd9c9459baa0e3eb6f03ef19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.000 >= min_delta = 0.0. New best score: 0.788\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b11fb790c464190ae9cb4e65da34e67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.000 >= min_delta = 0.0. New best score: 0.789\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759322ba0053445baec46efd07bc6bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.000 >= min_delta = 0.0. New best score: 0.789\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be235791662457296d514ba392bb51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.000 >= min_delta = 0.0. New best score: 0.789\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a779be253804e1cb9706f98b9dfe3f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.000 >= min_delta = 0.0. New best score: 0.790\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34806bb65d364a15967cdfb41319ade9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.001 >= min_delta = 0.0. New best score: 0.790\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16adfebd326e41bbb6431eb9445f33fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.002 >= min_delta = 0.0. New best score: 0.792\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29d4c9e3f82b48edb60664675767a6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.000 >= min_delta = 0.0. New best score: 0.793\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21fdb64f950f47ac847646e31243e404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.002 >= min_delta = 0.0. New best score: 0.794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb7d4f856ea4b15b67fa829701b4e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47530ddcd60471cb196fbcdd7307af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.002 >= min_delta = 0.0. New best score: 0.796\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f68b5d72b94d1d82729f22f527fc76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.000 >= min_delta = 0.0. New best score: 0.796\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9342ca014f844aee9ac80636536bf82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.001 >= min_delta = 0.0. New best score: 0.797\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4690b686d5b4b6c8578df371b3401f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20bed0e6b67f466dbb4cf8bdbe3a7c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.001 >= min_delta = 0.0. New best score: 0.798\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbcb429510642e78bdfe85ed4e0ee7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f280589a97f4f64b01896bcdee3795e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.001 >= min_delta = 0.0. New best score: 0.798\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ec0e4c21c4498fbe7f7a66b9433c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.000 >= min_delta = 0.0. New best score: 0.798\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb76fdd8c1b48cda290ef3e708e3cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d39dee2a593411c80fab6497c81ea05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0741a996d94e4fe1bb1f4430a7e95a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.000 >= min_delta = 0.0. New best score: 0.799\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fced07ea37a14633bf23f9ac1673de60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.000 >= min_delta = 0.0. New best score: 0.799\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed1c30fb54341febde863d135c87786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.000 >= min_delta = 0.0. New best score: 0.799\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f374ae3f6f4813be4c12d434acdbc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc83798709e414d964b08cf3137dcde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae176f49dd8d46a092e1874f10664d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf9e120c59f4d1584c743f664720f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca58e40719964dc79178d0da10d8397c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0568e4453d4a4eac4a2e4a859a196b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5937d8da75341baa413acee6123d540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.000 >= min_delta = 0.0. New best score: 0.799\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee21698599842d7bd440ef44512e436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be796abbe674d028dcd51893151bd3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316047549986422ba97c01e368a6dd04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2eddd5a84c44763b566db28878f0d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.000 >= min_delta = 0.0. New best score: 0.800\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "146062d4dd554d3a9bfd9f93229a56fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12bb780b08c43c397be165206634536",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18570c44c91c44978e6d7e68193ffd12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28245204bda4afaaf956ae515ea273c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f152354dea54406ae0a437f4ba944b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_pearson_r improved by 0.001 >= min_delta = 0.0. New best score: 0.800\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53431a44807543e4ae2eff944b2f7b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0464a555cf8b4f7a9d89cf4d7d4bc5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827d84acbfbb42cdad06d30595c3590b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20095824eac643298e4b8e49ce08fc08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509b0023419e4363adac549cea9c2687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9ee0a540424a32a2d6b281d1e6b53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faae3a10d9db4035be71c8d58e48fd7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc965d9f90543c3a54847db24c6c27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686ac65f45bc44c9b000fa4ef519b02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "512b7f8f88fd497e9110080e5ed5bcf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_pearson_r did not improve in the last 10 records. Best score: 0.800. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 774/774 [00:01<00:00, 536.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dead codes: 112 / 1024\n",
      "Perplexity: 541.0 (max: 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model = VQVAE()\n",
    "model = VQVAE.load_from_checkpoint(\"/home/pranav/mihir/algonauts_challenge/algonauts2025/checkpoints/fmri_vq_tokenizer/fmri_1_VIT_vq_08comm_16qdim/epoch=55_val_pearson_r=0.800.ckpt\")\n",
    "model.eval()\n",
    "val_data = []\n",
    "val_recon = []\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        x = batch[0].to(model.device)\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "        x_recon, _, _ = model(x)\n",
    "        val_data.append(x)\n",
    "        val_recon.append(x_recon)\n",
    "\n",
    "val_data = torch.cat(val_data)\n",
    "val_recon = torch.cat(val_recon)\n",
    "\n",
    "#Calculating dead codes and perplexity\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize counters\n",
    "codebook_size = 1024\n",
    "counts = torch.zeros(codebook_size, device=\"cuda\")  # Use \"cpu\" if needed\n",
    "\n",
    "# Run inference on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader):\n",
    "        x = batch.to(model.device)\n",
    "        z_e = model.encoder(x)  # Get encoder output\n",
    "        z_q, indices, _ = model.quantizer(z_e)  # Assuming `vq_layer` returns indices\n",
    "        indices_flat = indices.view(-1)  # Flatten all batch/spatial dimensions\n",
    "        counts += torch.bincount(indices_flat, minlength=codebook_size)\n",
    "\n",
    "# Compute metrics\n",
    "num_dead_codes = (counts == 0).sum().item()\n",
    "prob = counts / (counts.sum() + 1e-10)\n",
    "perplexity = torch.exp(-torch.sum(prob * torch.log(prob + 1e-10)))\n",
    "\n",
    "print(f\"Dead codes: {num_dead_codes} / {codebook_size}\")\n",
    "print(f\"Perplexity: {perplexity.item():.1f} (max: {codebook_size})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot code frequencies\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.histplot(counts.cpu().numpy(), bins=50, log_scale=(False, True))\n",
    "plt.xlabel(\"Code Frequency (log scale)\")\n",
    "plt.title(\"Code Usage Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "codebook_vectors = model.quantizer.codebook.cpu().numpy()  # Shape [1024, 8]\n",
    "similarity = cosine_similarity(codebook_vectors)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(similarity, cmap=\"viridis\", vmin=-1, vmax=1)\n",
    "plt.colorbar(label=\"Cosine Similarity\")\n",
    "plt.title(\"Codebook Vector Similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Collect codebook vectors and their usage counts\n",
    "codebook = model.quantizer.codebook.cpu().numpy()\n",
    "counts_np = counts.cpu().numpy()\n",
    "\n",
    "# Run t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "codebook_2d = tsne.fit_transform(codebook)\n",
    "\n",
    "# Plot with color indicating usage frequency\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(codebook_2d[:, 0], codebook_2d[:, 1], c=np.log(counts_np + 1), cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Log(Usage Count + 1)\")\n",
    "plt.title(\"Codebook t-SNE Projection\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained: 0.663\n",
      "Pearson correlation: 0.818\n",
      "MSE: 0.124\n",
      "MAE: 0.278\n"
     ]
    }
   ],
   "source": [
    "var_explained = 1 - torch.var(val_data - val_recon) / torch.var(val_data)\n",
    "pearson_r = torch.corrcoef(torch.stack([val_data.flatten(), val_recon.flatten()]))[0,1]\n",
    "mse = torch.mean((val_data - val_recon) ** 2)\n",
    "mae = torch.mean(torch.abs(val_data - val_recon))\n",
    "\n",
    "print(f\"Variance explained: {var_explained:.3f}\")\n",
    "print(f\"Pearson correlation: {pearson_r:.3f}\")\n",
    "print(f\"MSE: {mse:.3f}\")\n",
    "print(f\"MAE: {mae:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_codebook(model, val_loader, device='cuda'):\n",
    "    model.eval()\n",
    "    usage_count = torch.zeros(model.quantizer.codebook_size, device=device)\n",
    "    total_tokens = 0\n",
    "    distances = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x = batch[0].to(device)\n",
    "            if len(x.shape) == 1:\n",
    "                x = x.unsqueeze(0)\n",
    "            # Get encoder output\n",
    "            z = model.encoder(x)\n",
    "            # Get quantizer outputs before quantization\n",
    "            z_flat = z.reshape(-1, z.shape[-1])\n",
    "            _, indices, _ = model.quantizer(z_flat)\n",
    "            \n",
    "            # Update usage count\n",
    "            unique, counts = torch.unique(indices, return_counts=True)\n",
    "            usage_count[unique] += counts\n",
    "            total_tokens += indices.numel()\n",
    "            \n",
    "            # Calculate distances to assigned codebook vectors\n",
    "            dists = torch.cdist(z_flat, model.quantizer.codebook)\n",
    "            distances.append(dists.min(dim=1)[0])\n",
    "    \n",
    "    # Calculate metrics\n",
    "    usage_prob = usage_count / total_tokens\n",
    "    active_codes = (usage_count > 0).sum().item()\n",
    "    entropy = -(usage_prob * torch.log2(usage_prob + 1e-10)).sum().item()\n",
    "    distances = torch.cat(distances)\n",
    "    \n",
    "    print(f\"Active codebook vectors: {active_codes}/{model.quantizer.codebook_size}\")\n",
    "    print(f\"Codebook entropy: {entropy:.2f} bits\")\n",
    "    print(f\"Mean distance to codebook: {distances.mean():.4f}\")\n",
    "    print(f\"Distance std: {distances.std():.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'usage_count': usage_count.cpu(),\n",
    "        'usage_prob': usage_prob.cpu(),\n",
    "        'active_codes': active_codes,\n",
    "        'entropy': entropy,\n",
    "        'distances': distances.cpu(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active codebook vectors: 819/1024\n",
      "Codebook entropy: 9.07 bits\n",
      "Mean distance to codebook: 0.0616\n",
      "Distance std: 0.0351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'usage_count': tensor([  0.,   4.,   1.,  ...,  42., 104.,  10.]),\n",
       " 'usage_prob': tensor([0.0000e+00, 1.6150e-04, 4.0375e-05,  ..., 1.6957e-03, 4.1990e-03,\n",
       "         4.0375e-04]),\n",
       " 'active_codes': 819,\n",
       " 'entropy': 9.067659378051758,\n",
       " 'distances': tensor([0.0697, 0.0960, 0.0509,  ..., 0.0380, 0.0438, 0.0454])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_codebook(model, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
