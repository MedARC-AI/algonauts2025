{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "from utils import load_fmri, align_features_and_fmri_samples, align_features_and_fmri_samples_friends_s7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Class for Stimulus-fMRI Alignment\n",
    "\n",
    "A dataset class that aligns stimulus feature embeddings with fMRI data.\n",
    "\n",
    "## Parameters\n",
    "\n",
    "- **features_dir** : *str*\n",
    "    Directory containing stimulus features from the HuggingFace dataset\n",
    "- **fmri_dir** : *str*\n",
    "    Directory containing fMRI data from the Algonauts 2025 competition  \n",
    "- **movies** : *list*\n",
    "    List of movies to use for training\n",
    "- **subject** : *int*\n",
    "    Subject ID number\n",
    "- **excluded_samples_start** : *int, default=5*\n",
    "    Number of samples to exclude from the start\n",
    "- **excluded_samples_end** : *int, default=5*\n",
    "    Number of samples to exclude from the end\n",
    "- **hrf_delay** : *int, default=3*\n",
    "    Hemodynamic response function delay\n",
    "- **stimulus_window** : *int, default=5*\n",
    "    Size of the stimulus window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlgonautsDataset(Dataset):\n",
    "    def __init__(self, features_dir, fmri_dir, movies, subject, excluded_samples_start=5, excluded_samples_end=5, hrf_delay=3, stimulus_window=5):\n",
    "        self.features_dir = features_dir\n",
    "        self.fmri_dir = fmri_dir\n",
    "        self.movies = movies\n",
    "        self.subject = subject\n",
    "        self.excluded_samples_start = excluded_samples_start\n",
    "        self.excluded_samples_end = excluded_samples_end\n",
    "        self.hrf_delay = hrf_delay\n",
    "        self.stimulus_window = stimulus_window\n",
    "        self.partition_indices = defaultdict(list)\n",
    "        \n",
    "        # First load all raw features\n",
    "        stimuli_features = {\"visual\": {}, \"audio\": {}, \"language\": {}}\n",
    "        # Load audio and video features first\n",
    "        for movie in self.movies:\n",
    "            if 'friends' in movie:\n",
    "                season = movie.split('-')[1]\n",
    "                dir_list = sorted(os.listdir(self.features_dir + 'audio')) #List of all audio for each subset of dataset\n",
    "                for episode in dir_list:\n",
    "                    if f\"{season}e\" in episode and '_features_' in episode:\n",
    "                        episode_base = episode.split('_features_')[0] # friends_s01e01 and so on....\n",
    "                        \n",
    "                        for modality in ['audio', 'visual']:\n",
    "                            with h5py.File(os.path.join(self.features_dir, modality, f\"{episode_base}_features_{modality}.h5\"), 'r') as f:\n",
    "                                try:\n",
    "                                    stimuli_features[modality][episode_base.split('_')[1]] = f[episode_base.split('_')[1]][modality][:]\n",
    "                                except:\n",
    "                                    f.visit(lambda x: print(x))\n",
    "                lang_dir_list = sorted(os.listdir(self.features_dir + 'language'))\n",
    "                for episode in lang_dir_list:\n",
    "                    if f\"{season}e\" in episode and '_features_' in episode:\n",
    "                        episode_base = episode.split('_features_')[0]\n",
    "                        \n",
    "                        with h5py.File(os.path.join(self.features_dir, 'language', f\"{episode_base}_features_language.h5\"), 'r') as f:\n",
    "                            try:\n",
    "                                st_season_episode = episode_base.split('_')[1]\n",
    "                                stimuli_features['language'][st_season_episode] = f[st_season_episode]['language_pooler_output'][:]\n",
    "                            except:\n",
    "                                f.visit(lambda x: print(x))\n",
    "            else:\n",
    "                movie_name = movie.replace('movie10-', '')\n",
    "                partitions = sorted([f for f in os.listdir(self.features_dir + 'audio') if movie_name in f and '_features_' in f])\n",
    "                \n",
    "                for partition in partitions:\n",
    "                    partition_base = partition.split('_features_')[0]\n",
    "                    \n",
    "                    for modality in ['audio', 'visual']:\n",
    "                        with h5py.File(os.path.join(self.features_dir, modality, f\"{partition_base}_features_{modality}.h5\"), 'r') as f:\n",
    "                            try:\n",
    "                                stimuli_features[modality][partition_base] = f[partition_base][modality][:]\n",
    "                            except:\n",
    "                                f.visit(lambda x: print(x))\n",
    "                lang_partitions = sorted([f for f in os.listdir(self.features_dir + 'language') if movie_name in f and '_features_' in f])\n",
    "                \n",
    "                for partition in lang_partitions:\n",
    "                    partition_base = partition.split('_features_')[0]\n",
    "                    \n",
    "                    with h5py.File(os.path.join(self.features_dir, 'language', f\"{partition_base}_features_language.h5\"), 'r') as f:\n",
    "                        try:\n",
    "                            stimuli_features['language'][partition_base] = f[partition_base]['language_pooler_output'][:]\n",
    "                        except:\n",
    "                            f.visit(lambda x: print(x))\n",
    "\n",
    "        fmri_data = load_fmri(self.fmri_dir, self.subject)\n",
    "        self.raw_stimuli = stimuli_features\n",
    "\n",
    "        self.aligned_features, self.aligned_fmri = align_features_and_fmri_samples(\n",
    "            stimuli_features, \n",
    "            fmri_data, \n",
    "            self.excluded_samples_start, \n",
    "            self.excluded_samples_end, \n",
    "            self.hrf_delay, \n",
    "            self.stimulus_window, \n",
    "            self.movies\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.aligned_features['audio'].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'audio': self.aligned_features['audio'][idx],\n",
    "            'video': self.aligned_features['visual'][idx],\n",
    "            'language': self.aligned_features['language'][idx],\n",
    "            'fmri': self.aligned_fmri[idx]\n",
    "        }\n",
    "    \n",
    "    def get_raw_stimuli(self):\n",
    "        return self.raw_stimuli\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dir = '/home/pranav/mihir/algonauts_challenge/AlgonautsDS-features/developer_kit/stimulus_features/raw/'\n",
    "fmri_dir = '/home/pranav/mihir/algonauts_challenge/algonauts_2025.competitors/fmri/'\n",
    "# movies_train = [\"friends-s01\"]\n",
    "movies_train = [\"friends-s01\", \"friends-s02\", \"friends-s03\", \"friends-s04\", \"friends-s05\", \"movie10-bourne\", \"movie10-figures\", \"movie10-life\", \"movie10-wolf\"]\n",
    "movies_val = [\"friends-s06\"]\n",
    "modality = \"all\"  #@param [\"visual\", \"audio\", \"language\", \"all\"]\n",
    "\n",
    "excluded_samples_start = 5  #@param {type:\"slider\", min:0, max:20, step:1}\n",
    "excluded_samples_end = 5  #@param {type:\"slider\", min:0, max:20, step:1}\n",
    "hrf_delay = 3  #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "stimulus_window = 5\n",
    "\n",
    "subject = 1 #@param [\"1\", \"2\", \"3\", \"5\"] {type:\"raw\", allow-input: true}\n",
    "\n",
    "train_ds = AlgonautsDataset(features_dir, fmri_dir, movies=movies_train, subject=subject, excluded_samples_start=excluded_samples_start, excluded_samples_end=excluded_samples_end, hrf_delay=hrf_delay, stimulus_window=stimulus_window)\n",
    "val_ds = AlgonautsDataset(features_dir, fmri_dir, movies=movies_val, subject=subject, excluded_samples_start=excluded_samples_start, excluded_samples_end=excluded_samples_end, hrf_delay=hrf_delay, stimulus_window=stimulus_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length:  129516\n",
      "Validation dataset length:  22924\n"
     ]
    }
   ],
   "source": [
    "print(\"Train dataset length: \", len(train_ds))\n",
    "print(\"Validation dataset length: \", len(val_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Building Your Model Here\n",
    "\n",
    "The data is now prepared - you can begin implementing your model architecture and training pipeline below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run inference on trained model\n",
    "\n",
    "Friends Season 7 is the test set. Its corresponding fMRI data is withheld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_test = [\"friends-s07\"] \n",
    "test_ds = AlgonautsDataset(features_dir, fmri_dir, movies=movies_test, subject=subject, excluded_samples_start=excluded_samples_start, excluded_samples_end=excluded_samples_end, hrf_delay=hrf_delay, stimulus_window=stimulus_window)\n",
    "test_stimuli = test_ds.get_raw_stimuli()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "visual features movie names and shape:\n",
      "s07e01a (460, 8192)\n",
      "s07e01b (494, 8192)\n",
      "s07e02a (492, 8192)\n",
      "s07e02b (526, 8192)\n",
      "s07e03a (418, 8192)\n",
      "s07e03b (452, 8192)\n",
      "s07e04a (448, 8192)\n",
      "s07e04b (482, 8192)\n",
      "s07e05a (454, 8192)\n",
      "s07e05b (488, 8192)\n",
      "s07e06a (478, 8192)\n",
      "s07e06b (513, 8192)\n",
      "s07e07a (473, 8192)\n",
      "s07e07b (507, 8192)\n",
      "s07e08a (475, 8192)\n",
      "s07e08b (509, 8192)\n",
      "s07e09a (451, 8192)\n",
      "s07e09b (485, 8192)\n",
      "s07e10a (460, 8192)\n",
      "s07e10b (494, 8192)\n",
      "s07e11a (465, 8192)\n",
      "s07e11b (499, 8192)\n",
      "s07e12a (452, 8192)\n",
      "s07e12b (487, 8192)\n",
      "s07e13a (540, 8192)\n",
      "s07e13b (574, 8192)\n",
      "s07e14a (467, 8192)\n",
      "s07e14b (501, 8192)\n",
      "s07e15a (567, 8192)\n",
      "s07e15b (601, 8192)\n",
      "s07e16a (398, 8192)\n",
      "s07e16b (402, 8192)\n",
      "s07e16c (432, 8192)\n",
      "s07e17a (433, 8192)\n",
      "s07e17b (468, 8192)\n",
      "s07e18a (477, 8192)\n",
      "s07e18b (512, 8192)\n",
      "s07e19a (437, 8192)\n",
      "s07e19b (471, 8192)\n",
      "s07e20a (454, 8192)\n",
      "s07e20b (488, 8192)\n",
      "s07e21a (430, 8192)\n",
      "s07e21b (464, 8192)\n",
      "s07e22a (472, 8192)\n",
      "s07e22b (506, 8192)\n",
      "s07e23a (481, 8192)\n",
      "s07e23b (485, 8192)\n",
      "s07e23c (485, 8192)\n",
      "s07e23d (515, 8192)\n",
      "\n",
      "audio features movie names and shape:\n",
      "s07e01a (460, 128)\n",
      "s07e01b (494, 128)\n",
      "s07e02a (492, 128)\n",
      "s07e02b (526, 128)\n",
      "s07e03a (418, 128)\n",
      "s07e03b (452, 128)\n",
      "s07e04a (448, 128)\n",
      "s07e04b (482, 128)\n",
      "s07e05a (454, 128)\n",
      "s07e05b (488, 128)\n",
      "s07e06a (478, 128)\n",
      "s07e06b (513, 128)\n",
      "s07e07a (473, 128)\n",
      "s07e07b (507, 128)\n",
      "s07e08a (475, 128)\n",
      "s07e08b (509, 128)\n",
      "s07e09a (451, 128)\n",
      "s07e09b (485, 128)\n",
      "s07e10a (460, 128)\n",
      "s07e10b (494, 128)\n",
      "s07e11a (465, 128)\n",
      "s07e11b (499, 128)\n",
      "s07e12a (452, 128)\n",
      "s07e12b (487, 128)\n",
      "s07e13a (540, 128)\n",
      "s07e13b (574, 128)\n",
      "s07e14a (467, 128)\n",
      "s07e14b (501, 128)\n",
      "s07e15a (567, 128)\n",
      "s07e15b (601, 128)\n",
      "s07e16a (398, 128)\n",
      "s07e16b (402, 128)\n",
      "s07e16c (432, 128)\n",
      "s07e17a (433, 128)\n",
      "s07e17b (468, 128)\n",
      "s07e18a (477, 128)\n",
      "s07e18b (512, 128)\n",
      "s07e19a (437, 128)\n",
      "s07e19b (471, 128)\n",
      "s07e20a (454, 128)\n",
      "s07e20b (488, 128)\n",
      "s07e21a (430, 128)\n",
      "s07e21b (464, 128)\n",
      "s07e22a (472, 128)\n",
      "s07e22b (506, 128)\n",
      "s07e23a (481, 128)\n",
      "s07e23b (485, 128)\n",
      "s07e23c (485, 128)\n",
      "s07e23d (515, 128)\n",
      "\n",
      "language features movie names and shape:\n",
      "s07e01a (459, 768)\n",
      "s07e01b (493, 768)\n",
      "s07e02a (491, 768)\n",
      "s07e02b (525, 768)\n",
      "s07e03a (417, 768)\n",
      "s07e03b (451, 768)\n",
      "s07e04a (447, 768)\n",
      "s07e04b (481, 768)\n",
      "s07e05a (453, 768)\n",
      "s07e05b (487, 768)\n",
      "s07e06a (477, 768)\n",
      "s07e06b (512, 768)\n",
      "s07e07a (472, 768)\n",
      "s07e07b (506, 768)\n",
      "s07e08a (474, 768)\n",
      "s07e08b (508, 768)\n",
      "s07e09a (450, 768)\n",
      "s07e09b (484, 768)\n",
      "s07e10a (458, 768)\n",
      "s07e10b (493, 768)\n",
      "s07e11a (464, 768)\n",
      "s07e11b (498, 768)\n",
      "s07e12a (451, 768)\n",
      "s07e12b (486, 768)\n",
      "s07e13a (539, 768)\n",
      "s07e13b (573, 768)\n",
      "s07e14a (466, 768)\n",
      "s07e14b (500, 768)\n",
      "s07e15a (566, 768)\n",
      "s07e15b (600, 768)\n",
      "s07e16a (397, 768)\n",
      "s07e16b (401, 768)\n",
      "s07e16c (431, 768)\n",
      "s07e17a (432, 768)\n",
      "s07e17b (467, 768)\n",
      "s07e18a (476, 768)\n",
      "s07e18b (511, 768)\n",
      "s07e19a (436, 768)\n",
      "s07e19b (470, 768)\n",
      "s07e20a (453, 768)\n",
      "s07e20b (487, 768)\n",
      "s07e21a (429, 768)\n",
      "s07e21b (463, 768)\n",
      "s07e22a (471, 768)\n",
      "s07e22b (505, 768)\n",
      "s07e23a (480, 768)\n",
      "s07e23b (484, 768)\n",
      "s07e23c (484, 768)\n",
      "s07e23d (514, 768)\n"
     ]
    }
   ],
   "source": [
    "for key_modality, value_modality in test_stimuli.items():\n",
    "    print(f\"\\n{key_modality} features movie names and shape:\")\n",
    "    for key_movie, value_movie in value_modality.items():\n",
    "        print(key_movie + \" \" + str(value_movie.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning stimulus and fMRI features of the four subjects: 100%|██████████| 4/4 [00:08<00:00,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: sub-01\n",
      "  Episode: s07e01a - visual features shape: (460, 5, 8192)\n",
      "  Episode: s07e01a - audio features shape: (460, 5, 128)\n",
      "  Episode: s07e01a - language features shape: (460, 768)\n",
      "----------------------------------------\n",
      "Subject: sub-02\n",
      "  Episode: s07e01a - visual features shape: (460, 5, 8192)\n",
      "  Episode: s07e01a - audio features shape: (460, 5, 128)\n",
      "  Episode: s07e01a - language features shape: (460, 768)\n",
      "----------------------------------------\n",
      "Subject: sub-03\n",
      "  Episode: s07e01a - visual features shape: (460, 5, 8192)\n",
      "  Episode: s07e01a - audio features shape: (460, 5, 128)\n",
      "  Episode: s07e01a - language features shape: (460, 768)\n",
      "----------------------------------------\n",
      "Subject: sub-05\n",
      "  Episode: s07e01a - visual features shape: (460, 5, 8192)\n",
      "  Episode: s07e01a - audio features shape: (460, 5, 128)\n",
      "  Episode: s07e01a - language features shape: (460, 768)\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "aligned_features_friends_s7 = align_features_and_fmri_samples_friends_s7(\n",
    "    test_stimuli, fmri_dir)\n",
    "\n",
    "# As an example, print the shape of the stimulus features of one episode for\n",
    "# each subject\n",
    "for key, val in aligned_features_friends_s7.items():\n",
    "    episode_name = \"s07e01a\"\n",
    "    example_episode_shape_visual = val[episode_name]['visual'].shape\n",
    "    example_episode_shape_audio = val[episode_name]['audio'].shape\n",
    "    example_episode_shape_language = val[episode_name]['language'].shape\n",
    "    print(f\"Subject: {key}\")\n",
    "    print(f\"  Episode: {episode_name} - visual features shape: {example_episode_shape_visual}\")\n",
    "    print(f\"  Episode: {episode_name} - audio features shape: {example_episode_shape_audio}\")\n",
    "    print(f\"  Episode: {episode_name} - language features shape: {example_episode_shape_language}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_predictions = {}\n",
    "\n",
    "# Loop through each subject\n",
    "desc = \"Predicting fMRI responses of each subject\"\n",
    "for sub, features in tqdm(aligned_features_friends_s7.items(), desc=desc):\n",
    "\n",
    "    # Initialize the nested dictionary for each subject's predictions\n",
    "    submission_predictions[sub] = {}\n",
    "\n",
    "    # Loop through each Friends season 7 episode\n",
    "    for epi, feat_epi in features.items():\n",
    "\n",
    "        # convert the predictions to float32\n",
    "        video = torch.tensor(feat_epi['visual']).cuda()\n",
    "        audio = torch.tensor(feat_epi['audio']).cuda()\n",
    "        text = torch.tensor(feat_epi['language']).cuda()\n",
    "        fmri_pred = model(video, audio, text).detach().cpu().numpy() #TODO: Replace model with your trained model\n",
    "\n",
    "        # Store formatted predictions in the nested dictionary\n",
    "        submission_predictions[sub][epi] = fmri_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the saving directory\n",
    "run_name = \"model_name\"\n",
    "save_dir = Path('saved_preds/') / run_name\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Save the predicted fMRI dictionary as a .npy file\n",
    "output_file = save_dir / \"fmri_predictions_friends_s7.npy\"\n",
    "np.save(output_file, submission_predictions)\n",
    "print(f\"Formatted predictions saved to: {output_file}\")\n",
    "\n",
    "# Zip the saved file for submission\n",
    "zip_file = save_dir / \"fmri_predictions_friends_s7.zip\"  # Use / instead of +\n",
    "with zipfile.ZipFile(zip_file, 'w') as zipf:\n",
    "    zipf.write(output_file, os.path.basename(output_file))\n",
    "print(f\"Submission file successfully zipped as: {zip_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the zip file to Codabench for eval."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
