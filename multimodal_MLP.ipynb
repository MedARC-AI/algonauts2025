{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import lightning as L\n",
    "from vector_quantize_pytorch import VectorQuantize\n",
    "from torchmetrics.functional import pearson_corrcoef\n",
    "from pathlib import Path\n",
    "\n",
    "from utils import load_fmri, align_features_and_fmri_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlgonautsDataset(Dataset):\n",
    "    def __init__(self, features_dir, fmri_dir, movies, subject, excluded_samples_start=5, excluded_samples_end=5, hrf_delay=3, stimulus_window=5):\n",
    "        self.features_dir = features_dir\n",
    "        self.fmri_dir = fmri_dir\n",
    "        self.movies = movies\n",
    "        self.subject = subject\n",
    "        self.excluded_samples_start = excluded_samples_start\n",
    "        self.excluded_samples_end = excluded_samples_end\n",
    "        self.hrf_delay = hrf_delay\n",
    "        self.stimulus_window = stimulus_window\n",
    "        self.partition_indices = defaultdict(list)\n",
    "        \n",
    "        # First load all raw features\n",
    "        stimuli_features = {\"visual\": {}, \"audio\": {}, \"language\": {}}\n",
    "        # Load audio and video features first\n",
    "        for movie in self.movies:\n",
    "            if 'friends' in movie:\n",
    "                season = movie.split('-')[1]\n",
    "                dir_list = sorted(os.listdir(self.features_dir + 'audio')) #List of all audio for each subset of dataset\n",
    "                for episode in dir_list:\n",
    "                    if f\"{season}e\" in episode and '_features_' in episode:\n",
    "                        episode_base = episode.split('_features_')[0] # friends_s01e01 and so on....\n",
    "                        \n",
    "                        for modality in ['audio', 'visual']:\n",
    "                            with h5py.File(os.path.join(self.features_dir, modality, f\"{episode_base}_features_{modality}.h5\"), 'r') as f:\n",
    "                                try:\n",
    "                                    stimuli_features[modality][episode_base.split('_')[1]] = f[episode_base.split('_')[1]][modality][:]\n",
    "                                except:\n",
    "                                    f.visit(lambda x: print(x))\n",
    "                lang_dir_list = sorted(os.listdir(self.features_dir + 'language'))\n",
    "                for episode in lang_dir_list:\n",
    "                    if f\"{season}e\" in episode and '_features_' in episode:\n",
    "                        episode_base = episode.split('_features_')[0]\n",
    "                        \n",
    "                        with h5py.File(os.path.join(self.features_dir, 'language', f\"{episode_base}_features_language.h5\"), 'r') as f:\n",
    "                            try:\n",
    "                                st_season_episode = episode_base.split('_')[1]\n",
    "                                stimuli_features['language'][st_season_episode] = f[st_season_episode]['language_pooler_output'][:]\n",
    "                            except:\n",
    "                                f.visit(lambda x: print(x))\n",
    "            else:\n",
    "                movie_name = movie.replace('movie10-', '')\n",
    "                partitions = sorted([f for f in os.listdir(self.features_dir + 'audio') if movie_name in f and '_features_' in f])\n",
    "                \n",
    "                for partition in partitions:\n",
    "                    partition_base = partition.split('_features_')[0]\n",
    "                    \n",
    "                    for modality in ['audio', 'visual']:\n",
    "                        with h5py.File(os.path.join(self.features_dir, modality, f\"{partition_base}_features_{modality}.h5\"), 'r') as f:\n",
    "                            try:\n",
    "                                stimuli_features[modality][partition_base] = f[partition_base][modality][:]\n",
    "                            except:\n",
    "                                f.visit(lambda x: print(x))\n",
    "                lang_partitions = sorted([f for f in os.listdir(self.features_dir + 'language') if movie_name in f and '_features_' in f])\n",
    "                \n",
    "                for partition in lang_partitions:\n",
    "                    partition_base = partition.split('_features_')[0]\n",
    "                    \n",
    "                    with h5py.File(os.path.join(self.features_dir, 'language', f\"{partition_base}_features_language.h5\"), 'r') as f:\n",
    "                        try:\n",
    "                            stimuli_features['language'][partition_base] = f[partition_base]['language_pooler_output'][:]\n",
    "                        except:\n",
    "                            f.visit(lambda x: print(x))\n",
    "\n",
    "        fmri_data = load_fmri(self.fmri_dir, self.subject)\n",
    "\n",
    "        self.aligned_features, self.aligned_fmri = align_features_and_fmri_samples(\n",
    "            stimuli_features, \n",
    "            fmri_data, \n",
    "            self.excluded_samples_start, \n",
    "            self.excluded_samples_end, \n",
    "            self.hrf_delay, \n",
    "            self.stimulus_window, \n",
    "            self.movies\n",
    "        )\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.aligned_features['audio'].shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'audio': self.aligned_features['audio'][idx],\n",
    "            'video': self.aligned_features['visual'][idx],\n",
    "            'language': self.aligned_features['language'][idx],\n",
    "            'fmri': self.aligned_fmri[idx]\n",
    "        }\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stimuli_features loaded:  dict_keys(['visual', 'audio', 'language'])\n",
      "fmri_data loaded\n",
      "stimuli and fmri aligned\n",
      "stimuli_features loaded:  dict_keys(['visual', 'audio', 'language'])\n",
      "fmri_data loaded\n",
      "stimuli and fmri aligned\n"
     ]
    }
   ],
   "source": [
    "features_dir = '/home/pranav/mihir/algonauts_challenge/AlgonautsDS-features/developer_kit/stimulus_features/raw/'\n",
    "fmri_dir = '/home/pranav/mihir/algonauts_challenge/algonauts_2025.competitors/fmri/'\n",
    "movies_train = [\"friends-s01\"]\n",
    "# movies_train = [\"friends-s01\", \"friends-s02\", \"friends-s03\", \"friends-s04\", \"friends-s05\", \"movie10-bourne\", \"movie10-figures\", \"movie10-life\", \"movie10-wolf\"]\n",
    "movies_val = [\"friends-s06\"]\n",
    "modality = \"all\"  #@param [\"visual\", \"audio\", \"language\", \"all\"]\n",
    "\n",
    "excluded_samples_start = 5  #@param {type:\"slider\", min:0, max:20, step:1}\n",
    "excluded_samples_end = 5  #@param {type:\"slider\", min:0, max:20, step:1}\n",
    "hrf_delay = 3  #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "stimulus_window = 5\n",
    "\n",
    "subject = 1 #@param [\"1\", \"2\", \"3\", \"5\"] {type:\"raw\", allow-input: true}\n",
    "\n",
    "train_ds = AlgonautsDataset(features_dir, fmri_dir, movies=movies_train, subject=subject, excluded_samples_start=excluded_samples_start, excluded_samples_end=excluded_samples_end, hrf_delay=hrf_delay, stimulus_window=stimulus_window)\n",
    "val_ds = AlgonautsDataset(features_dir, fmri_dir, movies=movies_val, subject=subject, excluded_samples_start=excluded_samples_start, excluded_samples_end=excluded_samples_end, hrf_delay=hrf_delay, stimulus_window=stimulus_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 128)\n",
      "(5, 8192)\n",
      "(768,)\n",
      "(1000,)\n",
      "22787\n",
      "22924\n"
     ]
    }
   ],
   "source": [
    "print(train_ds[0]['audio'].shape)\n",
    "print(train_ds[0]['video'].shape)\n",
    "print(train_ds[0]['language'].shape)\n",
    "print(train_ds[0]['fmri'].shape)\n",
    "print(len(train_ds))\n",
    "print(len(val_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22787\n",
      "22924\n"
     ]
    }
   ],
   "source": [
    "print(len(train_ds))\n",
    "print(len(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "torch.Size([250])\n",
      "torch.Size([250])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "audio, video, language, fmri = train_ds[0]['audio'], train_ds[0]['video'], train_ds[0]['language'], train_ds[0]['fmri']\n",
    "print(audio.shape)\n",
    "print(video.shape)\n",
    "print(language.shape)\n",
    "print(fmri.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_workers = 4\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'friends-s01': (0, 22787)})\n"
     ]
    }
   ],
   "source": [
    "print(train_ds.get_partition_indices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ses-001_task-s01e02a', 'ses-001_task-s01e02b', 'ses-001_task-s01e03a', 'ses-001_task-s01e03b', 'ses-002_task-s01e04a', 'ses-002_task-s01e04b', 'ses-002_task-s01e05a', 'ses-002_task-s01e05b', 'ses-003_task-s01e01a', 'ses-003_task-s01e01b', 'ses-003_task-s01e06a', 'ses-003_task-s01e06b', 'ses-004_task-s01e07a', 'ses-004_task-s01e07b', 'ses-004_task-s01e08a', 'ses-004_task-s01e08b', 'ses-004_task-s01e09a', 'ses-004_task-s01e09b', 'ses-005_task-s01e10a', 'ses-005_task-s01e10b', 'ses-005_task-s01e11a', 'ses-005_task-s01e11b', 'ses-006_task-s01e12a', 'ses-006_task-s01e12b', 'ses-006_task-s01e13a', 'ses-006_task-s01e13b', 'ses-006_task-s01e14a', 'ses-006_task-s01e14b', 'ses-007_task-s01e15a', 'ses-007_task-s01e15b', 'ses-007_task-s01e16a', 'ses-007_task-s01e16b', 'ses-007_task-s01e17a', 'ses-007_task-s01e17b', 'ses-008_task-s01e18a', 'ses-008_task-s01e18b', 'ses-008_task-s01e19a', 'ses-008_task-s01e19b', 'ses-009_task-s01e20a', 'ses-009_task-s01e20b', 'ses-009_task-s01e21a', 'ses-009_task-s01e21b', 'ses-009_task-s01e22a', 'ses-009_task-s01e22b', 'ses-010_task-s01e23a', 'ses-010_task-s01e23b', 'ses-010_task-s01e24a', 'ses-010_task-s01e24b', 'ses-010_task-s02e01a', 'ses-010_task-s02e01b', 'ses-011_task-s02e02a', 'ses-011_task-s02e02b', 'ses-011_task-s02e03a', 'ses-011_task-s02e03b', 'ses-011_task-s02e04a', 'ses-011_task-s02e04b', 'ses-011_task-s02e05a', 'ses-011_task-s02e05b', 'ses-012_task-s02e06a', 'ses-012_task-s02e06b', 'ses-012_task-s02e07a', 'ses-012_task-s02e07b', 'ses-013_task-s02e08a', 'ses-013_task-s02e08b', 'ses-013_task-s02e09a', 'ses-013_task-s02e09b', 'ses-013_task-s02e10a', 'ses-013_task-s02e10b', 'ses-014_task-s02e11a', 'ses-014_task-s02e11b', 'ses-014_task-s02e12a', 'ses-014_task-s02e12b', 'ses-014_task-s02e13a', 'ses-014_task-s02e13b', 'ses-015_task-s02e14a', 'ses-015_task-s02e14b', 'ses-015_task-s02e15a', 'ses-015_task-s02e15b', 'ses-016_task-s02e16a', 'ses-016_task-s02e16b', 'ses-016_task-s02e17a', 'ses-016_task-s02e17b', 'ses-017_task-s02e18a', 'ses-017_task-s02e18b', 'ses-017_task-s02e19a', 'ses-017_task-s02e19b', 'ses-017_task-s02e20a', 'ses-017_task-s02e20b', 'ses-017_task-s02e21a', 'ses-017_task-s02e21b', 'ses-017_task-s02e22a', 'ses-017_task-s02e22b', 'ses-018_task-s02e23a', 'ses-018_task-s02e23b', 'ses-018_task-s02e24a', 'ses-018_task-s02e24b', 'ses-019_task-s03e01a', 'ses-019_task-s03e01b', 'ses-019_task-s03e02a', 'ses-019_task-s03e02b', 'ses-019_task-s03e03a', 'ses-019_task-s03e03b', 'ses-020_task-s03e04a', 'ses-020_task-s03e04b', 'ses-020_task-s03e05a', 'ses-020_task-s03e05b', 'ses-020_task-s03e06a', 'ses-020_task-s03e06b', 'ses-021_task-s03e07a', 'ses-021_task-s03e07b', 'ses-021_task-s03e08a', 'ses-021_task-s03e08b', 'ses-021_task-s03e09a', 'ses-021_task-s03e09b', 'ses-022_task-s03e10a', 'ses-022_task-s03e10b', 'ses-022_task-s03e11a', 'ses-022_task-s03e11b', 'ses-022_task-s03e12a', 'ses-022_task-s03e12b', 'ses-023_task-s03e13a', 'ses-023_task-s03e13b', 'ses-023_task-s03e14a', 'ses-023_task-s03e14b', 'ses-024_task-s03e15a', 'ses-024_task-s03e15b', 'ses-024_task-s03e16a', 'ses-024_task-s03e16b', 'ses-024_task-s03e17a', 'ses-024_task-s03e17b', 'ses-025_task-s03e18a', 'ses-025_task-s03e18b', 'ses-025_task-s03e19a', 'ses-025_task-s03e19b', 'ses-025_task-s03e20a', 'ses-025_task-s03e20b', 'ses-026_task-s03e21a', 'ses-026_task-s03e21b', 'ses-026_task-s03e22a', 'ses-026_task-s03e22b', 'ses-027_task-s03e23a', 'ses-027_task-s03e23b', 'ses-027_task-s03e24a', 'ses-027_task-s03e24b', 'ses-027_task-s03e25a', 'ses-027_task-s03e25b', 'ses-027_task-s04e01a', 'ses-027_task-s04e01b', 'ses-027_task-s04e02a', 'ses-027_task-s04e02b', 'ses-028_task-s04e03a', 'ses-028_task-s04e03b', 'ses-028_task-s04e04a', 'ses-028_task-s04e04b', 'ses-028_task-s04e05a', 'ses-028_task-s04e05b', 'ses-028_task-s04e06a', 'ses-028_task-s04e06b', 'ses-028_task-s04e07a', 'ses-028_task-s04e07b', 'ses-029_task-s04e08a', 'ses-029_task-s04e08b', 'ses-029_task-s04e09a', 'ses-029_task-s04e09b', 'ses-029_task-s04e10a', 'ses-029_task-s04e10b', 'ses-029_task-s04e11a', 'ses-029_task-s04e11b', 'ses-030_task-s04e12a', 'ses-030_task-s04e12b', 'ses-030_task-s04e13a', 'ses-030_task-s04e13b', 'ses-030_task-s04e14a', 'ses-030_task-s04e14b', 'ses-031_task-s04e15a', 'ses-031_task-s04e15b', 'ses-031_task-s04e16a', 'ses-031_task-s04e16b', 'ses-031_task-s04e17a', 'ses-031_task-s04e17b', 'ses-032_task-s04e18a', 'ses-032_task-s04e18b', 'ses-032_task-s04e19a', 'ses-032_task-s04e19b', 'ses-033_task-s04e20a', 'ses-033_task-s04e20b', 'ses-034_task-s04e21a', 'ses-034_task-s04e21b', 'ses-034_task-s04e22a', 'ses-034_task-s04e22b', 'ses-035_task-s04e23a', 'ses-035_task-s04e23b', 'ses-035_task-s04e23c', 'ses-035_task-s04e23d', 'ses-036_task-s05e01a', 'ses-036_task-s05e01b', 'ses-036_task-s05e02a', 'ses-036_task-s05e02b', 'ses-037_task-s05e03a', 'ses-037_task-s05e03b', 'ses-037_task-s05e04a', 'ses-037_task-s05e04b', 'ses-041_task-s05e05a', 'ses-041_task-s05e05b', 'ses-041_task-s05e06a', 'ses-041_task-s05e06b', 'ses-042_task-s05e07a', 'ses-042_task-s05e07b', 'ses-043_task-s05e08a', 'ses-043_task-s05e08b', 'ses-044_task-s05e09a', 'ses-044_task-s05e09b', 'ses-044_task-s05e10a', 'ses-044_task-s05e10b', 'ses-045_task-s05e11a', 'ses-045_task-s05e11b', 'ses-045_task-s05e12a', 'ses-045_task-s05e12b', 'ses-046_task-s05e13a', 'ses-046_task-s05e13b', 'ses-046_task-s05e14a', 'ses-046_task-s05e14b', 'ses-047_task-s05e15a', 'ses-047_task-s05e15b', 'ses-047_task-s05e16a', 'ses-047_task-s05e16b', 'ses-048_task-s05e17a', 'ses-048_task-s05e17b', 'ses-048_task-s05e18a', 'ses-048_task-s05e18b', 'ses-049_task-s05e19a', 'ses-049_task-s05e19b', 'ses-049_task-s05e20a', 'ses-049_task-s05e20b', 'ses-050_task-s05e21a', 'ses-050_task-s05e21b', 'ses-050_task-s05e22a', 'ses-050_task-s05e22b', 'ses-051_task-s05e23a', 'ses-051_task-s05e23b', 'ses-052_task-s05e23c', 'ses-052_task-s05e23d', 'ses-052_task-s06e01a', 'ses-052_task-s06e01b', 'ses-053_task-s06e02a', 'ses-053_task-s06e02b', 'ses-053_task-s06e03a', 'ses-053_task-s06e03b', 'ses-053_task-s06e04a', 'ses-054_task-s06e04b', 'ses-054_task-s06e05a', 'ses-054_task-s06e05b', 'ses-055_task-s06e06a', 'ses-055_task-s06e06b', 'ses-055_task-s06e07a', 'ses-055_task-s06e07b', 'ses-056_task-s06e08a', 'ses-056_task-s06e08b', 'ses-056_task-s06e09a', 'ses-056_task-s06e09b', 'ses-056_task-s06e10a', 'ses-057_task-s06e10b', 'ses-057_task-s06e11a', 'ses-057_task-s06e11b', 'ses-057_task-s06e12a', 'ses-057_task-s06e12b', 'ses-058_task-s06e13a', 'ses-058_task-s06e13b', 'ses-058_task-s06e14a', 'ses-058_task-s06e14b', 'ses-059_task-s06e15a', 'ses-060_task-s06e15b', 'ses-060_task-s06e15c', 'ses-061_task-s06e15d', 'ses-061_task-s06e17a', 'ses-061_task-s06e17b', 'ses-062_task-s06e18a', 'ses-062_task-s06e18b', 'ses-062_task-s06e19a', 'ses-062_task-s06e19b', 'ses-063_task-s06e20a', 'ses-063_task-s06e20b', 'ses-063_task-s06e21a', 'ses-064_task-s06e21b', 'ses-064_task-s06e22a', 'ses-064_task-s06e22b', 'ses-065_task-s06e23a', 'ses-065_task-s06e23b', 'ses-065_task-s06e24a', 'ses-066_task-s06e24b', 'ses-066_task-s06e24c', 'ses-066_task-s06e24d']\n"
     ]
    }
   ],
   "source": [
    "file = \"/home/pranav/mihir/algonauts_challenge/algonauts_2025.competitors/fmri/sub-01/func/sub-01_task-friends_space-MNI152NLin2009cAsym_atlas-Schaefer18_parcel-1000Par7Net_desc-s123456_bold.h5\"\n",
    "with h5py.File(file, 'r') as f:\n",
    "    key_arr = list(f.keys())\n",
    "    data = []\n",
    "    data_keys = []\n",
    "    for key in sorted(key_arr):\n",
    "        if 's01' in key:\n",
    "            data_keys.append(key)\n",
    "            data.append(f[key][:])\n",
    "    data = np.concatenate(data, axis=0)\n",
    "    # print(f['sub-01_task-friends_space-MNI152NLin2009cAsym_atlas-Schaefer18_parcel-1000Par7Net_desc-s123456_bold'].shape)\n",
    "print(sorted(key_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(data_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for i in train_ds:\n",
    "    # print(i['fmri'].shape)\n",
    "    # print(i['audio'].shape)\n",
    "    # print(i['video'].shape)\n",
    "    # print(i['language'].shape)\n",
    "    num += 1\n",
    "print(num)\n",
    "# print(i['fmri'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "   def __init__(self, in_dim, out_dim):\n",
    "       super().__init__()\n",
    "       self.downsample = in_dim != out_dim\n",
    "       self.net = nn.Sequential(\n",
    "           nn.Linear(in_dim, out_dim),\n",
    "           nn.LayerNorm(out_dim),\n",
    "           nn.GELU(),\n",
    "           nn.Linear(out_dim, out_dim),\n",
    "           nn.LayerNorm(out_dim),\n",
    "           nn.GELU()\n",
    "       )\n",
    "       if self.downsample:\n",
    "           self.proj = nn.Linear(in_dim, out_dim)\n",
    "   \n",
    "   def forward(self, x):\n",
    "       if self.downsample:\n",
    "           return self.proj(x) + self.net(x)\n",
    "       return x + self.net(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "   def __init__(self, input_dim=1000, hidden_dims=[512, 384, 256], num_tokens=32, codebook_dim=64):\n",
    "       super().__init__()\n",
    "       \n",
    "       # Initial projection with one residual block\n",
    "       self.input_proj = ResidualBlock(input_dim, hidden_dims[0])\n",
    "       \n",
    "       # Main network with one residual block per layer\n",
    "       layers = []\n",
    "       for i in range(len(hidden_dims)-1):\n",
    "           layers.append(ResidualBlock(hidden_dims[i], hidden_dims[i+1]))\n",
    "       self.layers = nn.Sequential(*layers)\n",
    "       \n",
    "       # Project to token space with one residual block\n",
    "       self.token_proj = ResidualBlock(hidden_dims[-1], num_tokens * codebook_dim)\n",
    "       \n",
    "       self.num_tokens = num_tokens\n",
    "       self.codebook_dim = codebook_dim\n",
    "       \n",
    "   def forward(self, x):\n",
    "       x = self.input_proj(x)\n",
    "       x = self.layers(x)\n",
    "       x = self.token_proj(x)\n",
    "       return x.view(x.shape[0], self.num_tokens, self.codebook_dim)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "   def __init__(self, output_dim=1000, hidden_dims=[256, 384, 512], num_tokens=32, codebook_dim=64):\n",
    "       super().__init__()\n",
    "       \n",
    "       # Process tokens with one residual block\n",
    "       self.token_proj = ResidualBlock(num_tokens * codebook_dim, hidden_dims[0])\n",
    "       \n",
    "       # Main network with one residual block per layer\n",
    "       layers = []\n",
    "       for i in range(len(hidden_dims)-1):\n",
    "           layers.append(ResidualBlock(hidden_dims[i], hidden_dims[i+1]))\n",
    "       self.layers = nn.Sequential(*layers)\n",
    "       \n",
    "       # Final projection with one residual block\n",
    "       self.output_proj = ResidualBlock(hidden_dims[-1], output_dim)\n",
    "       \n",
    "   def forward(self, x):\n",
    "       # x shape: [batch_size, num_tokens, codebook_dim] \n",
    "       x = x.reshape(x.shape[0], -1)  # Flatten tokens\n",
    "       x = self.token_proj(x)\n",
    "       x = self.layers(x)\n",
    "       return self.output_proj(x)\n",
    "\n",
    "class VQVAE(L.LightningModule):\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_dim=1000, \n",
    "            hidden_dims=[512, 384, 256], \n",
    "            num_tokens=32, \n",
    "            codebook_size=1024, \n",
    "            codebook_dim=8,\n",
    "            commitment_weight=0.25,\n",
    "            quantizer_decay=0.99,\n",
    "            learning_rate=3e-4,\n",
    "            weight_decay=0.01\n",
    "            ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(input_dim, hidden_dims, num_tokens, codebook_dim)\n",
    "        self.decoder = Decoder(input_dim, hidden_dims[::-1], num_tokens, codebook_dim)\n",
    "        self.quantizer = VectorQuantize(\n",
    "                dim=codebook_dim,\n",
    "                codebook_size=codebook_size,\n",
    "                decay=quantizer_decay,\n",
    "                commitment_weight=commitment_weight\n",
    "                )\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z_q, indices, commitment_loss = self.quantizer(z)\n",
    "        x_recon = self.decoder(z_q)\n",
    "        return x_recon, commitment_loss, indices\n",
    "    \n",
    "    def encode(self, x):\n",
    "        z = self.encoder(x)\n",
    "        _, indices, _ = self.quantizer(z)\n",
    "        return indices\n",
    "        \n",
    "    def decode(self, indices):\n",
    "        z_q = self.quantizer.get_codes_from_indices(indices)\n",
    "        return self.decoder(z_q)\n",
    "    \n",
    "class MultiModalMLP(L.LightningModule):\n",
    "    def __init__(self, video_dim, audio_dim, text_dim, hidden_dim, num_tokens, fmri_tok_dir, learning_rate, weight_decay):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Dimensions for each modality\n",
    "        self.video_dim = video_dim \n",
    "        self.audio_dim = audio_dim\n",
    "        self.text_dim = text_dim\n",
    "        self.fmri_tokenizer = VQVAE.load_from_checkpoint(fmri_tok_dir)\n",
    "        \n",
    "        for param in self.fmri_tokenizer.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.fmri_tokenizer.eval()\n",
    "        \n",
    "        # Trainable token for missing text\n",
    "        self.missing_text_token = nn.Parameter(torch.randn(1, text_dim))\n",
    "        \n",
    "        # MLP layers\n",
    "        total_dim = video_dim + audio_dim + text_dim\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(total_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, num_tokens)\n",
    "        )\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, video, audio, text):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            video: [batch_size, video_dim]\n",
    "            audio: [batch_size, audio_dim] \n",
    "            text: [batch_size, text_dim]\n",
    "        \"\"\"\n",
    "        batch_size = video.shape[0]\n",
    "        # Generate text mask based on NaN values\n",
    "        text_mask = ~torch.isnan(text).any(dim=1, keepdim=True)\n",
    "        \n",
    "        # Replace missing text with learned token\n",
    "        text = torch.where(\n",
    "            text_mask,\n",
    "            text,\n",
    "            self.missing_text_token.expand(batch_size, -1)\n",
    "        )\n",
    "        \n",
    "        # Concatenate all features\n",
    "        text = text.unsqueeze(1)\n",
    "        x = torch.cat([video, audio, text], dim=-1).squeeze(1)\n",
    "        # Predict tokens\n",
    "        return self.mlp(x)\n",
    "\n",
    "    def calculate_metrics(self, x, x_recon):\n",
    "        # Flatten the tensors for correlation calculation\n",
    "        x_flat = x.reshape(x.shape[0], -1)\n",
    "        x_recon_flat = x_recon.reshape(x_recon.shape[0], -1)\n",
    "        \n",
    "        # Calculate Pearson R for each sample in batch\n",
    "        correlations = torch.stack([\n",
    "            pearson_corrcoef(x_flat[i], x_recon_flat[i])\n",
    "            for i in range(x_flat.shape[0])\n",
    "        ])\n",
    "        avg_pearson_r = correlations.mean()\n",
    "        \n",
    "        # Calculate variance explained\n",
    "        total_variance = torch.var(x_flat, dim=1).sum()\n",
    "        residual_variance = torch.var(x_flat - x_recon_flat, dim=1).sum()\n",
    "        variance_explained = 1 - (residual_variance / total_variance)\n",
    "        \n",
    "        # Calculate MSE and MAE\n",
    "        mse = F.mse_loss(x_flat, x_recon_flat)\n",
    "        mae = F.l1_loss(x_flat, x_recon_flat)\n",
    "        \n",
    "        return avg_pearson_r, variance_explained, mse, mae\n",
    "        \n",
    "\n",
    "    def training_step(self, batch):\n",
    "        video, audio, text, fmri = batch['video'], batch['audio'], batch['language'], batch['fmri']\n",
    "        logits = self(video, audio, text)\n",
    "        fmri_tokens = self.fmri_tokenizer.encode(fmri).to(dtype=logits.dtype)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = criterion(logits, fmri_tokens)\n",
    "        recon_fmri = self.fmri_tokenizer.decode(logits.round().long())\n",
    "\n",
    "        avg_pearson_r, variance_explained, mse, mae = self.calculate_metrics(fmri, recon_fmri)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_pearson_r', avg_pearson_r)\n",
    "        self.log('train_variance_explained', variance_explained)\n",
    "        self.log('train_mse', mse)\n",
    "        self.log('train_mae', mae)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        video, audio, text, fmri = batch['video'], batch['audio'], batch['language'], batch['fmri']\n",
    "        logits = self(video, audio, text)\n",
    "        fmri_tokens = self.fmri_tokenizer.encode(fmri).to(dtype=logits.dtype)\n",
    "        \n",
    "        criterion = nn.MSELoss()\n",
    "        val_loss = criterion(logits, fmri_tokens)\n",
    "        val_recon_fmri = self.fmri_tokenizer.decode(logits.round().long())\n",
    "        val_avg_pearson_r, val_variance_explained, val_mse, val_mae = self.calculate_metrics(fmri, val_recon_fmri)\n",
    "        \n",
    "        self.log('val_loss', val_loss)\n",
    "        self.log('val_pearson_r', val_avg_pearson_r)\n",
    "        self.log('val_variance_explained', val_variance_explained)\n",
    "        self.log('val_mse', val_mse)\n",
    "        self.log('val_mae', val_mae)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(), \n",
    "            lr=self.learning_rate, \n",
    "            betas=(0.9, 0.999), \n",
    "            eps=1e-8, \n",
    "            weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"monitor\": \"val_loss\"\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "\n",
    "batch_size = 4\n",
    "video_dim = 8192\n",
    "audio_dim = 128\n",
    "text_dim = 768\n",
    "hidden_dim = 1024\n",
    "num_tokens = 32\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 0.01 \n",
    "num_workers = 4\n",
    "fmri_tok_dir = \"/home/pranav/mihir/algonauts_challenge/algonauts2025/checkpoints/fmri_vqvae_res_gelu_8qdim_1024/epoch=44_val_loss=0.137.ckpt\"\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples:  22787\n",
      "Validation samples:  22924\n"
     ]
    }
   ],
   "source": [
    "print(\"Training samples: \", len(train_ds))\n",
    "print(\"Validation samples: \", len(val_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "run_name = \"MM_MLP_1024dim_only_sub01\"\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"algonauts2025\",\n",
    "    name=run_name,\n",
    "    save_dir=\"wandb_logs/\"\n",
    ")\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=50,\n",
    "    precision=32,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            dirpath=f'checkpoints/{run_name}',\n",
    "            filename='{epoch:02d}_{val_loss:.3f}',\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_top_k=1,\n",
    "            save_last=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | Name           | Type       | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | fmri_tokenizer | VQVAE      | 5.4 M  | eval \n",
      "1 | mlp            | Sequential | 10.4 M | train\n",
      "  | other params   | n/a        | 768    | n/a  \n",
      "------------------------------------------------------\n",
      "10.4 M    Trainable params\n",
      "5.4 M     Non-trainable params\n",
      "15.8 M    Total params\n",
      "63.157    Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "79        Modules in eval mode\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.utilities.model_summary import ModelSummary\n",
    "torch.set_float32_matmul_precision('high')\n",
    "mm_mlp = MultiModalMLP(\n",
    "    video_dim=video_dim,\n",
    "    audio_dim=audio_dim,\n",
    "    text_dim=text_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    num_tokens=num_tokens,\n",
    "    fmri_tok_dir=fmri_tok_dir,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "summary = ModelSummary(mm_mlp, max_depth=1)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmihir-neal\u001b[0m (\u001b[33mmihirneal\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>wandb_logs/wandb/run-20250128_195247-5dpepia6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mihirneal/algonauts2025/runs/5dpepia6' target=\"_blank\">MM_MLP_1024dim_only_sub01</a></strong> to <a href='https://wandb.ai/mihirneal/algonauts2025' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mihirneal/algonauts2025' target=\"_blank\">https://wandb.ai/mihirneal/algonauts2025</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mihirneal/algonauts2025/runs/5dpepia6' target=\"_blank\">https://wandb.ai/mihirneal/algonauts2025/runs/5dpepia6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | fmri_tokenizer | VQVAE      | 5.4 M  | eval \n",
      "1 | mlp            | Sequential | 10.4 M | train\n",
      "  | other params   | n/a        | 768    | n/a  \n",
      "------------------------------------------------------\n",
      "10.4 M    Trainable params\n",
      "5.4 M     Non-trainable params\n",
      "15.8 M    Total params\n",
      "63.157    Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "79        Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12e9aa4c87a4090be45f15b8bc0a4c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889b4631a724400089dc35d1d0e78098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd424b2bd714b38b879550de612ef8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94c35b28cfc4fea87e57f788b3e805f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840dd40bcd614e60ade5ec6f1aee2ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bcfad4bfc540e991e319cfd88323a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5e1104b4154a6b92cbc56a3b0587a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1462da9ebd8a4329abbff38a980551c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58408ed5675b4cbc889ee4b56439c45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d14569a2ef4929a47d760121f6988d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6051b0b127264b3782f3b4e3f88ac890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061c45360c21430d884b499af01deb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74054471598a477387f6d2e92d51c59f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a322d4ba24e144e48657ed8a496939a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3fd9894b5145ea9f5bef753d1afac2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29694b1d88534da4a4ce1ec9a92f17f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a2d363da43e49a2aa1007605d0d20b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3599d321a8458f9c25a790e710ac9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0362edcf1c33432ca1c59427227539a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fb7df2d2b446da963e4c4b556931fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f475414037d4368a49591bb2eded23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a3e35e823f49e2872bed302067daf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a410fe73a674bc6b091676dcf1d55b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b041ba833b94cbaad5b9e4a94893f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb0f3be41034841b6d593cc7e09ea60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9476d4fd76e4f5bb379f97a354006db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c549b88498b04e75b82181e891e37e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21b87a8a3d640c091f67878e614ee65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e61ca1d5a345a99b322b46565f2485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382dee5ce60a442495f2712e35ee75cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11dd77b14414e209c3638049f991244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61610f041a5d4902b7693f6039d1d3ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd0bb73ab92431e9202a1083d863813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb34e42a30c4e1fae65b89c87aec8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d430df1ba51440b86ccbbf0a0adb775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d1d282a6964c48a21e4b64ce4f0a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025c6ac514014115bfd3421f6034b973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418e71783d8c4818a916679eb9510ac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4629c85c979f40d6a60984e8860c3c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1200132816414987b4bc26f7d34e61a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c91d7dd9b843839b4cf9409ee11d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9c3b072d7c0414a8c10dbe91f493cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a2d157383a4a3b8c79a0634e67c2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8878ab4935a40bcbb62edce18bf81b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b604abb3e9b849bd8b8c6819959ee7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c40f41f14248588ca70a01040420a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec0ff547527411e9f423165556c7f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f56b159a7f4b968d0d15805dd673a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fa23d6b122466eb13d6dc3e43e698d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511e454d9df64e969452c392907db431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da53340fc4d48ad83df27cd3e6af64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e33430e98b4e419e7112723170f0bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(mm_mlp, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
