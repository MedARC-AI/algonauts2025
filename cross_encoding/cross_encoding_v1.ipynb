{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-subject encoding\n",
    "\n",
    "Predicting each subject's activity using the synchronized activity of the other subjects. (Idk if any papers have done this, probably they have. Please someone lmk if they know of a reference.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader\n",
    "\n",
    "The data loader samples clips of synchronized activity from the same friends episodes across subjects. Each clip is shape `(n_subs, sample_length, dim)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "from torch.utils.data import IterableDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "SUBJECTS = [1, 2, 3, 5]\n",
    "\n",
    "ROOT = Path(\"/ocean/projects/med220004p/clane2/algonauts25\")\n",
    "ALGONAUTS_2025_FMRI_ROOT = ROOT / \"data/algonauts_2025_fmri\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Algonauts2025FriendsFmri(IterableDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str | Path,\n",
    "        subjects: list[int] | None = None,\n",
    "        seasons: list[int] | None = None,\n",
    "        sample_length: int = 128,\n",
    "        num_samples: int | None = None,\n",
    "        shuffle: bool = True,\n",
    "        keep_in_memory: bool = False,\n",
    "        seed: int | None = None,\n",
    "    ):\n",
    "        self.root = root\n",
    "        self.subjects = subjects or SUBJECTS\n",
    "        self.seasons = seasons or list(range(1, 7))\n",
    "        self.sample_length = sample_length\n",
    "        self.num_samples = num_samples\n",
    "        self.shuffle = shuffle\n",
    "        self.keep_in_memory = keep_in_memory\n",
    "        self.seed = seed\n",
    "\n",
    "        self._files = {\n",
    "            sub: h5py.File(\n",
    "                Path(root)\n",
    "                / f\"data/sub-{sub:02d}/func\" \n",
    "                / f\"sub-{sub:02d}_task-friends_space-MNI152NLin2009cAsym_atlas-Schaefer18_parcel-1000Par7Net_desc-s123456_bold.h5\"\n",
    "            )\n",
    "            for sub in self.subjects\n",
    "        }\n",
    "\n",
    "        self._task_key_maps = defaultdict(dict)\n",
    "        seasons_set = set(self.seasons)\n",
    "        for sub, file in self._files.items():\n",
    "            for key in file.keys():\n",
    "                task = key.split(\"-\")[-1]  # 'ses-066_task-s06e24d'\n",
    "                season, _, _ = _parse_friends_task(task)\n",
    "                if season in seasons_set:\n",
    "                    self._task_key_maps[task][sub] = key\n",
    "\n",
    "        self._task_list = sorted(\n",
    "            [\n",
    "                task for task, map in self._task_key_maps.items()\n",
    "                if len(map) == len(self.subjects)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        if self.keep_in_memory:\n",
    "            self._data = defaultdict(dict)\n",
    "            for sub in self.subjects:\n",
    "                for task in self._task_list:\n",
    "                    key = self._task_key_maps[task][sub]\n",
    "                    self._data[sub][key] = self._files[sub][key][:]\n",
    "        else:\n",
    "            self._data = None\n",
    "\n",
    "        self._rng = np.random.default_rng(seed)\n",
    "    \n",
    "    def _iter_shuffle(self):\n",
    "        sample_idx = 0\n",
    "        while True:\n",
    "            task_order = self._rng.permutation(len(self._task_list))\n",
    "\n",
    "            for ii in task_order:\n",
    "                task = self._task_list[ii]\n",
    "\n",
    "                keys = [self._task_key_maps[task][sub] for sub in self.subjects]\n",
    "                datas = [self._get_data(sub, key) for sub, key in zip(self.subjects, keys)]\n",
    "                length = min(len(data) for data in datas)\n",
    "                \n",
    "                offset = int(self._rng.integers(0, length - self.sample_length + 1))\n",
    "                sample = np.stack(\n",
    "                    [data[offset: offset + self.sample_length] for data in datas]\n",
    "                )\n",
    "\n",
    "                yield sample\n",
    "\n",
    "                sample_idx += 1\n",
    "                if self.num_samples and sample_idx >= self.num_samples:\n",
    "                    return\n",
    "    \n",
    "    def _iter_ordered(self):\n",
    "        sample_idx = 0\n",
    "        for task in self._task_list:\n",
    "            keys = [self._task_key_maps[task][sub] for sub in self.subjects]\n",
    "            datas = [self._get_data(sub, key) for sub, key in zip(self.subjects, keys)]\n",
    "            length = min(len(data) for data in datas)\n",
    "\n",
    "            for offset in range(0, length - self.sample_length + 1, self.sample_length):\n",
    "                sample = np.stack(\n",
    "                    [data[offset: offset + self.sample_length] for data in datas]\n",
    "                )\n",
    "                yield sample\n",
    "\n",
    "                sample_idx += 1\n",
    "                if self.num_samples and sample_idx >= self.num_samples:\n",
    "                    return\n",
    "    \n",
    "    def _get_data(self, sub: int, key: str):\n",
    "        maps = self._data if self.keep_in_memory else self._files\n",
    "        return maps[sub][key]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        if self.shuffle:\n",
    "            yield from self._iter_shuffle()\n",
    "        else:\n",
    "            yield from self._iter_ordered()\n",
    "\n",
    "\n",
    "def _parse_friends_task(task: str):\n",
    "    match = re.match(r\"s([0-9]+)e([0-9]+)([a-z])\", task)\n",
    "    season = int(match.group(1))\n",
    "    episode = int(match.group(2))\n",
    "    part = match.group(3)\n",
    "    return season, episode, part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [00:00, 12811.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time=0.030s, MB/s=10944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = Algonauts2025FriendsFmri(\n",
    "    root=ALGONAUTS_2025_FMRI_ROOT,\n",
    "    seasons=[6],\n",
    "    sample_length=64,\n",
    "    num_samples=None,\n",
    "    shuffle=False,\n",
    "    keep_in_memory=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "total_bytes = 0\n",
    "tic = time.monotonic()\n",
    "for sample in tqdm(dataset):\n",
    "    total_bytes += sample.size * 4\n",
    "rt = time.monotonic() - tic\n",
    "tput = total_bytes / 1024 ** 2 / rt \n",
    "print(f\"run time={rt:.3f}s, MB/s={tput:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Model architecture is a simple linear encoder and decoder for each subject. The encoder/decoder is \"factorized\" into a depthwise conv1d (to align data temporally), and a linear projection (to align data spatially).\n",
    "\n",
    "For each subject, the input to the decoder is the average of the latents for the other three subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv1d(nn.Conv1d):\n",
    "    \"\"\"Conv1d layer with a causal mask, to only \"attend\" to past time points.\"\"\"\n",
    "    attn_mask: torch.Tensor\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int,\n",
    "        stride: int = 1,\n",
    "        padding: str | int = 0,\n",
    "        dilation: int = 1,\n",
    "        groups: int = 1,\n",
    "        bias: bool = True,\n",
    "    ):\n",
    "        assert kernel_size % 2 == 1, \"causal conv requires odd kernel size\"\n",
    "        super().__init__(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=bias,\n",
    "        )\n",
    "\n",
    "        attn_mask = torch.zeros(kernel_size)\n",
    "        attn_mask[:kernel_size // 2 + 1] = 1.0\n",
    "        self.weight.data.mul_(attn_mask)\n",
    "        self.register_buffer(\"attn_mask\", attn_mask)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        weight = self.weight * self.attn_mask\n",
    "        return F.conv1d(\n",
    "            input, weight, self.bias, self.stride, self.padding, self.dilation, self.groups\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLinearEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        embed_dim: int,\n",
    "        kernel_size: int = 11,\n",
    "        causal: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        conv_layer = CausalConv1d if causal else nn.Conv1d\n",
    "        self.conv = conv_layer(\n",
    "            in_features,\n",
    "            in_features,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=\"same\",\n",
    "            groups=in_features,\n",
    "        )\n",
    "        self.fc = nn.Linear(in_features, embed_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: (N, L, C)\n",
    "        x = x.transpose(-1, -2)\n",
    "        x = self.conv(x)\n",
    "        x = x.transpose(-1, -2)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvLinearDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        out_features: int,\n",
    "        kernel_size: int = 11,\n",
    "        causal: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        conv_layer = CausalConv1d if causal else nn.Conv1d\n",
    "        self.fc = nn.Linear(embed_dim, out_features)\n",
    "        self.conv = conv_layer(\n",
    "            out_features,\n",
    "            out_features,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=\"same\",\n",
    "            groups=out_features,\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # x: (N, L, C)\n",
    "        x = self.fc(x)\n",
    "        x = x.transpose(-1, -2)\n",
    "        x = self.conv(x)\n",
    "        x = x.transpose(-1, -2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLinearEncoder(\n",
      "  (conv): CausalConv1d(1000, 1000, kernel_size=(11,), stride=(1,), padding=same, groups=1000)\n",
      "  (fc): Linear(in_features=1000, out_features=256, bias=True)\n",
      ")\n",
      "torch.Size([16, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "encoder = ConvLinearEncoder(\n",
    "    in_features=1000,\n",
    "    embed_dim=256,\n",
    "    causal=True\n",
    ")\n",
    "print(encoder)\n",
    "\n",
    "# (N, L, C)\n",
    "x = torch.randn(16, 64, 1000)\n",
    "embed = encoder.forward(x)\n",
    "print(embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossSubjectConvLinearEncoder(nn.Module):\n",
    "    weight: torch.Tensor\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_subjects: int,\n",
    "        encoder_fn: type[nn.Module],\n",
    "        decoder_fn: type[nn.Module],\n",
    "        embed_dim: int = 256,\n",
    "        normalize: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_subjects = num_subjects\n",
    "        # todo: could also consider having a shared group encoder/decoder\n",
    "        self.encoders = nn.ModuleList([encoder_fn() for _ in range(num_subjects)])\n",
    "        self.norm = nn.LayerNorm(embed_dim) if normalize else nn.Identity()\n",
    "        self.decoders = nn.ModuleList([decoder_fn() for _ in range(num_subjects)])\n",
    "        \n",
    "        # todo: could learn the averaging weights\n",
    "        weight = (1.0 - torch.eye(self.num_subjects)) / (self.num_subjects - 1.0)\n",
    "        self.register_buffer(\"weight\", weight)\n",
    "        self.apply(init_weights)\n",
    "    \n",
    "    def forward(self, input: torch.Tensor):\n",
    "        # input: (N, S, L, C)\n",
    "        # subject specific encoders\n",
    "        embed = torch.stack(\n",
    "            [encoder(input[:, ii]) for ii, encoder in enumerate(self.encoders)],\n",
    "            dim=1,\n",
    "        )\n",
    "        embed = self.norm(embed)\n",
    "        # average pool the latents for all but target subject\n",
    "        embed = torch.einsum(\"nslc,ts->ntlc\", embed, self.weight)\n",
    "        # subject specific decoders\n",
    "        output = torch.stack(\n",
    "            [decoder(embed[:, ii]) for ii, decoder in enumerate(self.decoders)],\n",
    "            dim=1,\n",
    "        )\n",
    "        return output\n",
    "\n",
    "\n",
    "def init_weights(m: nn.Module):\n",
    "    if isinstance(m, (nn.Conv1d, nn.Conv2d, nn.Linear)):\n",
    "        nn.init.trunc_normal_(m.weight, std=0.02)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossSubjectConvLinearEncoder(\n",
      "  (encoders): ModuleList(\n",
      "    (0-3): 4 x ConvLinearEncoder(\n",
      "      (conv): Conv1d(1000, 1000, kernel_size=(11,), stride=(1,), padding=same, groups=1000)\n",
      "      (fc): Linear(in_features=1000, out_features=256, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (norm): Identity()\n",
      "  (decoders): ModuleList(\n",
      "    (0-3): 4 x ConvLinearDecoder(\n",
      "      (fc): Linear(in_features=256, out_features=1000, bias=True)\n",
      "      (conv): Conv1d(1000, 1000, kernel_size=(11,), stride=(1,), padding=same, groups=1000)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "torch.Size([16, 4, 64, 1000])\n"
     ]
    }
   ],
   "source": [
    "encoder_fn = partial(ConvLinearEncoder, 1000, 256)\n",
    "decoder_fn = partial(ConvLinearDecoder, 256, 1000)\n",
    "\n",
    "cross_encoder = CrossSubjectConvLinearEncoder(\n",
    "    num_subjects=4,\n",
    "    encoder_fn=encoder_fn,\n",
    "    decoder_fn=decoder_fn,\n",
    "    embed_dim=256,\n",
    ")\n",
    "print(cross_encoder)\n",
    "\n",
    "# (N, S, L, C)\n",
    "x = torch.randn(16, 4, 64, 1000)\n",
    "z = cross_encoder.forward(x)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Basic training loop, AdamW, no lr decay, no bells and whistles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from timm.utils import AverageMeter, random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    *,\n",
    "    epoch: int,\n",
    "    model: torch.nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    epoch_batches: int | None,\n",
    "    device: torch.device,\n",
    "):\n",
    "    model.train()\n",
    "    \n",
    "    use_cuda = device.type == \"cuda\"\n",
    "    if use_cuda:\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    loss_m = AverageMeter()\n",
    "    data_time_m = AverageMeter()\n",
    "    step_time_m = AverageMeter()\n",
    "\n",
    "    epoch_batches = len(train_loader) if epoch_batches is None else epoch_batches\n",
    "    first_step = epoch * epoch_batches\n",
    "\n",
    "    end = time.monotonic()\n",
    "    for batch_idx, sample in enumerate(train_loader):\n",
    "        step = first_step + batch_idx\n",
    "        sample = sample.to(device)\n",
    "        batch_size = sample.size(0)\n",
    "        data_time = time.monotonic() - end\n",
    "\n",
    "        # forward pass\n",
    "        output = model(sample)\n",
    "        loss = F.mse_loss(output, sample)\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        if math.isnan(loss_item) or math.isinf(loss_item):\n",
    "            raise RuntimeError(\"NaN/Inf loss encountered on step %d; exiting\", step)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # end of iteration timing\n",
    "        if use_cuda:\n",
    "            torch.cuda.synchronize()\n",
    "        step_time = time.monotonic() - end\n",
    "\n",
    "        loss_m.update(loss_item, batch_size)\n",
    "        data_time_m.update(data_time, batch_size)\n",
    "        step_time_m.update(step_time, batch_size)\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            tput = batch_size / step_time_m.avg\n",
    "            if use_cuda:\n",
    "                alloc_mem_gb = torch.cuda.max_memory_allocated() / 1e9\n",
    "                res_mem_gb = torch.cuda.max_memory_reserved() / 1e9\n",
    "            else:\n",
    "                alloc_mem_gb = res_mem_gb = 0.0\n",
    "\n",
    "            print(\n",
    "                f\"Train: {epoch:>3d} [{batch_idx:>3d}/{epoch_batches}][{step:>6d}]\"\n",
    "                f\"  Loss: {loss_m.val:#.3g} ({loss_m.avg:#.3g})\"\n",
    "                f\"  Time: {data_time_m.avg:.3f},{step_time_m.avg:.3f} {tput:.0f}/s\"\n",
    "                f\"  Mem: {alloc_mem_gb:.2f},{res_mem_gb:.2f} GB\"\n",
    "            )\n",
    "\n",
    "        # Restart timer for next iteration\n",
    "        end = time.monotonic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(\n",
    "    *,\n",
    "    epoch: int,\n",
    "    model: torch.nn.Module,\n",
    "    val_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    use_cuda = device.type == \"cuda\"\n",
    "    \n",
    "    loss_m = AverageMeter()\n",
    "    data_time_m = AverageMeter()\n",
    "    step_time_m = AverageMeter()\n",
    "\n",
    "    samples = []\n",
    "    outputs = []\n",
    "\n",
    "    end = time.monotonic()\n",
    "    for batch_idx, sample in enumerate(val_loader):\n",
    "        sample = sample.to(device)\n",
    "        batch_size = sample.size(0)\n",
    "        data_time = time.monotonic() - end\n",
    "\n",
    "        # forward pass\n",
    "        output = model(sample)\n",
    "        loss = F.mse_loss(output, sample)\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        # end of iteration timing\n",
    "        if use_cuda:\n",
    "            torch.cuda.synchronize()\n",
    "        step_time = time.monotonic() - end\n",
    "\n",
    "        loss_m.update(loss_item, batch_size)\n",
    "        data_time_m.update(data_time, batch_size)\n",
    "        step_time_m.update(step_time, batch_size)\n",
    "\n",
    "        samples.append(sample.cpu().numpy())\n",
    "        outputs.append(output.cpu().numpy())\n",
    "\n",
    "        # Reset timer\n",
    "        end = time.monotonic()\n",
    "\n",
    "    # (N, S, L, C)\n",
    "    samples = np.concatenate(samples)\n",
    "    outputs = np.concatenate(outputs)\n",
    "    \n",
    "    accs = {\n",
    "        f\"acc_s{sub}\": pearsonr_score(samples[:, ii], outputs[:, ii])\n",
    "        for ii, sub in enumerate(SUBJECTS)\n",
    "    }\n",
    "    accs_fmt = \",\".join(f\"{acc:.3f}\" for acc in accs.values())\n",
    "    acc = sum(accs.values()) / len(accs)\n",
    "\n",
    "    tput = batch_size / step_time_m.avg\n",
    "    print(\n",
    "        f\"Val: {epoch:>3d}\"\n",
    "        f\"  Loss: {loss_m.avg:#.3g}\"\n",
    "        f\"  Acc: {accs_fmt} ({acc:.3f})\"\n",
    "        f\"  Time: {data_time_m.avg:.3f},{step_time_m.avg:.3f} {tput:.0f}/s\"\n",
    "    )\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "def pearsonr_score(\n",
    "    y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-7\n",
    ") -> np.ndarray:\n",
    "    y_true = y_true.reshape(-1, y_true.shape[-1])\n",
    "    y_pred = y_pred.reshape(-1, y_pred.shape[-1])\n",
    "\n",
    "    y_true = y_true - y_true.mean(axis=0)\n",
    "    y_true = y_true / (np.linalg.norm(y_true, axis=0) + eps)\n",
    "\n",
    "    y_pred = y_pred - y_pred.mean(axis=0)\n",
    "    y_pred = y_pred / (np.linalg.norm(y_pred, axis=0) + eps)\n",
    "\n",
    "    score = (y_true * y_pred).sum(axis=0).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 3315\n",
    "batch_size = 16\n",
    "sample_length = 64\n",
    "n_train_samples = 2000\n",
    "embed_dim = 256\n",
    "kernel_size = 11\n",
    "lr = 3e-4\n",
    "weight_decay = 0.001\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: cpu\n"
     ]
    }
   ],
   "source": [
    "random_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Algonauts2025FriendsFmri(\n",
    "    root=ALGONAUTS_2025_FMRI_ROOT,\n",
    "    seasons=range(1, 6),\n",
    "    sample_length=sample_length,\n",
    "    num_samples=n_train_samples,\n",
    "    shuffle=True,\n",
    "    keep_in_memory=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "val_dataset = Algonauts2025FriendsFmri(\n",
    "    root=ALGONAUTS_2025_FMRI_ROOT,\n",
    "    seasons=[6],\n",
    "    sample_length=sample_length,\n",
    "    shuffle=False,\n",
    "    keep_in_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: (16, 4, 64, 1000)\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "print(\"Batch shape:\", tuple(batch.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: CrossSubjectConvLinearEncoder(\n",
      "  (encoders): ModuleList(\n",
      "    (0-3): 4 x ConvLinearEncoder(\n",
      "      (conv): Conv1d(1000, 1000, kernel_size=(11,), stride=(1,), padding=same, groups=1000)\n",
      "      (fc): Linear(in_features=1000, out_features=256, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (norm): Identity()\n",
      "  (decoders): ModuleList(\n",
      "    (0-3): 4 x ConvLinearDecoder(\n",
      "      (fc): Linear(in_features=256, out_features=1000, bias=True)\n",
      "      (conv): Conv1d(1000, 1000, kernel_size=(11,), stride=(1,), padding=same, groups=1000)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Num params: 2.15M\n"
     ]
    }
   ],
   "source": [
    "encoder_fn = partial(ConvLinearEncoder, 1000, embed_dim, kernel_size=kernel_size)\n",
    "decoder_fn = partial(ConvLinearDecoder, embed_dim, 1000, kernel_size=kernel_size)\n",
    "\n",
    "model = CrossSubjectConvLinearEncoder(\n",
    "    num_subjects=4,\n",
    "    encoder_fn=encoder_fn,\n",
    "    decoder_fn=decoder_fn,\n",
    "    embed_dim=embed_dim,\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "param_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Model:\", model)\n",
    "print(f\"Num params: {param_count/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "epoch_batches = n_train_samples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:   0 [  0/125][     0]  Loss: 0.359 (0.359)  Time: 0.012,0.258 62/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [ 10/125][    10]  Loss: 0.368 (0.371)  Time: 0.006,0.156 103/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [ 20/125][    20]  Loss: 0.361 (0.373)  Time: 0.006,0.161 100/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [ 30/125][    30]  Loss: 0.378 (0.373)  Time: 0.006,0.157 102/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [ 40/125][    40]  Loss: 0.378 (0.373)  Time: 0.006,0.163 98/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [ 50/125][    50]  Loss: 0.375 (0.372)  Time: 0.006,0.159 100/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [ 60/125][    60]  Loss: 0.352 (0.371)  Time: 0.005,0.159 101/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [ 70/125][    70]  Loss: 0.357 (0.369)  Time: 0.005,0.158 101/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [ 80/125][    80]  Loss: 0.357 (0.367)  Time: 0.005,0.157 102/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [ 90/125][    90]  Loss: 0.347 (0.365)  Time: 0.005,0.156 103/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [100/125][   100]  Loss: 0.350 (0.364)  Time: 0.005,0.157 102/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [110/125][   110]  Loss: 0.340 (0.362)  Time: 0.005,0.156 103/s  Mem: 0.00,0.00 GB\n",
      "Train:   0 [120/125][   120]  Loss: 0.331 (0.361)  Time: 0.005,0.155 103/s  Mem: 0.00,0.00 GB\n",
      "Val:   0  Loss: 0.342  Acc: 0.239,0.250,0.256,0.233 (0.245)  Time: 0.007,0.075 215/s\n",
      "Train:   1 [  5/125][   130]  Loss: 0.344 (0.340)  Time: 0.005,0.148 108/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [ 15/125][   140]  Loss: 0.334 (0.341)  Time: 0.005,0.150 107/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [ 25/125][   150]  Loss: 0.352 (0.342)  Time: 0.005,0.162 98/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [ 35/125][   160]  Loss: 0.335 (0.342)  Time: 0.005,0.161 99/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [ 45/125][   170]  Loss: 0.333 (0.340)  Time: 0.005,0.158 101/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [ 55/125][   180]  Loss: 0.331 (0.339)  Time: 0.005,0.158 101/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [ 65/125][   190]  Loss: 0.336 (0.339)  Time: 0.005,0.158 101/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [ 75/125][   200]  Loss: 0.336 (0.338)  Time: 0.005,0.157 102/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [ 85/125][   210]  Loss: 0.327 (0.337)  Time: 0.005,0.155 103/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [ 95/125][   220]  Loss: 0.331 (0.337)  Time: 0.005,0.156 103/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [105/125][   230]  Loss: 0.334 (0.337)  Time: 0.005,0.161 99/s  Mem: 0.00,0.00 GB\n",
      "Train:   1 [115/125][   240]  Loss: 0.332 (0.336)  Time: 0.005,0.162 99/s  Mem: 0.00,0.00 GB\n",
      "Val:   1  Loss: 0.330  Acc: 0.290,0.295,0.309,0.274 (0.292)  Time: 0.007,0.074 216/s\n",
      "Train:   2 [  0/125][   250]  Loss: 0.316 (0.316)  Time: 0.005,0.147 109/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [ 10/125][   260]  Loss: 0.327 (0.329)  Time: 0.005,0.154 104/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [ 20/125][   270]  Loss: 0.321 (0.329)  Time: 0.005,0.152 105/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [ 30/125][   280]  Loss: 0.322 (0.328)  Time: 0.005,0.153 104/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [ 40/125][   290]  Loss: 0.309 (0.327)  Time: 0.005,0.152 105/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [ 50/125][   300]  Loss: 0.341 (0.328)  Time: 0.005,0.153 104/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [ 60/125][   310]  Loss: 0.329 (0.328)  Time: 0.005,0.153 105/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [ 70/125][   320]  Loss: 0.325 (0.327)  Time: 0.005,0.152 105/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [ 80/125][   330]  Loss: 0.320 (0.327)  Time: 0.005,0.156 102/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [ 90/125][   340]  Loss: 0.324 (0.327)  Time: 0.005,0.157 102/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [100/125][   350]  Loss: 0.318 (0.327)  Time: 0.005,0.156 103/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [110/125][   360]  Loss: 0.316 (0.327)  Time: 0.005,0.156 103/s  Mem: 0.00,0.00 GB\n",
      "Train:   2 [120/125][   370]  Loss: 0.319 (0.327)  Time: 0.005,0.155 103/s  Mem: 0.00,0.00 GB\n",
      "Val:   2  Loss: 0.324  Acc: 0.312,0.316,0.332,0.292 (0.313)  Time: 0.005,0.098 163/s\n",
      "Train:   3 [  5/125][   380]  Loss: 0.316 (0.319)  Time: 0.005,0.169 95/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [ 15/125][   390]  Loss: 0.407 (0.328)  Time: 0.005,0.157 102/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [ 25/125][   400]  Loss: 0.319 (0.325)  Time: 0.005,0.156 102/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [ 35/125][   410]  Loss: 0.316 (0.324)  Time: 0.005,0.167 96/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [ 45/125][   420]  Loss: 0.334 (0.323)  Time: 0.005,0.166 97/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [ 55/125][   430]  Loss: 0.315 (0.323)  Time: 0.005,0.162 99/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [ 65/125][   440]  Loss: 0.323 (0.322)  Time: 0.005,0.163 98/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [ 75/125][   450]  Loss: 0.309 (0.323)  Time: 0.005,0.161 100/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [ 85/125][   460]  Loss: 0.326 (0.322)  Time: 0.005,0.160 100/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [ 95/125][   470]  Loss: 0.327 (0.323)  Time: 0.005,0.161 99/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [105/125][   480]  Loss: 0.331 (0.322)  Time: 0.005,0.161 100/s  Mem: 0.00,0.00 GB\n",
      "Train:   3 [115/125][   490]  Loss: 0.313 (0.322)  Time: 0.005,0.160 100/s  Mem: 0.00,0.00 GB\n",
      "Val:   3  Loss: 0.321  Acc: 0.325,0.327,0.347,0.302 (0.325)  Time: 0.007,0.075 212/s\n",
      "Train:   4 [  0/125][   500]  Loss: 0.313 (0.313)  Time: 0.005,0.143 112/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [ 10/125][   510]  Loss: 0.301 (0.317)  Time: 0.005,0.183 87/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [ 20/125][   520]  Loss: 0.313 (0.317)  Time: 0.005,0.170 94/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [ 30/125][   530]  Loss: 0.318 (0.318)  Time: 0.005,0.189 85/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [ 40/125][   540]  Loss: 0.310 (0.318)  Time: 0.005,0.180 89/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [ 50/125][   550]  Loss: 0.315 (0.317)  Time: 0.004,0.178 90/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [ 60/125][   560]  Loss: 0.317 (0.317)  Time: 0.005,0.174 92/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [ 70/125][   570]  Loss: 0.314 (0.317)  Time: 0.004,0.171 93/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [ 80/125][   580]  Loss: 0.326 (0.317)  Time: 0.004,0.171 94/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [ 90/125][   590]  Loss: 0.318 (0.317)  Time: 0.004,0.170 94/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [100/125][   600]  Loss: 0.314 (0.318)  Time: 0.004,0.168 95/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [110/125][   610]  Loss: 0.324 (0.318)  Time: 0.004,0.168 95/s  Mem: 0.00,0.00 GB\n",
      "Train:   4 [120/125][   620]  Loss: 0.320 (0.318)  Time: 0.004,0.166 96/s  Mem: 0.00,0.00 GB\n",
      "Val:   4  Loss: 0.319  Acc: 0.331,0.333,0.355,0.308 (0.332)  Time: 0.005,0.078 206/s\n",
      "Train:   5 [  5/125][   630]  Loss: 0.317 (0.320)  Time: 0.005,0.147 109/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [ 15/125][   640]  Loss: 0.327 (0.318)  Time: 0.004,0.149 107/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [ 25/125][   650]  Loss: 0.313 (0.316)  Time: 0.004,0.151 106/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [ 35/125][   660]  Loss: 0.319 (0.316)  Time: 0.005,0.166 97/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [ 45/125][   670]  Loss: 0.319 (0.316)  Time: 0.005,0.162 99/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [ 55/125][   680]  Loss: 0.312 (0.316)  Time: 0.005,0.159 100/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [ 65/125][   690]  Loss: 0.305 (0.316)  Time: 0.005,0.165 97/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [ 75/125][   700]  Loss: 0.315 (0.315)  Time: 0.005,0.163 98/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [ 85/125][   710]  Loss: 0.305 (0.315)  Time: 0.005,0.164 98/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [ 95/125][   720]  Loss: 0.307 (0.314)  Time: 0.005,0.163 98/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [105/125][   730]  Loss: 0.316 (0.314)  Time: 0.005,0.163 98/s  Mem: 0.00,0.00 GB\n",
      "Train:   5 [115/125][   740]  Loss: 0.314 (0.314)  Time: 0.005,0.163 98/s  Mem: 0.00,0.00 GB\n",
      "Val:   5  Loss: 0.317  Acc: 0.336,0.338,0.360,0.312 (0.337)  Time: 0.007,0.068 235/s\n",
      "Train:   6 [  0/125][   750]  Loss: 0.324 (0.324)  Time: 0.004,0.146 110/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [ 10/125][   760]  Loss: 0.323 (0.319)  Time: 0.005,0.150 106/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [ 20/125][   770]  Loss: 0.317 (0.317)  Time: 0.005,0.153 105/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [ 30/125][   780]  Loss: 0.311 (0.316)  Time: 0.005,0.151 106/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [ 40/125][   790]  Loss: 0.313 (0.316)  Time: 0.005,0.150 107/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [ 50/125][   800]  Loss: 0.317 (0.315)  Time: 0.005,0.150 106/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [ 60/125][   810]  Loss: 0.329 (0.315)  Time: 0.005,0.151 106/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [ 70/125][   820]  Loss: 0.307 (0.314)  Time: 0.004,0.154 104/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [ 80/125][   830]  Loss: 0.318 (0.314)  Time: 0.004,0.155 103/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [ 90/125][   840]  Loss: 0.306 (0.313)  Time: 0.004,0.156 103/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [100/125][   850]  Loss: 0.322 (0.313)  Time: 0.004,0.155 103/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [110/125][   860]  Loss: 0.304 (0.313)  Time: 0.004,0.155 103/s  Mem: 0.00,0.00 GB\n",
      "Train:   6 [120/125][   870]  Loss: 0.310 (0.313)  Time: 0.004,0.157 102/s  Mem: 0.00,0.00 GB\n",
      "Val:   6  Loss: 0.316  Acc: 0.339,0.342,0.365,0.314 (0.340)  Time: 0.014,0.095 168/s\n",
      "Train:   7 [  5/125][   880]  Loss: 0.302 (0.309)  Time: 0.004,0.153 104/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [ 15/125][   890]  Loss: 0.296 (0.309)  Time: 0.004,0.151 106/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [ 25/125][   900]  Loss: 0.312 (0.309)  Time: 0.004,0.151 106/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [ 35/125][   910]  Loss: 0.298 (0.310)  Time: 0.004,0.159 101/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [ 45/125][   920]  Loss: 0.317 (0.311)  Time: 0.004,0.159 101/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [ 55/125][   930]  Loss: 0.306 (0.311)  Time: 0.004,0.157 102/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [ 65/125][   940]  Loss: 0.308 (0.310)  Time: 0.004,0.158 101/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [ 75/125][   950]  Loss: 0.320 (0.311)  Time: 0.004,0.162 99/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [ 85/125][   960]  Loss: 0.308 (0.310)  Time: 0.004,0.160 100/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [ 95/125][   970]  Loss: 0.306 (0.311)  Time: 0.004,0.159 100/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [105/125][   980]  Loss: 0.304 (0.311)  Time: 0.004,0.158 101/s  Mem: 0.00,0.00 GB\n",
      "Train:   7 [115/125][   990]  Loss: 0.313 (0.311)  Time: 0.004,0.159 100/s  Mem: 0.00,0.00 GB\n",
      "Val:   7  Loss: 0.316  Acc: 0.342,0.344,0.367,0.316 (0.342)  Time: 0.005,0.068 237/s\n",
      "Train:   8 [  0/125][  1000]  Loss: 0.318 (0.318)  Time: 0.004,0.143 112/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [ 10/125][  1010]  Loss: 0.316 (0.309)  Time: 0.004,0.150 107/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [ 20/125][  1020]  Loss: 0.319 (0.309)  Time: 0.004,0.154 104/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [ 30/125][  1030]  Loss: 0.305 (0.309)  Time: 0.006,0.155 103/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [ 40/125][  1040]  Loss: 0.307 (0.310)  Time: 0.006,0.153 105/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [ 50/125][  1050]  Loss: 0.316 (0.310)  Time: 0.006,0.153 105/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [ 60/125][  1060]  Loss: 0.306 (0.310)  Time: 0.005,0.156 103/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [ 70/125][  1070]  Loss: 0.301 (0.310)  Time: 0.005,0.155 103/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [ 80/125][  1080]  Loss: 0.297 (0.309)  Time: 0.005,0.154 104/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [ 90/125][  1090]  Loss: 0.307 (0.309)  Time: 0.005,0.156 102/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [100/125][  1100]  Loss: 0.304 (0.309)  Time: 0.005,0.155 103/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [110/125][  1110]  Loss: 0.311 (0.309)  Time: 0.005,0.157 102/s  Mem: 0.00,0.00 GB\n",
      "Train:   8 [120/125][  1120]  Loss: 0.308 (0.309)  Time: 0.005,0.160 100/s  Mem: 0.00,0.00 GB\n",
      "Val:   8  Loss: 0.315  Acc: 0.344,0.345,0.369,0.318 (0.344)  Time: 0.015,0.086 187/s\n",
      "Train:   9 [  5/125][  1130]  Loss: 0.307 (0.305)  Time: 0.005,0.163 98/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [ 15/125][  1140]  Loss: 0.311 (0.308)  Time: 0.005,0.154 104/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [ 25/125][  1150]  Loss: 0.303 (0.310)  Time: 0.005,0.157 102/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [ 35/125][  1160]  Loss: 0.323 (0.310)  Time: 0.005,0.154 104/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [ 45/125][  1170]  Loss: 0.300 (0.310)  Time: 0.005,0.159 100/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [ 55/125][  1180]  Loss: 0.307 (0.310)  Time: 0.005,0.161 99/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [ 65/125][  1190]  Loss: 0.308 (0.310)  Time: 0.005,0.159 101/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [ 75/125][  1200]  Loss: 0.302 (0.310)  Time: 0.004,0.158 101/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [ 85/125][  1210]  Loss: 0.314 (0.310)  Time: 0.004,0.159 101/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [ 95/125][  1220]  Loss: 0.307 (0.309)  Time: 0.004,0.159 100/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [105/125][  1230]  Loss: 0.308 (0.309)  Time: 0.004,0.160 100/s  Mem: 0.00,0.00 GB\n",
      "Train:   9 [115/125][  1240]  Loss: 0.321 (0.310)  Time: 0.004,0.159 101/s  Mem: 0.00,0.00 GB\n",
      "Val:   9  Loss: 0.315  Acc: 0.345,0.347,0.371,0.319 (0.345)  Time: 0.006,0.073 219/s\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train_one_epoch(\n",
    "        epoch=epoch,\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        optimizer=optimizer,\n",
    "        epoch_batches=epoch_batches,\n",
    "        device=device,\n",
    "    )\n",
    "    validate(\n",
    "        epoch=epoch,\n",
    "        model=model,\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
